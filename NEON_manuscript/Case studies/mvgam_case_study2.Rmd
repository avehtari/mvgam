---
title: "mvgam case study 2: multivariate models"
author: Nicholas Clark (n.clark@uq.edu.au)
output:
  html_document:
    df_print: paged
  pdf_document:
    highlight: zenburn
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=40),tidy=TRUE)
```

In this example we will examine multivariate forecasting models using `mvgam`. Here we will access monthly search volume data from `Google Trends`, focusing on relative importances of search terms related to tick paralysis in Queensland, Australia
```{r message=FALSE, warning = FALSE}
library(mvgam)
library(tidyr)
if(!require(gtrendsR)){
  install.packages('gtrendsR')
}

terms = c("tick bite",
          "tick paralysis",
          "dog tick", 
          "paralysis tick dog")
trends <- gtrendsR::gtrends(terms, geo = "AU-QLD",
                            time = "all", onlyInterest = T)
```

`Google Trends` modified their algorithm for extracting search volume data in 2012, so we filter the series to only include observations after this point in time
```{r}
trends$interest_over_time %>%
  tidyr::spread(keyword, hits) %>%
  dplyr::select(-geo, -time, -gprop, -category) %>%
  dplyr::mutate(date = lubridate::ymd(date)) %>%
  dplyr::mutate(year = lubridate::year(date)) %>%
  dplyr::filter(year > 2012) %>%
  dplyr::select(-year) -> gtest
```

Convert to an `xts` object and then to the required `mvgam` format, holding out the final 10% of observations as the test data
```{r}
series <- xts::xts(x = gtest[,-1], order.by = gtest$date)
trends_data <- series_to_mvgam(series, freq = 12, train_prop = 0.9)
```

Plot the series to see how similar their seasonal shapes are over time
```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot(series, legend.loc = 'topleft')
```

Now we will fit an `mvgam` model with shared seasonality and random intercepts per series. An advantage of using `JAGS` for sampling is that we can implement truncated likelihood functions to recognise known bounds for particular parameters. As we know that `Google trends` relative search volumes cannot go above `100`, we specify this as the upper bound for each series (note that these truncated likelihoods are much slower to estimate in `JAGS` so only use them if required). Here we assume the dynamic trends can be represented using three latent factors that each follow an `AR3` process, and we assume a Negative Binomial distrubution for the response. At present each series is presumed to show the same degree of overdispersion, but this assumption will be relaxed in future versions
```{r}
trends_mod <- mvjagam(data_train = trends_data$data_train,
                      data_test = trends_data$data_test,
                      formula = y ~ s(series, bs = 're') + 
                        s(season, k = 12, m = 2, bs = 'cc'),
                      knots = list(season = c(0.5, 12.5)),
                      use_lv = T,
                      trend_model = 'AR3',
                      n_lv = 3,
                      family = 'nb',
                      n.burnin = 2000,
                      upper_bounds = rep(100, length(terms)),
                      auto_update = F)
```

Have a look at the returned `JAGS` model file to see how the dynamic factors are incorporated. Notice that the precisions of factors, together with each factor's set of loadings, are penalised using a regularised horseshoe prior. This should hopefully protect against specifying too large a number of factors than is needed to represent dependent temporal dynamics
```{r}
trends_mod$model_file
```

Given that these series could potentially be following a hierarchical seasonality, we will also trial a slghtly more complex model with an extra smoothing term per series that allows its seasonal curve to deviate from the global seasonal smooth
```{r}
trends_mod2 <- mvjagam(data_train = trends_data$data_train,
                      data_test = trends_data$data_test,
                      formula = y ~ s(series, bs = 're') + 
                        s(season, k = 12, m = 2, bs = 'cc') +
                        s(season, by = series, k = 5, m = 1),
                      knots = list(season = c(0.5, 12.5)),
                      use_lv = T,
                      trend_model = 'AR3',
                      n_lv = 3,
                      family = 'nb',
                      n.burnin = 2000,
                      upper_bounds = rep(100, length(terms)),
                      auto_update = F)
```

Compare the models using rolling forecast DRPS evaluation. Here we focus on near-term forecasts (`fc_horizon = 3`) when comparing model performances
```{r,  fig.width = 6, fig.height = 5, fig.align='center'}
compare_mvgams(trends_mod, trends_mod2, fc_horizon = 3,
               n_cores = 3, n_evaluations = 10)
```

Model 1 (with shared seasonality) is slightly preferred, suggesting there is not sufficient evidence that the variation in the seasonal curves for these series may not be useful for forecasting. This is likely because the noisiness of these series makes it difficult to estimate their individual seasonanl patterns, while any fluctuations through time can be more readily captured by the flexibility of the latent trends.

Inspect the model summary (note again that p-value approximations are a work in progress here and so may not be totally reliable).
```{r}
summary_mvgam(trends_mod)
```

Look at Dunn-Smyth residuals for some series from this preferred model to ensure the Negative Binomial is appropriate and that our dynamic factor process has captured most of the temporal dependencies in the observations
```{r, fig.width = 7, fig.height = 7, fig.align='center'}
plot_mvgam_resids(trends_mod, 1)
```

```{r, fig.width = 7, fig.height = 7, fig.align='center'}
plot_mvgam_resids(trends_mod, 2)
```

```{r, fig.width = 7, fig.height = 7, fig.align='center'}
plot_mvgam_resids(trends_mod, 3)
```

```{r, fig.width = 7, fig.height = 7, fig.align='center'}
plot_mvgam_resids(trends_mod, 4)
```

Perform posterior predictive checks to see if the model is able to simulate data that looks realistic and unbiased by examining simulated kernel densities for posterior predictions (`yhat`) compared to the density of the observations (`y`). This will be particularly useful for examining whether the shared overdispersion parameter is able to produce realistic looking simulations for each individual series.
```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 1, type = 'density')
```

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 2, type = 'density')
```

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 3, type = 'density')
```

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 4, type = 'density')
```

Look at traceplots for the smoothing parameters (`rho`) and latent trend parameters
```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_trace(object = trends_mod, param = 'rho')
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_trace(object = trends_mod, param = 'trend')
```

Plot posterior predictive distributions for the training and testing periods for each series
```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_fc(object = trends_mod, series = 1, data_test = trends_data$data_test)
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_fc(object = trends_mod, series = 2, data_test = trends_data$data_test)
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_fc(object = trends_mod, series = 3, data_test = trends_data$data_test)
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_fc(object = trends_mod, series = 4, data_test = trends_data$data_test)
```

Plot posterior distributions for the latent trend estimates, again for the training and testing periods
```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_trend(object = trends_mod, series = 1, data_test = trends_data$data_test)
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_trend(object = trends_mod, series = 2, data_test = trends_data$data_test)
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_trend(object = trends_mod, series = 3, data_test = trends_data$data_test)
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
plot_mvgam_trend(object = trends_mod, series = 4, data_test = trends_data$data_test)
```

Given that we fit a model with a shared seasonal pattern, the seasonal smooths for each series will be identical. Plot it here
```{r, fig.width = 4, fig.height = 3, fig.align='center'}
plot_mvgam_smooth(object = trends_mod, series = 1, smooth = 'season')
```

Plot posterior mean estimates of latent trend correlations. These correlations are more useful than looking at latent factor loadings, for example to inspect ordinations. This is because the orders of the loadings (although constrained for identifiability purposes) can vary from chain to chain
```{r}
correlations <- lv_correlations(object = trends_mod)
```

```{r, fig.align='center', fig.width=6, fig.height=4, message=FALSE}
library(ggplot2)
mean_correlations <- correlations$mean_correlations
mean_correlations[upper.tri(mean_correlations)] <- NA
mean_correlations <- data.frame(mean_correlations)
ggplot(mean_correlations %>%
         tibble::rownames_to_column("series1") %>%
         tidyr::pivot_longer(-c(series1), names_to = "series2", values_to = "Correlation"),
       aes(x = series1, y = series2)) + geom_tile(aes(fill = Correlation)) +
  scale_fill_gradient2(low="darkred", mid="white", high="darkblue",
                       midpoint = 0,
                       breaks = seq(-1,1,length.out = 5),
                       limits = c(-1, 1),
                       name = 'Trend\ncorrelation') + labs(x = '', y = '') + theme_dark() +
  theme(axis.text.x = element_text(angle = 45, hjust=1))
```

There is certainly some evidence of positive trend correlations for a few of these search terms, which is not surprising given how similar some of them are and how closely linked they should be to interest about tick paralysis in Queensland. Plot some STL decompositions of these series to see if these trends are noticeable in the data
```{r, fig.align='center', fig.width=6, fig.height=4, message=FALSE}
plot(stl(ts(as.vector(series$`tick paralysis`), frequency = 12), 'periodic'))
plot(stl(ts(as.vector(series$`paralysis tick dog`), frequency = 12), 'periodic'))
plot(stl(ts(as.vector(series$`dog tick`), frequency = 12), 'periodic'))
plot(stl(ts(as.vector(series$`tick bite`), frequency = 12), 'periodic'))
```

A logical next step for this analysis would be to trial varying overdispersion parameters for each series. This may be necessary as the residual diagnostic plots and forecast period posterior predictive checks suggest that the estimated Negative Binomial overdispersion parameter is more suitable for some series than for others: 
```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 1, type = 'density', data_test = trends_data$data_test)
```

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 1, type = 'mean', data_test = trends_data$data_test)
```


```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 2, type = 'density', data_test = trends_data$data_test)
```

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 2, type = 'mean', data_test = trends_data$data_test)
```


```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 3, type = 'density', data_test = trends_data$data_test)
```

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 3, type = 'mean', data_test = trends_data$data_test)
```


```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 4, type = 'density', data_test = trends_data$data_test)
```

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
plot_mvgam_ppc(trends_mod, series = 4, type = 'mean', data_test = trends_data$data_test)
```

Other next steps could involve devising a more goal-specific set of posterior predictive checks (see [this paper by Gelman et al](https://www.jstor.org/stable/2680852?seq=1#metadata_info_tab_contents) and [relevant works by Betancourt](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html) for examples), compare out of sample Discrete Rank Probability Scores for this model and simpler versions for the latent trends (i.e. AR2, AR1, Random Walk)

