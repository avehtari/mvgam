#' Vectorise a stan model's likelihood for quicker computation
#'
#'
#' @export
#' @param model_file Stan model file to be edited
#' @param model_data Prepared mvgam data for Stan modelling
#' @param family \code{character}. Must be either 'Negative Binomial' or 'Poisson'
#' @param trend_model \code{character} specifying the time series dynamics for the latent trend. Options are:
#''None' (no latent trend component; i.e. the GAM component is all that contributes to the linear predictor,
#'and the observation process is the only source of error; similarly to what is estimated by \code{\link[mcgv]{gam}}),
#''RW' (random walk with possible drift),
#''AR1' (AR1 model with intercept),
#''AR2' (AR2 model with intercept) or
#''AR3' (AR3 model with intercept) or
#''GP' (Gaussian process with squared exponential kernel; currently under development and
#'only available for estimation in \code{stan})
#' @param offset \code{logical}
#' @param threads \code{integer} Experimental option to use multithreading for within-chain
#'parallelisation in \code{Stan}. We recommend its use only if you are experienced with
#'\code{Stan}'s `reduce_sum` function and have a slow running model that cannot be sped
#'up by any other means
#' @return A `list` containing the updated Stan model and model data
vectorise_stan_lik = function(model_file, model_data, family = 'Poisson',
                         trend_model = 'None', offset = FALSE,
                         threads = 1){
  if(threads > 1){
    if(family == 'Poisson'){
      if(any(grepl('functions {', model_file, fixed = TRUE))){
        model_file[grep('functions {', model_file, fixed = TRUE)] <-
          paste0('functions {\n',
                 'real partial_log_lik_lpmf(int[] seq, int start, int end,\n',
                 ifelse(offset, 'data int[] Y, matrix X, vector b, vector alpha) {\n',
                        'data int[] Y, matrix X, vector b, real alpha) {\n'),
                 'real ptarget = 0;\n',
                 ifelse(offset,'ptarget += poisson_log_glm_lpmf(Y[start:end] | X[start:end], alpha[start:end], b);\n',
                        'ptarget += poisson_log_glm_lpmf(Y[start:end] | X[start:end], alpha, b);\n'),
                 'return ptarget;\n',
                 '}\n')
      } else {
        model_file[grep('Stan model code', model_file)] <-
          paste0('// Stan model code generated by package mvgam\n',
                 'functions {\n',
                 'real partial_log_lik_lpmf(int[] seq, int start, int end,\n',
                 ifelse(offset, 'data int[] Y, matrix X, vector b, vector alpha) {\n',
                        'data int[] Y, matrix X, vector b, real alpha) {\n'),
                 'real ptarget = 0;\n',
                 ifelse(offset,'ptarget += poisson_log_glm_lpmf(Y[start:end] | X[start:end], alpha[start:end], b);\n',
                        'ptarget += poisson_log_glm_lpmf(Y[start:end] | X[start:end], alpha, b);\n'),
                 'return ptarget;\n',
                 '}\n}\n')
      }
    } else {
      if(any(grepl('functions {', model_file, fixed = TRUE))){
        model_file[grep('functions {', model_file, fixed = TRUE)] <-
          paste0('functions {\n',
                 'real partial_log_lik_lpmf(int[] seq, int start, int end,\n',
                 'data int[] Y, vector mu, real[] phi) {\n',
                 'real ptarget = 0;\n',
                 'ptarget += neg_binomial_2_lpmf(Y[start:end] | mu[start:end],\n',
                 'inv(phi[start:end]));\n',
                 'return ptarget;\n',
                 '}\n')
      } else {
        model_file[grep('Stan model code', model_file)] <-
          paste0('// Stan model code generated by package mvgam\n',
                 'functions {\n',
                 'real partial_log_lik_lpmf(int[] seq, int start, int end,\n',
                 'data int[] Y, vector mu, real[] phi) {\n',
                 'real ptarget = 0;\n',
                 'ptarget += neg_binomial_2_lpmf(Y[start:end] | mu[start:end],\n',
                 'inv(phi[start:end]));\n',
                 'return ptarget;\n',
                 '}\n}')
      }
    }

    model_file <- readLines(textConnection(model_file), n = -1)
  }

  lik_line <- grep('// likelihood functions',
                   model_file, fixed = TRUE)
  model_file <- model_file[-c(lik_line:(lik_line + 6))]

  if(family == 'Poisson'){
    if(threads > 1){
      model_file[lik_line] <- paste0('// likelihood functions\n',
                                     'vector[n_nonmissing] flat_trends;\n',
                                     'flat_trends = (to_vector(trend))[obs_ind];\n',
                                     'target += reduce_sum(partial_log_lik_lpmf, seq,\n',
                                     'grainsize,\n',
                                     'flat_ys,\n',
                                     'append_col(flat_xs, flat_trends),\n',
                                     'append_row(b, 1.0),\n',
                                     ifelse(offset, 'offset[obs_ind]);\n}\n',
                                            '0.0);\n}\n'))
    } else {
      model_file[lik_line] <- paste0('// likelihood functions\n',
                                     'vector[n_nonmissing] flat_trends;\n',
                                     'flat_trends = (to_vector(trend))[obs_ind];\n',
                                     'flat_ys ~ poisson_log_glm(append_col(flat_xs, flat_trends),\n',
                                     ifelse(offset,'offset[obs_ind],', '0.0,'), 'append_row(b, 1.0));\n}\n')
    }

  }
  if(family == 'Negative Binomial'){
    if(threads > 1){
      model_file[lik_line] <- paste0('// likelihood functions\n',
                                     'vector[n_nonmissing] flat_trends;\n',
                                     'real flat_rs[n_nonmissing];\n',
                                     'flat_trends = (to_vector(trend))[obs_ind];\n',
                                     'flat_rs = to_array_1d(rep_each(r_inv, n)[obs_ind]);\n',
                                     'target += reduce_sum(partial_log_lik_lpmf, seq,\n',
                                     'grainsize,\n',
                                     'flat_ys,\n',
                                     ifelse(offset,'exp(append_col(flat_xs, flat_trends) * append_row(b, 1.0)) + offset[obs_ind],\n',
                                            'exp(append_col(flat_xs, flat_trends) * append_row(b, 1.0)),\n'),
                                     'flat_rs);\n}\n')
    } else {
      model_file[lik_line] <- paste0('// likelihood functions\n',
                                     'vector[n_nonmissing] flat_trends;\n',
                                     'real flat_rs[n_nonmissing];\n',
                                     'flat_trends = (to_vector(trend))[obs_ind];\n',
                                     'flat_rs = to_array_1d(rep_each(r_inv, n)[obs_ind]);\n',
                                     'flat_ys ~ neg_binomial_2(\n',
                                     ifelse(offset,'exp(append_col(flat_xs, flat_trends) * append_row(b, 1.0)) + offset[obs_ind],\n',
                                            'exp(append_col(flat_xs, flat_trends) * append_row(b, 1.0)),\n'),
                                     'inv(flat_rs));\n}\n')
    }

    if(any(grepl('functions {', model_file, fixed = TRUE))){
      model_file[grep('functions {', model_file, fixed = TRUE)] <-
        paste0('functions {\n',
               'vector rep_each(vector x, int K) {\n',
               'int N = rows(x);\n',
               'vector[N * K] y;\n',
               'int pos = 1;\n',
               'for (n in 1:N) {\n',
               'for (k in 1:K) {\n',
               'y[pos] = x[n];\n',
               'pos += 1;\n',
               '}\n',
               '}\n',
               'return y;\n',
               '}\n')
    } else {
      model_file[grep('Stan model code', model_file)] <-
        paste0('// Stan model code generated by package mvgam\n',
               'functions {\n',
               'vector rep_each(vector x, int K) {\n',
               'int N = rows(x);\n',
               'vector[N * K] y;\n',
               'int pos = 1;\n',
               'for (n in 1:N) {\n',
               'for (k in 1:K) {\n',
               'y[pos] = x[n];\n',
               'pos += 1;\n',
               '}\n',
               '}\n',
               'return y;\n',
               '}\n}')
    }
    model_file <- readLines(textConnection(model_file), n = -1)
  }

  # Gather the number of nonmissing observations
  model_data$n_nonmissing <- length(which(model_data$y_observed == 1))

  # Grab indices of nonmissing ys and include reduced sets of ys and Xs
  model_data$obs_ind <- which(as.vector(model_data$y_observed) == 1)
  model_data$flat_ys <- as.vector(model_data$y)[which(as.vector(model_data$y_observed) == 1)]
  model_data$X <- t(model_data$X)
  model_data$flat_xs <- as.matrix(model_data$X[as.vector(model_data$ytimes)[model_data$obs_ind],])

  # Add a grainsize integer
  if(threads > 1){
    model_data$seq <- 1:model_data$n_nonmissing
    model_data$grainsize <- max(100, floor(length(as.vector(model_data$y)) / threads))
  }

  # Update the data statement
  obs_line <- grep('int<lower=0, upper=1> y_observed[n, n_series]; // indices of missing vs observed',
                   model_file, fixed = TRUE)
  model_file <- model_file[-c(obs_line:(obs_line + 2))]
  if(threads > 1){
    model_file[obs_line] <- paste0('int<lower=0> n_nonmissing;',
                                   ' // number of nonmissing observations\n',
                                   'int<lower=0> flat_ys[n_nonmissing];',
                                   ' // flattened nonmissing observations\n',
                                   'matrix[n_nonmissing, num_basis] flat_xs;',
                                   ' // X values for nonmissing observations\n',
                                   'int<lower=0> obs_ind[n_nonmissing];',
                                   ' // indices of nonmissing observations\n',
                                   'int<lower=1> grainsize;',
                                   ' // grainsize for reduce_sum threading\n',
                                   'int<lower=1> seq[n_nonmissing];',
                                   ' // an integer sequence for reduce_sum slicing\n',
                                   '}')
  } else {
    model_file[obs_line] <- paste0('int<lower=0> n_nonmissing;',
                                   ' // number of nonmissing observations\n',
                                   'int<lower=0> flat_ys[n_nonmissing];',
                                   ' // flattened nonmissing observations\n',
                                   'matrix[n_nonmissing, num_basis] flat_xs;',
                                   ' // X values for nonmissing observations\n',
                                   'int<lower=0> obs_ind[n_nonmissing];',
                                   ' // indices of nonmissing observations\n',
                                   '}')
  }

  # Some final edits to improve efficiency of the Stan models
  model_file <- gsub('row_vector[num_basis] b_raw;',
                     'vector[num_basis] b_raw;', model_file, fixed = TRUE)
  model_file <- gsub('row_vector[num_basis] b;',
                     'vector[num_basis] b;', model_file, fixed = TRUE)
  model_file <- gsub('matrix[num_basis, total_obs] X; // transposed mgcv GAM design matrix',
                     'matrix[total_obs, num_basis] X; // mgcv GAM design matrix',
                     model_file, fixed = TRUE)
  model_file <- model_file[-(grep('// GAM contribution to expectations (log scale)',
                                  model_file, fixed = TRUE):
                               (grep('// GAM contribution to expectations (log scale)',
                                     model_file, fixed = TRUE) + 5))]

  if(trend_model == 'GP'){
    model_file <- model_file[-(grep('eta = to_vector(b * X);',
                                    model_file, fixed = TRUE))]
    model_file <- model_file[-((grep('mus[1:n, s] = eta[ytimes[1:n, s]] + trend[1:n, s];',
                                    model_file, fixed = TRUE) - 1):
                               (grep('mus[1:n, s] = eta[ytimes[1:n, s]] + trend[1:n, s];',
                                     model_file, fixed = TRUE) + 1))]

  } else {
    model_file <- model_file[-(grep('eta = to_vector(b * X);',
                                    model_file, fixed = TRUE):
                                 (grep('eta = to_vector(b * X);',
                                       model_file, fixed = TRUE) + 4))]
  }

  model_file <- model_file[-((grep('// posterior predictions',
                                   model_file, fixed = TRUE) + 1):
                               (grep('// posterior predictions',
                                     model_file, fixed = TRUE) + 3))]
  model_file[grep('generated quantities {',
                  model_file, fixed = TRUE)] <- paste0('generated quantities {\n',
                                                       'vector[total_obs] eta;\n',
                                                       'matrix[n, n_series] mus;')
  if(family == 'Poisson'){
    model_file[grep('// posterior predictions',
                    model_file, fixed = TRUE)] <- paste0('// posterior predictions\n',
                                                         ifelse(offset, 'eta = X * b + offset;\n',
                                                                'eta = X * b;\n'),
                                                         'for(s in 1:n_series){ \n',
                                                         'mus[1:n, s] = eta[ytimes[1:n, s]] + trend[1:n, s];\n',
                                                         'ypred[1:n, s] = poisson_log_rng(mus[1:n, s]);\n',
                                                         '}')
  } else {
    model_file[grep('// posterior predictions',
                    model_file, fixed = TRUE)] <- paste0('// posterior predictions\n',
                                                         ifelse(offset, 'eta = X * b + offset;\n',
                                                                'eta = X * b;\n'),
                                                         'for(s in 1:n_series){ \n',
                                                         'mus[1:n, s] = eta[ytimes[1:n, s]] + trend[1:n, s];\n',
                                                         'ypred[1:n, s] = neg_binomial_2_rng(exp(mus[1:n, s]), r_vec[1:n, s]);\n',
                                                         '}')
  }

  # Vectorise trend models
  if(trend_model == 'RW'){
    if(any(grepl('// dynamic factor estimates', model_file, fixed = TRUE))){
      init_trend_line <- grep('LV_raw[1, j] ~ normal(0, 0.1)',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'LV_raw[1, 1:n_lv] ~ normal(0, 0.1);'

      remainder_line <- grep('LV_raw[2:n, j] ~ normal(LV_raw[1:(n - 1), j], 0.1)',
                             model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(remainder_line:(remainder_line + 2))]
      model_file[remainder_line] <-
        paste0('for(j in 1:n_lv){\n',
               'LV_raw[2:n, j] ~ normal(LV_raw[1:(n - 1), j], 0.1);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    } else {
      init_trend_line <- grep('trend[1, s] ~ normal(0, sigma[s])',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'trend[1, 1:n_series] ~ normal(0, sigma);'

      remainder_line <- grep('trend[2:n, s] ~ normal(trend[1:(n - 1), s], sigma[s])',
                             model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(remainder_line:(remainder_line + 2))]
      model_file[remainder_line] <-
        paste0('for(s in 1:n_series){\n',
               'trend[2:n, s] ~ normal(trend[1:(n - 1), s], sigma[s]);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    }

  }

  if(trend_model == 'AR1'){
    if(any(grepl('// dynamic factor estimates', model_file, fixed = TRUE))){
      init_trend_line <- grep('LV_raw[1, j] ~ normal(0, 0.1)',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'LV_raw[1, 1:n_lv] ~ normal(0, 0.1);'

      remainder_line <- grep('LV_raw[2:n, j] ~ normal(ar1[j] * LV_raw[1:(n - 1), j], 0.1)',
                             model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(remainder_line:(remainder_line + 2))]
      model_file[remainder_line] <-
        paste0('for(j in 1:n_lv){\n',
               'LV_raw[2:n, j] ~ normal(ar1[j] * LV_raw[1:(n - 1), j], 0.1);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    } else {
      init_trend_line <- grep('trend[1, s] ~ normal(0, sigma[s])',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'trend[1, 1:n_series] ~ normal(0, sigma);'

      remainder_line <- grep('trend[2:n, s] ~ normal(ar1[s] * trend[1:(n - 1), s], sigma[s])',
                             model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(remainder_line:(remainder_line + 2))]
      model_file[remainder_line] <-
        paste0('for(s in 1:n_series){\n',
               'trend[2:n, s] ~ normal(ar1[s] * trend[1:(n - 1), s], sigma[s]);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    }

  }

  if(trend_model == 'AR2'){
    if(any(grepl('// dynamic factor estimates', model_file, fixed = TRUE))){
      init_trend_line <- grep('LV_raw[1, j] ~ normal(0, 0.1)',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'LV_raw[1, 1:n_lv] ~ normal(0, 0.1);'

      second_line <- grep('LV_raw[2, j] ~ normal(LV_raw[1, j] * ar1[j], 0.1)',
                          model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(second_line:(second_line + 2))]
      model_file[second_line] <-
        'LV_raw[2, 1:n_lv] ~ normal(LV_raw[1, 1:n_lv] * ar1, 0.1);'

      remainder_line <- grep('LV_raw[i, j] ~ normal(ar1[j] * LV_raw[i - 1, j] + ar2[j] * LV_raw[i - 2, j]',
                             model_file, fixed = TRUE) - 2
      model_file <- model_file[-c(remainder_line:(remainder_line + 3))]
      model_file[remainder_line] <-
        paste0('for(j in 1:n_lv){\n',
               'LV_raw[3:n, j] ~ normal(ar1[j] * LV_raw[2:(n - 1), j] + ar2[j] * LV_raw[1:(n - 2), j], 0.1);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    } else {
      init_trend_line <- grep('trend[1, s] ~ normal(0, sigma[s])',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'trend[1, 1:n_series] ~ normal(0, sigma);'

      second_line <- grep('trend[2, s] ~ normal(trend[1, s] * ar1[s], sigma[s])',
                          model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(second_line:(second_line + 2))]
      model_file[second_line] <-
        'trend[2, 1:n_series] ~ normal(trend[1, 1:n_series] * ar1, sigma);'

      remainder_line <- grep('trend[i, s] ~ normal(ar1[s] * trend[i - 1, s] + ar2[s] * trend[i - 2, s]',
                             model_file, fixed = TRUE) - 2
      model_file <- model_file[-c(remainder_line:(remainder_line + 3))]
      model_file[remainder_line] <-
        paste0('for(s in 1:n_series){\n',
               'trend[3:n, s] ~ normal(ar1[s] * trend[2:(n - 1), s] + ar2[s] * trend[1:(n - 2), s], sigma[s]);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    }
  }

  if(trend_model == 'AR3'){
    if(any(grepl('// dynamic factor estimates', model_file, fixed = TRUE))){
      init_trend_line <- grep('LV_raw[1, j] ~ normal(0, 0.1)',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'LV_raw[1, 1:n_lv] ~ normal(0, 0.1);'

      second_line <- grep('LV_raw[2, j] ~ normal(LV_raw[1, j] * ar1[j], 0.1)',
                          model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(second_line:(second_line + 2))]
      model_file[second_line] <-
        'LV_raw[2, 1:n_lv] ~ normal(LV_raw[1, 1:n_lv] * ar1, 0.1);'

      third_line <- grep('LV_raw[3, j] ~ normal(LV_raw[2, j] * ar1[j] + LV_raw[1, j] * ar2[j]',
                         model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(third_line:(third_line + 2))]
      model_file[third_line] <-
        'LV_raw[3, 1:n_lv] ~ normal(LV_raw[2, 1:n_lv] * ar1 + LV_raw[1, 1:n_lv] * ar2, 0.1);'

      remainder_line <- grep('LV_raw[i, j] ~ normal(ar1[j] * LV_raw[i - 1, j] + ar2[j] * LV_raw[i - 2, j] + ar3[j] * LV_raw[i - 3, j]',
                             model_file, fixed = TRUE) - 2
      model_file <- model_file[-c(remainder_line:(remainder_line + 3))]
      model_file[remainder_line] <-
        paste0('for(j in 1:n_lv){\n',
               'LV_raw[4:n, j] ~ normal(ar1[j] * LV_raw[3:(n - 1), j] + ar2[j] * LV_raw[2:(n - 2), j] + ar3[j] * LV_raw[1:(n - 3), j], 0.1);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    } else {
      init_trend_line <- grep('trend[1, s] ~ normal(0, sigma[s])',
                              model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(init_trend_line:(init_trend_line + 2))]
      model_file[init_trend_line] <-
        'trend[1, 1:n_series] ~ normal(0, sigma);'

      second_line <- grep('trend[2, s] ~ normal(trend[1, s] * ar1[s], sigma[s])',
                          model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(second_line:(second_line + 2))]
      model_file[second_line] <-
        'trend[2, 1:n_series] ~ normal(trend[1, 1:n_series] * ar1, sigma);'

      third_line <- grep('trend[3, s] ~ normal(trend[2, s] * ar1[s] + trend[1, s] * ar2[s]',
                         model_file, fixed = TRUE) - 1
      model_file <- model_file[-c(third_line:(third_line + 2))]
      model_file[third_line] <-
        'trend[3, 1:n_series] ~ normal(trend[2, 1:n_series] * ar1 + trend[1, 1:n_series] * ar2, sigma);'

      remainder_line <- grep('trend[i, s] ~ normal(ar1[s] * trend[i - 1, s] + ar2[s] * trend[i - 2, s] + ar3[s] * trend[i - 3, s]',
                             model_file, fixed = TRUE) - 2
      model_file <- model_file[-c(remainder_line:(remainder_line + 3))]
      model_file[remainder_line] <-
        paste0('for(s in 1:n_series){\n',
               'trend[4:n, s] ~ normal(ar1[s] * trend[3:(n - 1), s] + ar2[s] * trend[2:(n - 2), s] + ar3[s] * trend[1:(n - 3), s], sigma[s]);\n',
               '}')
      model_file = readLines(textConnection(model_file), n = -1)
    }
  }

  # Clean to remove trend components if this is a 'None' trend model
  if(trend_model == 'None'){
    model_file = readLines(textConnection(model_file), n = -1)
    model_file <- gsub(' + trend[1:n, s]', '', model_file, fixed = TRUE)
    model_file <- gsub('exp(append_col(flat_xs, flat_trends)',
                       'exp(flat_xs', model_file, fixed = TRUE)
    model_file <- gsub('append_col(flat_xs, flat_trends)',
                       'flat_xs', model_file, fixed = TRUE)
    model_file <- gsub('append_row(b, 1.0)', 'b', model_file, fixed = TRUE)
    model_file <- model_file[-grep('vector[n_nonmissing] flat_trends;',
                                   model_file, fixed = TRUE)]
    model_file <- model_file[-grep('flat_trends = (to_vector(trend))[obs_ind];',
                                   model_file, fixed = TRUE)]
  }

  # Tidying the representation
  if(any(grepl('functions {', model_file, fixed = TRUE))){
    model_file <- model_file[-(grep('// Stan model code generated by package mvgam',
                                    model_file, fixed = TRUE))]
    model_file[grep('functions {', model_file, fixed = TRUE)] <-
      paste0('// Stan model code generated by package mvgam\n',
             'functions {')
  }

  return(list(model_file = readLines(textConnection(model_file), n = -1),
              model_data = model_data))
}
