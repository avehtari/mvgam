<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="mvgam">
<title>Overview of the mvgam package • mvgam</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Overview of the mvgam package">
<meta property="og:description" content="mvgam">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">mvgam</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.6</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/data_in_mvgam.html">Formatting data for use in mvgam</a>
    <a class="dropdown-item" href="../articles/forecast_evaluation.html">Forecasting and forecast evaluation in mvgam</a>
    <a class="dropdown-item" href="../articles/mvgam_overview.html">Overview of the mvgam package</a>
    <a class="dropdown-item" href="../articles/shared_states.html">Shared latent states in mvgam</a>
    <a class="dropdown-item" href="../articles/time_varying_effects.html">Time-varying effects in mvgam</a>
    <a class="dropdown-item" href="../articles/trend_formulas.html">State-Space models in mvgam</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/nicholasjclark/mvgam/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Overview of the mvgam package</h1>
                        <h4 data-toc-skip class="author">Nicholas J
Clark</h4>
            
            <h4 data-toc-skip class="date">2023-11-01</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/nicholasjclark/mvgam/blob/HEAD/vignettes/mvgam_overview.Rmd" class="external-link"><code>vignettes/mvgam_overview.Rmd</code></a></small>
      <div class="d-none name"><code>mvgam_overview.Rmd</code></div>
    </div>

    
    
<p>The purpose of this vignette is to give a general overview of the
<code>mvgam</code> package and its primary functions.</p>
<div class="section level2">
<h2 id="dynamic-gams">Dynamic GAMs<a class="anchor" aria-label="anchor" href="#dynamic-gams"></a>
</h2>
<p>Briefly, assume <span class="math inline">\(\tilde{\boldsymbol{y}}_{t}\)</span> is the
conditional expectation of a response variable <span class="math inline">\(\boldsymbol{y}\)</span> at time <span class="math inline">\(\boldsymbol{t}\)</span>. Assuming <span class="math inline">\(\boldsymbol{y}\)</span> is drawn from an
exponential distribution with an invertible link function, the linear
predictor for a Dynamic GAM is written as:</p>
<p><span class="math display">\[g(\tilde{\boldsymbol{y}}_{t})=\alpha+\sum\limits_{i=1}^I\boldsymbol{s}_{i,t}\boldsymbol{x}_{i,t}+\boldsymbol{z}_{t}\,,\]</span></p>
<p>Here <span class="math inline">\(\alpha\)</span> is the unknown
intercept, the <span class="math inline">\(\boldsymbol{s}\)</span>’s are
unknown smooth functions of covariates (<span class="math inline">\(\boldsymbol{x}\)</span>’s) and <span class="math inline">\(\boldsymbol{z}\)</span> is a dynamic latent trend.
Each smooth function <span class="math inline">\(\boldsymbol{s}_{i}\)</span> is composed of basis
expansions whose coefficients, which must be estimated, control the
functional relationship between <span class="math inline">\(\boldsymbol{x}_{i}\)</span> and <span class="math inline">\(log(\tilde{\boldsymbol{y}})\)</span>. The size of
the basis expansion limits the smooth’s potential complexity. A larger
set of basis functions allows greater flexibility. Several advantages of
GAMs are that they can model a diversity of response families, including
discrete distributions (i.e. Poisson, Negative Binomial,
Tweedie-Poisson) that accommodate common ecological features such as
zero-inflation or overdispersion, and that they can be formulated to
include hierarchical smoothing for multivariate responses. For the
dynamic component, in its most basic form we assume a random walk with
drift:</p>
<p><span class="math display">\[\boldsymbol{z}_{t}=\phi+\boldsymbol{z}_{t-1}+\boldsymbol{e}_{t}\,,\]</span></p>
<p>where <span class="math inline">\(\phi\)</span> is an optional drift
parameter (if the latent trend is assumed to not be stationary) and
<span class="math inline">\(\boldsymbol{e}\)</span> is drawn from a
zero-centred Gaussian distribution. This model is easily modified to
include autoregressive terms, which <code>mvgam</code> accomodates up to
<code>order = 3</code>. There are many other types of models that can be
handled in <code>mvgam</code>, but this overview will just introduce a
few of them.</p>
</div>
<div class="section level2">
<h2 id="example-time-series-data">Example time series data<a class="anchor" aria-label="anchor" href="#example-time-series-data"></a>
</h2>
<p>The ‘portal_data’ object contains time series of rodent captures from
the Portal Project, <a href="https://portal.weecology.org/" target="_blank" class="external-link">a long-term monitoring study based near the town of
Portal, Arizona</a>. Researchers have been operating a standardized set
of baited traps within 24 experimental plots at this site since the
1970’s. Sampling follows the lunar monthly cycle, with observations
occurring on average about 28 days apart. However, missing observations
do occur due to difficulties accessing the site (weather events, COVID
disruptions etc..). You can read about the full sampling protocol <a href="https://www.biorxiv.org/content/10.1101/332783v3.full" target="_blank" class="external-link">in this preprint by Ernest et al on the Biorxiv</a>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"portal_data"</span><span class="op">)</span></span></code></pre></div>
<p>As the data come pre-loaded with the <code>mvgam</code> package, you
can read a little about it in the help page using
<code><a href="../reference/portal_data.html">?portal_data</a></code>. Before working with data, it is important to
inspect how the data are structured, first using <code>head</code>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">portal_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   moon DM DO PP OT year month mintemp precipitation     ndvi</span></span>
<span><span class="co">## 1  329 10  6  0  2 2004     1  -9.710          37.8 1.465889</span></span>
<span><span class="co">## 2  330 14  8  1  0 2004     2  -5.924           8.7 1.558507</span></span>
<span><span class="co">## 3  331  9  1  2  1 2004     3  -0.220          43.5 1.337817</span></span>
<span><span class="co">## 4  332 NA NA NA NA 2004     4   1.931          23.9 1.658913</span></span>
<span><span class="co">## 5  333 15  8 10  1 2004     5   6.568           0.9 1.853656</span></span>
<span><span class="co">## 6  334 NA NA NA NA 2004     6  11.590           1.4 1.761330</span></span></code></pre>
<p>But the <code>glimpse</code> function in <code>dplyr</code> is also
useful for understanding how variables are structured</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">portal_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Rows: 199</span></span>
<span><span class="co">## Columns: 10</span></span>
<span><span class="co">## $ moon          <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 3…</span></span>
<span><span class="co">## $ DM            <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 10, 14, 9, NA, 15, NA, NA, 9, 5, 8, NA, 14, 7, NA, NA, 9…</span></span>
<span><span class="co">## $ DO            <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 6, 8, 1, NA, 8, NA, NA, 3, 3, 4, NA, 3, 8, NA, NA, 3, NA…</span></span>
<span><span class="co">## $ PP            <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 0, 1, 2, NA, 10, NA, NA, 16, 18, 12, NA, 3, 2, NA, NA, 1…</span></span>
<span><span class="co">## $ OT            <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 2, 0, 1, NA, 1, NA, NA, 1, 0, 0, NA, 2, 1, NA, NA, 1, NA…</span></span>
<span><span class="co">## $ year          <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 20…</span></span>
<span><span class="co">## $ month         <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6,…</span></span>
<span><span class="co">## $ mintemp       <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> -9.710, -5.924, -0.220, 1.931, 6.568, 11.590, 14.370, 16…</span></span>
<span><span class="co">## $ precipitation <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 37.8, 8.7, 43.5, 23.9, 0.9, 1.4, 20.3, 91.0, 60.5, 25.2,…</span></span>
<span><span class="co">## $ ndvi          <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.4658889, 1.5585069, 1.3378172, 1.6589129, 1.8536561, 1…</span></span></code></pre>
<p>We will focus analyses on the time series of captures for one
specific rodent species, the Desert Pocket Mouse <em>Chaetodipus
penicillatus</em>. This species is interesting in that it goes into a
kind of “hibernation” during the colder months, leading to very low
captures during the winter period</p>
</div>
<div class="section level2">
<h2 id="manipulating-data-for-modelling">Manipulating data for modelling<a class="anchor" aria-label="anchor" href="#manipulating-data-for-modelling"></a>
</h2>
<p>Manipulating the data into a ‘long’ format is necessary for modelling
in <code>mvgam</code>. By ‘long’ format, we mean that each
<code>series x time</code> observation needs to have its own entry in
the <code>dataframe</code> or <code>list</code> object that we wish to
use as data for modelling. A simple example can be viewed by simulating
data using the <code>sim_mvgam</code> function. See
<code><a href="../reference/sim_mvgam.html">?sim_mvgam</a></code> for more details</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sim_mvgam.html">sim_mvgam</a></span><span class="op">(</span>n_series <span class="op">=</span> <span class="fl">4</span>, T <span class="op">=</span> <span class="fl">24</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">data_train</span>, <span class="fl">12</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    y season year   series time</span></span>
<span><span class="co">## 1  3      1    1 series_1    1</span></span>
<span><span class="co">## 2  0      1    1 series_2    1</span></span>
<span><span class="co">## 3  2      1    1 series_3    1</span></span>
<span><span class="co">## 4  1      1    1 series_4    1</span></span>
<span><span class="co">## 5  3      2    1 series_1    2</span></span>
<span><span class="co">## 6  1      2    1 series_2    2</span></span>
<span><span class="co">## 7  1      2    1 series_3    2</span></span>
<span><span class="co">## 8  3      2    1 series_4    2</span></span>
<span><span class="co">## 9  0      3    1 series_1    3</span></span>
<span><span class="co">## 10 0      3    1 series_2    3</span></span>
<span><span class="co">## 11 0      3    1 series_3    3</span></span>
<span><span class="co">## 12 0      3    1 series_4    3</span></span></code></pre>
<p>Notice how we have four different time series in these simulated
data, but we do not spread the outcome values into different columns.
Rather, there is only a single column for the outcome variable, labelled
<code>y</code> in these simulated data. We also must supply a variable
labelled <code>time</code> to ensure the modelling software knows how to
arrange the time series when building models. This setup still allows us
to formulate multivariate time series models, as you can see in the <a href="https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html">State-Space
vignette</a>. Below are the steps needed to shape our
<code>portal_data</code> object into the correct form. First, we create
a <code>time</code> variable, select the column representing counts of
our target species (<code>PP</code>), and select appropriate variables
that we can use as predictors</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">portal_data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  </span>
<span>  <span class="co"># mvgam requires a 'time' variable be present in the data to index</span></span>
<span>  <span class="co"># the temporal observations. This is especially important when tracking </span></span>
<span>  <span class="co"># multiple time series. In the Portal data, the 'moon' variable indexes the</span></span>
<span>  <span class="co"># lunar monthly timestep of the trapping sessions</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>time <span class="op">=</span> <span class="va">moon</span> <span class="op">-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">moon</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  </span>
<span>  <span class="co"># We can also provide a more informative name for the outcome variable, which </span></span>
<span>  <span class="co"># is counts of the 'PP' species (Chaetodipus penicillatus) across all control</span></span>
<span>  <span class="co"># plots</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>count <span class="op">=</span> <span class="va">PP</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  </span>
<span>  <span class="co"># The other requirement for mvgam is a 'series' variable, which needs to be a</span></span>
<span>  <span class="co"># factor variable to index which time series each row in the data belongs to.</span></span>
<span>  <span class="co"># Again, this is more useful when you have multiple time series in the data</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>series <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="st">'PP'</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  </span>
<span>  <span class="co"># Select the variables of interest to keep in the model_data</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">series</span>, <span class="va">year</span>, <span class="va">time</span>, <span class="va">count</span>, <span class="va">mintemp</span>, <span class="va">ndvi</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">model_data</span></span></code></pre></div>
<p>The data now contain six variables:<br><code>series</code>, a factor indexing which time series each
observation belongs to<br><code>year</code>, the year of sampling<br><code>time</code>, the indicator of which time step each observation
belongs to<br><code>count</code>, the response variable representing the number of
captures of the species <code>PP</code> in each sampling
observation<br><code>mintemp</code>, the monthly average minimum temperature at each
time step<br><code>ndvi</code>, the monthly average Normalized Difference Vegetation
Index at each time step</p>
<p>Now check the data structure again</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">model_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   series year time count mintemp     ndvi</span></span>
<span><span class="co">## 1     PP 2004    1     0  -9.710 1.465889</span></span>
<span><span class="co">## 2     PP 2004    2     1  -5.924 1.558507</span></span>
<span><span class="co">## 3     PP 2004    3     2  -0.220 1.337817</span></span>
<span><span class="co">## 4     PP 2004    4    NA   1.931 1.658913</span></span>
<span><span class="co">## 5     PP 2004    5    10   6.568 1.853656</span></span>
<span><span class="co">## 6     PP 2004    6    NA  11.590 1.761330</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">model_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Rows: 199</span></span>
<span><span class="co">## Columns: 6</span></span>
<span><span class="co">## $ series  <span style="color: #949494; font-style: italic;">&lt;fct&gt;</span> PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP…</span></span>
<span><span class="co">## $ year    <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 20…</span></span>
<span><span class="co">## $ time    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…</span></span>
<span><span class="co">## $ count   <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 0, 1, 2, NA, 10, NA, NA, 16, 18, 12, NA, 3, 2, NA, NA, 13, NA,…</span></span>
<span><span class="co">## $ mintemp <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> -9.710, -5.924, -0.220, 1.931, 6.568, 11.590, 14.370, 16.520, …</span></span>
<span><span class="co">## $ ndvi    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.4658889, 1.5585069, 1.3378172, 1.6589129, 1.8536561, 1.76132…</span></span></code></pre>
<p>You can also summarize multiple variables, which is helpful to search
for data ranges and identify missing values</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  series        year           time           count          mintemp       </span></span>
<span><span class="co">##  PP:199   Min.   :2004   Min.   :  1.0   Min.   : 0.00   Min.   :-24.000  </span></span>
<span><span class="co">##           1st Qu.:2008   1st Qu.: 50.5   1st Qu.: 2.50   1st Qu.: -3.884  </span></span>
<span><span class="co">##           Median :2012   Median :100.0   Median :12.00   Median :  2.130  </span></span>
<span><span class="co">##           Mean   :2012   Mean   :100.0   Mean   :15.14   Mean   :  3.504  </span></span>
<span><span class="co">##           3rd Qu.:2016   3rd Qu.:149.5   3rd Qu.:24.00   3rd Qu.: 12.310  </span></span>
<span><span class="co">##           Max.   :2020   Max.   :199.0   Max.   :65.00   Max.   : 18.140  </span></span>
<span><span class="co">##                                          NA's   :36                       </span></span>
<span><span class="co">##       ndvi       </span></span>
<span><span class="co">##  Min.   :0.2817  </span></span>
<span><span class="co">##  1st Qu.:1.0741  </span></span>
<span><span class="co">##  Median :1.3501  </span></span>
<span><span class="co">##  Mean   :1.4709  </span></span>
<span><span class="co">##  3rd Qu.:1.8178  </span></span>
<span><span class="co">##  Max.   :3.9126  </span></span>
<span><span class="co">## </span></span></code></pre>
<p>We have some <code>NA</code>s in our response variable
<code>count</code>. Let’s visualize the data as a heatmap to get a sense
of where these are distributed (<code>NA</code>s are shown as red bars
in the below plot)</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/image.html" class="external-link">image</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">model_data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>                <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html" class="external-link">arrange</a></span><span class="op">(</span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html" class="external-link">desc</a></span><span class="op">(</span><span class="va">time</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, axes <span class="op">=</span> <span class="cn">F</span>,</span>
<span>      col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">'grey80'</span>, <span class="st">'darkred'</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html" class="external-link">axis</a></span><span class="op">(</span><span class="fl">3</span>, at <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>, len <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NCOL</a></span><span class="op">(</span><span class="va">model_data</span><span class="op">)</span><span class="op">)</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">model_data</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-5-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>These observations will generally be thrown out by most modelling
packages in . But as you will see when we work through the tutorials,
<code>mvgam</code> keeps these in the data so that predictions can be
automatically returned for the full dataset. The time series and some of
its descriptive features can be plotted using
<code><a href="../reference/plot_mvgam_series.html">plot_mvgam_series()</a></code>:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_mvgam_series.html">plot_mvgam_series</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">model_data</span>, series <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="st">'count'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-6-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="glms-with-temporal-random-effects">GLMs with temporal random effects<a class="anchor" aria-label="anchor" href="#glms-with-temporal-random-effects"></a>
</h2>
<p>Our first task will be to fit a Generalized Linear Model (GLM) that
can adequately capture the features of our <code>count</code>
observations (integer data, lower bound at zero, missing values) while
also attempting to model temporal variation. We are almost ready to fit
our first model, which will be a GLM with Poisson observations, a log
link function and random (hierarchical) intercepts for
<code>year</code>. This will allow us to capture our prior belief that,
although each year is unique, having been sampled from the same
population of effects, all years are connected and thus might contain
valuable information about one another. This will be done by
capitalizing on the partial pooling properties of hierarchical models.
Hierarchical (also known as random) effects offer many advantages when
modelling data with grouping structures (i.e. multiple species,
locations, years etc…). The ability to incorporate these in time series
models is a huge advantage over traditional models such as ARIMA or
Exponential Smoothing. But before we fit the model, we will need to
convert <code>year</code> to a factor so that we can use a random effect
basis in <code>mvgam</code>. See <code>?smooth.terms</code> and
<code>?smooth.construct.re.smooth.spec</code> for details about the
<code>re</code> basis construction that is used by both
<code>mvgam</code> and <code>mgcv</code></p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  </span>
<span>  <span class="co"># Create a 'year_fac' factor version of 'year'</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>year_fac <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">year</span><span class="op">)</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">model_data</span></span></code></pre></div>
<p>Preview the dataset to ensure year is now a factor with a unique
factor level for each year in the data</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">model_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Rows: 199</span></span>
<span><span class="co">## Columns: 7</span></span>
<span><span class="co">## $ series   <span style="color: #949494; font-style: italic;">&lt;fct&gt;</span> PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, P…</span></span>
<span><span class="co">## $ year     <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2…</span></span>
<span><span class="co">## $ time     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…</span></span>
<span><span class="co">## $ count    <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> 0, 1, 2, NA, 10, NA, NA, 16, 18, 12, NA, 3, 2, NA, NA, 13, NA…</span></span>
<span><span class="co">## $ mintemp  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> -9.710, -5.924, -0.220, 1.931, 6.568, 11.590, 14.370, 16.520,…</span></span>
<span><span class="co">## $ ndvi     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.4658889, 1.5585069, 1.3378172, 1.6589129, 1.8536561, 1.7613…</span></span>
<span><span class="co">## $ year_fac <span style="color: #949494; font-style: italic;">&lt;fct&gt;</span> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2…</span></span></code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/levels.html" class="external-link">levels</a></span><span class="op">(</span><span class="va">model_data</span><span class="op">$</span><span class="va">year_fac</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  [1] "2004" "2005" "2006" "2007" "2008" "2009" "2010" "2011" "2012" "2013"</span></span>
<span><span class="co">## [11] "2014" "2015" "2016" "2017" "2018" "2019" "2020"</span></span></code></pre>
<p>We are now ready for our first <code>mvgam</code> model. The syntax
will be familiar to users who have previously built models with
<code>mgcv</code>. But for a refresher, see <code>?formula.gam</code>
and the examples in <code>?gam</code>. Random effects can be specified
using the <code>s</code> wrapper with the <code>re</code> basis. Note
that we can also suppress the primary intercept using the usual
<code>R</code> formula syntax <code>- 1</code>. <code>mvgam</code> has a
number of possible observation families that can be used, see
<code><a href="../reference/mvgam_families.html">?mvgam_families</a></code> for more information. We will use
<code>Stan</code> as the fitting engine, which deploys Hamiltonian Monte
Carlo (HMC) for full Bayesian inference. By default, 4 HMC chains will
be run using a warmup of 500 iterations and collecting 500 posterior
samples from each chain. The package will also aim to use the
<code>Cmdstan</code> backend when possible, so it is recommended that
users have an up-to-date installation of <code>Cmdstan</code> and the
associated <code>cmdstanr</code> interface on their machines (note that
you can set the backend yourself using the <code>backend</code>
argument: see <code><a href="../reference/mvgam.html">?mvgam</a></code> for details). Interested users should
consult the <a href="https://mc-stan.org/docs/stan-users-guide/index.html" target="_blank" class="external-link"><code>Stan</code> user’s guide</a> for more information
about the software and the enormous variety of models that can be
tackled with HMC.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvgam.html">mvgam</a></span><span class="op">(</span><span class="va">count</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">year_fac</span>, bs <span class="op">=</span> <span class="st">'re'</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span>,</span>
<span>                family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>                data <span class="op">=</span> <span class="va">model_data</span><span class="op">)</span></span></code></pre></div>
<p>The model can be described mathematically for each timepoint <span class="math inline">\(t\)</span> as follows: <span class="math display">\[\begin{align*}
\boldsymbol{count}_t &amp; \sim \text{Poisson}(\lambda_t) \\
log(\lambda_t) &amp; = \beta_{year[year_t]} \\
\beta_{year} &amp; \sim \text{Normal}(\mu_{year}, \sigma_{year})
\end{align*}\]</span></p>
<p>Where the <span class="math inline">\(\beta_{year}\)</span> effects
are drawn from a <em>population</em> distribution that is parameterized
by a common mean <span class="math inline">\((\mu_{year})\)</span> and
variance <span class="math inline">\((\sigma_{year})\)</span>. Priors on
most of the model parameters can be interrogated and changed using
similar functionality to the options available in <code>brms</code>. For
example, the default priors on <span class="math inline">\((\mu_{year})\)</span> and <span class="math inline">\((\sigma_{year})\)</span> can be viewed using the
following code:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_mvgam_priors.html">get_mvgam_priors</a></span><span class="op">(</span><span class="va">count</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">year_fac</span>, bs <span class="op">=</span> <span class="st">'re'</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span>,</span>
<span>                 family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>                 data <span class="op">=</span> <span class="va">model_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                      param_name param_length           param_info</span></span>
<span><span class="co">## 1             vector[1] mu_raw;            1 s(year_fac) pop mean</span></span>
<span><span class="co">## 2 vector&lt;lower=0&gt;[1] sigma_raw;            1   s(year_fac) pop sd</span></span>
<span><span class="co">##                               prior                 example_change</span></span>
<span><span class="co">## 1            mu_raw ~ std_normal();   mu_raw ~ normal(-0.86, 0.1);</span></span>
<span><span class="co">## 2 sigma_raw ~ student_t(3, 0, 2.5); sigma_raw ~ exponential(0.15);</span></span>
<span><span class="co">##   new_lowerbound new_upperbound</span></span>
<span><span class="co">## 1             NA             NA</span></span>
<span><span class="co">## 2             NA             NA</span></span></code></pre>
<p>See examples in <code><a href="../reference/get_mvgam_priors.html">?get_mvgam_priors</a></code> to find out different
ways that priors can be altered. Once the model has finished, the first
step is to inspect the <code>summary</code> to ensure no major
diagnostic warnings have been produced and to quickly summarise
posterior distributions for key parameters</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## GAM formula:</span></span>
<span><span class="co">## count ~ s(year_fac, bs = "re") - 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Family:</span></span>
<span><span class="co">## poisson</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Link function:</span></span>
<span><span class="co">## log</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Trend model:</span></span>
<span><span class="co">## None</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N series:</span></span>
<span><span class="co">## 1 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N timepoints:</span></span>
<span><span class="co">## 199 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Status:</span></span>
<span><span class="co">## Fitted using Stan </span></span>
<span><span class="co">## 4 chains, each with iter = 1000; warmup = 500; thin = 1 </span></span>
<span><span class="co">## Total post-warmup draws = 2000</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## GAM coefficient (beta) estimates:</span></span>
<span><span class="co">##                 2.5% 50% 97.5% Rhat n_eff</span></span>
<span><span class="co">## s(year_fac).1   1.80 2.1   2.3 1.00  2415</span></span>
<span><span class="co">## s(year_fac).2   2.50 2.7   2.8 1.00  2461</span></span>
<span><span class="co">## s(year_fac).3   3.00 3.1   3.2 1.00  2815</span></span>
<span><span class="co">## s(year_fac).4   3.10 3.3   3.4 1.00  2724</span></span>
<span><span class="co">## s(year_fac).5   1.90 2.1   2.3 1.00  2684</span></span>
<span><span class="co">## s(year_fac).6   1.50 1.8   2.0 1.00  2229</span></span>
<span><span class="co">## s(year_fac).7   1.80 2.0   2.3 1.00  2510</span></span>
<span><span class="co">## s(year_fac).8   2.80 3.0   3.1 1.00  3404</span></span>
<span><span class="co">## s(year_fac).9   3.10 3.3   3.4 1.00  2493</span></span>
<span><span class="co">## s(year_fac).10  2.60 2.8   2.9 1.00  2898</span></span>
<span><span class="co">## s(year_fac).11  3.00 3.1   3.2 1.00  2666</span></span>
<span><span class="co">## s(year_fac).12  3.10 3.2   3.3 1.00  2774</span></span>
<span><span class="co">## s(year_fac).13  2.00 2.2   2.4 1.00  2801</span></span>
<span><span class="co">## s(year_fac).14  2.50 2.6   2.8 1.00  3007</span></span>
<span><span class="co">## s(year_fac).15  1.90 2.2   2.4 1.00  2587</span></span>
<span><span class="co">## s(year_fac).16  1.90 2.1   2.3 1.00  2996</span></span>
<span><span class="co">## s(year_fac).17 -0.34 1.0   1.9 1.01   499</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## GAM group-level estimates:</span></span>
<span><span class="co">##                2.5%  50% 97.5% Rhat n_eff</span></span>
<span><span class="co">## mean(year_fac) 2.10 2.40   2.7 1.01   268</span></span>
<span><span class="co">## sd(year_fac)   0.46 0.69   1.1 1.02   245</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Approximate significance of GAM observation smooths:</span></span>
<span><span class="co">##              edf Chi.sq p-value    </span></span>
<span><span class="co">## s(year_fac) 13.6  22934  &lt;2e-16 ***</span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Stan MCMC diagnostics:</span></span>
<span><span class="co">## n_eff / iter looks reasonable for all parameters</span></span>
<span><span class="co">## Rhat looks reasonable for all parameters</span></span>
<span><span class="co">## 0 of 2000 iterations ended with a divergence (0%)</span></span>
<span><span class="co">## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%)</span></span>
<span><span class="co">## E-FMI indicated no pathological behavior</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Samples were drawn using NUTS(diag_e) at Wed Nov 01 1:34:47 PM 2023.</span></span>
<span><span class="co">## For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">## and Rhat is the potential scale reduction factor on split MCMC chains</span></span>
<span><span class="co">## (at convergence, Rhat = 1)</span></span></code></pre>
<p>The diagnostic messages at the bottom of the summary show that the
HMC sampler did not encounter any problems or difficult posterior
spaces. This is a good sign. Posterior distributions for model
parameters can be extracted in any way that an object of class
<code>brmsfit</code> can (see <code><a href="../reference/mvgam_draws.html">?mvgam::mvgam_draws</a></code> for
details). For example, we can extract the coefficients related to the
GAM linear predictor (i.e. the <span class="math inline">\(\beta\)</span>’s) into a <code>data.frame</code>
using:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beta_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">model1</span>, variable <span class="op">=</span> <span class="st">'betas'</span><span class="op">)</span></span>
<span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">beta_post</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Rows: 2,000</span></span>
<span><span class="co">## Columns: 17</span></span>
<span><span class="co">## $ `s(year_fac).1`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.12741, 2.06172, 2.26520, 1.87120, 2.11356, 2.02281,…</span></span>
<span><span class="co">## $ `s(year_fac).2`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.70976, 2.65610, 2.80059, 2.57470, 2.62080, 2.64143,…</span></span>
<span><span class="co">## $ `s(year_fac).3`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 3.21372, 2.99190, 3.15631, 3.06638, 3.25373, 3.05804,…</span></span>
<span><span class="co">## $ `s(year_fac).4`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 3.35741, 3.27654, 3.24237, 3.36924, 3.16718, 3.29427,…</span></span>
<span><span class="co">## $ `s(year_fac).5`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.00693, 2.13077, 2.22059, 1.97835, 2.23718, 2.18988,…</span></span>
<span><span class="co">## $ `s(year_fac).6`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.95859, 1.94173, 1.69621, 1.84471, 1.88843, 2.02054,…</span></span>
<span><span class="co">## $ `s(year_fac).7`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.00779, 1.98562, 2.02139, 1.99735, 2.29102, 2.01331,…</span></span>
<span><span class="co">## $ `s(year_fac).8`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 3.00082, 3.00869, 2.94693, 3.01746, 2.94800, 2.90384,…</span></span>
<span><span class="co">## $ `s(year_fac).9`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 3.29098, 3.26173, 3.23145, 3.12494, 3.28167, 3.11192,…</span></span>
<span><span class="co">## $ `s(year_fac).10` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.81306, 2.74364, 2.76800, 2.69343, 2.64693, 2.76191,…</span></span>
<span><span class="co">## $ `s(year_fac).11` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.97452, 3.19016, 3.02230, 3.06157, 3.06382, 3.01307,…</span></span>
<span><span class="co">## $ `s(year_fac).12` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 3.24826, 3.19209, 3.23930, 3.34408, 3.16023, 3.16357,…</span></span>
<span><span class="co">## $ `s(year_fac).13` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.24956, 2.25044, 2.26586, 2.30196, 2.20031, 2.45340,…</span></span>
<span><span class="co">## $ `s(year_fac).14` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.78322, 2.65942, 2.56753, 2.78219, 2.76498, 2.63267,…</span></span>
<span><span class="co">## $ `s(year_fac).15` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.01670, 2.03438, 2.29317, 2.04276, 2.30141, 2.24028,…</span></span>
<span><span class="co">## $ `s(year_fac).16` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.98938, 2.13250, 2.19084, 1.95541, 2.18875, 2.18327,…</span></span>
<span><span class="co">## $ `s(year_fac).17` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.0242100, 1.1238100, 1.3669000, 1.7130500, 1.5115200…</span></span></code></pre>
<p>With any model fitted in <code>mvgam</code>, the underlying
<code>Stan</code> code can be viewed using the <code>code</code>
function:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/code.html">code</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## // Stan model code generated by package mvgam</span></span>
<span><span class="co">## data {</span></span>
<span><span class="co">##   int&lt;lower=0&gt; total_obs; // total number of observations</span></span>
<span><span class="co">##   int&lt;lower=0&gt; n; // number of timepoints per series</span></span>
<span><span class="co">##   int&lt;lower=0&gt; n_series; // number of series</span></span>
<span><span class="co">##   int&lt;lower=0&gt; num_basis; // total number of basis coefficients</span></span>
<span><span class="co">##   matrix[total_obs, num_basis] X; // mgcv GAM design matrix</span></span>
<span><span class="co">##   array[n, n_series] int&lt;lower=0&gt; ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?)</span></span>
<span><span class="co">##   int&lt;lower=0&gt; n_nonmissing; // number of nonmissing observations</span></span>
<span><span class="co">##   array[n_nonmissing] int&lt;lower=0&gt; flat_ys; // flattened nonmissing observations</span></span>
<span><span class="co">##   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations</span></span>
<span><span class="co">##   array[n_nonmissing] int&lt;lower=0&gt; obs_ind; // indices of nonmissing observations</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## parameters {</span></span>
<span><span class="co">##   // raw basis coefficients</span></span>
<span><span class="co">##   vector[num_basis] b_raw;</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // random effect variances</span></span>
<span><span class="co">##   vector&lt;lower=0&gt;[1] sigma_raw;</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // random effect means</span></span>
<span><span class="co">##   vector[1] mu_raw;</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## transformed parameters {</span></span>
<span><span class="co">##   // basis coefficients</span></span>
<span><span class="co">##   vector[num_basis] b;</span></span>
<span><span class="co">##   b[1 : 17] = mu_raw[1] + b_raw[1 : 17] * sigma_raw[1];</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## model {</span></span>
<span><span class="co">##   // prior for random effect population variances</span></span>
<span><span class="co">##   sigma_raw ~ student_t(3, 0, 2.5);</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // prior for random effect population means</span></span>
<span><span class="co">##   mu_raw ~ std_normal();</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // prior (non-centred) for s(year_fac)...</span></span>
<span><span class="co">##   b_raw[1 : 17] ~ std_normal();</span></span>
<span><span class="co">##   {</span></span>
<span><span class="co">##     // likelihood functions</span></span>
<span><span class="co">##     flat_ys ~ poisson_log_glm(flat_xs, 0.0, b);</span></span>
<span><span class="co">##   }</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## generated quantities {</span></span>
<span><span class="co">##   vector[total_obs] eta;</span></span>
<span><span class="co">##   matrix[n, n_series] mus;</span></span>
<span><span class="co">##   array[n, n_series] int ypred;</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // posterior predictions</span></span>
<span><span class="co">##   eta = X * b;</span></span>
<span><span class="co">##   for (s in 1 : n_series) {</span></span>
<span><span class="co">##     mus[1 : n, s] = eta[ytimes[1 : n, s]];</span></span>
<span><span class="co">##     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]);</span></span>
<span><span class="co">##   }</span></span>
<span><span class="co">## }</span></span></code></pre>
<div class="section level3">
<h3 id="plotting-effects-and-residuals">Plotting effects and residuals<a class="anchor" aria-label="anchor" href="#plotting-effects-and-residuals"></a>
</h3>
<p>Now for interrogating the model. We can get some sense of the
variation in yearly intercepts from the summary above, but it is easier
to understand them using targeted plots. Plot posterior distributions of
the temporal random effects using <code>plot.mvgam</code> with
<code>type = 're'</code>. See <code><a href="../reference/plot.mvgam.html">?plot.mvgam</a></code> for more details
about the types of plots that can be produced from fitted
<code>mvgam</code> objects</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model1</span>, type <span class="op">=</span> <span class="st">'re'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plot%20random%20effect%20estimates-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
<div class="section level3">
<h3 id="bayesplot-support">
<code>bayesplot</code> support<a class="anchor" aria-label="anchor" href="#bayesplot-support"></a>
</h3>
<p>We can also capitalize on most of the useful MCMC plotting functions
from the <code>bayesplot</code> package to visualize posterior
distributions and diagnostics (see <code><a href="../reference/mcmc_plot.mvgam.html">?mvgam::mcmc_plot.mvgam</a></code>
for details):</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">mcmc_plot</span><span class="op">(</span>object <span class="op">=</span> <span class="va">model1</span>,</span>
<span>          variable <span class="op">=</span> <span class="st">'betas'</span>,</span>
<span>          type <span class="op">=</span> <span class="st">'areas'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-13-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>There is clearly some variation in these yearly intercept estimates.
But how do these translate into time-varying predictions? To understand
this, we can plot posterior hindcasts from this model for the training
period using <code>plot.mvgam</code> with
<code>type = 'forecast'</code></p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model1</span>, type <span class="op">=</span> <span class="st">'forecast'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plot%20posterior%20hindcasts-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>If you wish to extract these hindcasts for other downstream analyses,
the <code>hindcast</code> function can be used. This will return a list
object of class <code>mvgam_forecast</code>. In the
<code>hindcasts</code> slot, a matrix of posterior retrodictions will be
returned for each series in the data (only one series in our
example):</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hindcast.mvgam.html">hindcast</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">hc</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 15</span></span>
<span><span class="co">##  $ call              :Class 'formula'  language count ~ s(year_fac, bs = "re") - 1</span></span>
<span><span class="co">##   .. ..- attr(*, ".Environment")=&lt;environment: R_GlobalEnv&gt; </span></span>
<span><span class="co">##  $ trend_call        : NULL</span></span>
<span><span class="co">##  $ family            : chr "poisson"</span></span>
<span><span class="co">##  $ trend_model       : chr "None"</span></span>
<span><span class="co">##  $ drift             : logi FALSE</span></span>
<span><span class="co">##  $ use_lv            : logi FALSE</span></span>
<span><span class="co">##  $ fit_engine        : chr "stan"</span></span>
<span><span class="co">##  $ type              : chr "response"</span></span>
<span><span class="co">##  $ series_names      : chr "PP"</span></span>
<span><span class="co">##  $ train_observations:List of 1</span></span>
<span><span class="co">##   ..$ PP: int [1:199] 0 1 2 NA 10 NA NA 16 18 12 ...</span></span>
<span><span class="co">##  $ train_times       : num [1:199] 1 2 3 4 5 6 7 8 9 10 ...</span></span>
<span><span class="co">##  $ test_observations : NULL</span></span>
<span><span class="co">##  $ test_times        : NULL</span></span>
<span><span class="co">##  $ hindcasts         :List of 1</span></span>
<span><span class="co">##   ..$ PP: num [1:2000, 1:199] 14 10 7 4 14 5 8 8 4 7 ...</span></span>
<span><span class="co">##   .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. ..$ : NULL</span></span>
<span><span class="co">##   .. .. ..$ : chr [1:199] "ypred[1,1]" "ypred[2,1]" "ypred[3,1]" "ypred[4,1]" ...</span></span>
<span><span class="co">##  $ forecasts         : NULL</span></span>
<span><span class="co">##  - attr(*, "class")= chr "mvgam_forecast"</span></span></code></pre>
<p>You can also extract these hindcasts on the linear predictor scale,
which in this case is the log scale (our Poisson GLM used a log link
function). Sometimes this can be useful for asking more targeted
questions about drivers of variation:</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hindcast.mvgam.html">hindcast</a></span><span class="op">(</span><span class="va">model1</span>, type <span class="op">=</span> <span class="st">'link'</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/range.html" class="external-link">range</a></span><span class="op">(</span><span class="va">hc</span><span class="op">$</span><span class="va">hindcasts</span><span class="op">$</span><span class="va">PP</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] -2.60790  3.47267</span></span></code></pre>
<p>Objects of class <code>mvgam_forecast</code> have an associated plot
function as well:</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hc</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plot%20hindcasts%20on%20the%20linear%20predictor%20scale-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>This plot can look a bit confusing as it seems like there is linear
interpolation from the end of one year to the start of the next. But
this is just due to the way the lines are automatically connected in
base plots</p>
<p>In any regression analysis, a key question is whether the residuals
show any patterns that can be indicative of un-modelled sources of
variation. For GLMs, we can use a modified residual called the <a href="https://www.jstor.org/stable/1390802" target="_blank" class="external-link">Dunn-Smyth,
or randomized quantile, residual</a>. Inspect Dunn-Smyth residuals from
the model using <code>plot.mvgam</code> with
<code>type = 'residuals'</code></p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model1</span>, type <span class="op">=</span> <span class="st">'residuals'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plot%20posterior%20residuals-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
</div>
<div class="section level2">
<h2 id="automatic-forecasting-for-new-data">Automatic forecasting for new data<a class="anchor" aria-label="anchor" href="#automatic-forecasting-for-new-data"></a>
</h2>
<p>These temporal random effects do not have a sense of “time”. Because
of this, each yearly random intercept is not restricted in some way to
be similar to the previous yearly intercept. This drawback becomes
evident when we predict for a new year. To do this, we can repeat the
exercise above but this time will split the data into training and
testing sets before re-running the model. We can then supply the test
set as <code>newdata</code>. For splitting, we will make use of the
<code>filter</code> function from <code>dplyr</code></p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">time</span> <span class="op">&lt;=</span> <span class="fl">160</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">data_train</span> </span>
<span><span class="va">model_data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">time</span> <span class="op">&gt;</span> <span class="fl">160</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">data_test</span></span></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model1b</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvgam.html">mvgam</a></span><span class="op">(</span><span class="va">count</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">year_fac</span>, bs <span class="op">=</span> <span class="st">'re'</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span>,</span>
<span>                family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>                data <span class="op">=</span> <span class="va">data_train</span>,</span>
<span>                newdata <span class="op">=</span> <span class="va">data_test</span><span class="op">)</span></span></code></pre></div>
<p>Repeating the plots above gives insight into how the model’s
hierarchical prior formulation provides all the structure needed to
sample values for un-modelled years</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model1b</span>, type <span class="op">=</span> <span class="st">'re'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-17-1.png" width="60%" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model1b</span>, type <span class="op">=</span> <span class="st">'forecast'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-18-1.png" width="60%" style="display: block; margin: auto;"></p>
<pre><code><span><span class="co">## Out of sample DRPS:</span></span>
<span><span class="co">## [1] 184.7682</span></span></code></pre>
<p>We can also view the test data in the forecast plot to see that the
predictions do not capture the temporal variation in the test set</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model1b</span>, type <span class="op">=</span> <span class="st">'forecast'</span>, newdata <span class="op">=</span> <span class="va">data_test</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plotting%20predictions%20against%20test%20data-1.png" width="60%" style="display: block; margin: auto;"></p>
<pre><code><span><span class="co">## Out of sample DRPS:</span></span>
<span><span class="co">## [1] 184.7682</span></span></code></pre>
<p>As with the <code>hindcast</code> function, we can use the
<code>forecast</code> function to automatically extract the posterior
distributions for these predictions. This also returns an object of
class <code>mvgam_forecast</code>, but now it will contain both the
hindcasts and forecasts for each series in the data:</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/forecast.mvgam.html">forecast</a></span><span class="op">(</span><span class="va">model1b</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">fc</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 16</span></span>
<span><span class="co">##  $ call              :Class 'formula'  language count ~ s(year_fac, bs = "re") - 1</span></span>
<span><span class="co">##   .. ..- attr(*, ".Environment")=&lt;environment: R_GlobalEnv&gt; </span></span>
<span><span class="co">##  $ trend_call        : NULL</span></span>
<span><span class="co">##  $ family            : chr "poisson"</span></span>
<span><span class="co">##  $ family_pars       : NULL</span></span>
<span><span class="co">##  $ trend_model       : chr "None"</span></span>
<span><span class="co">##  $ drift             : logi FALSE</span></span>
<span><span class="co">##  $ use_lv            : logi FALSE</span></span>
<span><span class="co">##  $ fit_engine        : chr "stan"</span></span>
<span><span class="co">##  $ type              : chr "response"</span></span>
<span><span class="co">##  $ series_names      : Factor w/ 1 level "PP": 1</span></span>
<span><span class="co">##  $ train_observations:List of 1</span></span>
<span><span class="co">##   ..$ PP: int [1:160] 0 1 2 NA 10 NA NA 16 18 12 ...</span></span>
<span><span class="co">##  $ train_times       : num [1:160] 1 2 3 4 5 6 7 8 9 10 ...</span></span>
<span><span class="co">##  $ test_observations :List of 1</span></span>
<span><span class="co">##   ..$ PP: int [1:39] NA 0 0 10 3 14 18 NA 28 46 ...</span></span>
<span><span class="co">##  $ test_times        : num [1:39] 161 162 163 164 165 166 167 168 169 170 ...</span></span>
<span><span class="co">##  $ hindcasts         :List of 1</span></span>
<span><span class="co">##   ..$ PP: num [1:2000, 1:160] 7 9 2 7 8 15 11 8 12 9 ...</span></span>
<span><span class="co">##   .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. ..$ : NULL</span></span>
<span><span class="co">##   .. .. ..$ : chr [1:160] "ypred[1,1]" "ypred[2,1]" "ypred[3,1]" "ypred[4,1]" ...</span></span>
<span><span class="co">##  $ forecasts         :List of 1</span></span>
<span><span class="co">##   ..$ PP: num [1:2000, 1:39] 6 13 8 16 12 8 7 6 10 7 ...</span></span>
<span><span class="co">##   .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. ..$ : NULL</span></span>
<span><span class="co">##   .. .. ..$ : chr [1:39] "ypred[161,1]" "ypred[162,1]" "ypred[163,1]" "ypred[164,1]" ...</span></span>
<span><span class="co">##  - attr(*, "class")= chr "mvgam_forecast"</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="adding-predictors-as-fixed-effects">Adding predictors as “fixed” effects<a class="anchor" aria-label="anchor" href="#adding-predictors-as-fixed-effects"></a>
</h2>
<p>Any users familiar with GLMs will know that we nearly always wish to
include predictor variables that may explain some of the variation in
our observations. Predictors are easily incorporated into GLMs / GAMs.
Here, we will update the model from above by including a parametric
(fixed) effect of <code>ndvi</code> as a linear predictor:</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvgam.html">mvgam</a></span><span class="op">(</span><span class="va">count</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">year_fac</span>, bs <span class="op">=</span> <span class="st">'re'</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                  <span class="va">ndvi</span> <span class="op">-</span> <span class="fl">1</span>,</span>
<span>                family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>                data <span class="op">=</span> <span class="va">data_train</span>,</span>
<span>                newdata <span class="op">=</span> <span class="va">data_test</span><span class="op">)</span></span></code></pre></div>
<p>The model can be described mathematically as follows: <span class="math display">\[\begin{align*}
\boldsymbol{count}_t &amp; \sim \text{Poisson}(\lambda_t) \\
log(\lambda_t) &amp; = \beta_{year[year_t]} + \beta_{ndvi} *
\boldsymbol{ndvi}_t \\
\beta_{year} &amp; \sim \text{Normal}(\mu_{year}, \sigma_{year}) \\
\beta_{ndvi} &amp; \sim \text{Normal}(0, 1) \end{align*}\]</span></p>
<p>Where the <span class="math inline">\(\beta_{year}\)</span> effects
are the same as before but we now have another predictor <span class="math inline">\((\beta_{ndvi})\)</span> that applies to the
<code>ndvi</code> value at each timepoint <span class="math inline">\(t\)</span>. Inspect the summary of this model</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model2</span><span class="op">)</span></span></code></pre></div>
<pre class="scroll-300"><code><span><span class="co">## GAM formula:</span></span>
<span><span class="co">## count ~ ndvi + s(year_fac, bs = "re") - 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Family:</span></span>
<span><span class="co">## poisson</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Link function:</span></span>
<span><span class="co">## log</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Trend model:</span></span>
<span><span class="co">## None</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N series:</span></span>
<span><span class="co">## 1 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N timepoints:</span></span>
<span><span class="co">## 160 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Status:</span></span>
<span><span class="co">## Fitted using Stan </span></span>
<span><span class="co">## 4 chains, each with iter = 1000; warmup = 500; thin = 1 </span></span>
<span><span class="co">## Total post-warmup draws = 2000</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## GAM coefficient (beta) estimates:</span></span>
<span><span class="co">##                2.5%  50% 97.5% Rhat n_eff</span></span>
<span><span class="co">## ndvi           0.32 0.39  0.45    1  1918</span></span>
<span><span class="co">## s(year_fac).1  1.10 1.40  1.70    1  2213</span></span>
<span><span class="co">## s(year_fac).2  1.80 2.00  2.20    1  2256</span></span>
<span><span class="co">## s(year_fac).3  2.20 2.40  2.60    1  1957</span></span>
<span><span class="co">## s(year_fac).4  2.30 2.50  2.70    1  1831</span></span>
<span><span class="co">## s(year_fac).5  1.20 1.40  1.60    1  2486</span></span>
<span><span class="co">## s(year_fac).6  1.00 1.30  1.50    1  2599</span></span>
<span><span class="co">## s(year_fac).7  1.10 1.40  1.70    1  2338</span></span>
<span><span class="co">## s(year_fac).8  2.10 2.30  2.50    1  2515</span></span>
<span><span class="co">## s(year_fac).9  2.70 2.90  3.00    1  2012</span></span>
<span><span class="co">## s(year_fac).10 2.00 2.20  2.40    1  2919</span></span>
<span><span class="co">## s(year_fac).11 2.30 2.40  2.60    1  2029</span></span>
<span><span class="co">## s(year_fac).12 2.50 2.70  2.80    1  2418</span></span>
<span><span class="co">## s(year_fac).13 1.40 1.60  1.90    1  2568</span></span>
<span><span class="co">## s(year_fac).14 0.65 2.00  3.30    1  1271</span></span>
<span><span class="co">## s(year_fac).15 0.53 2.00  3.30    1  1046</span></span>
<span><span class="co">## s(year_fac).16 0.72 2.00  3.30    1  1337</span></span>
<span><span class="co">## s(year_fac).17 0.63 2.00  3.30    1  1380</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## GAM group-level estimates:</span></span>
<span><span class="co">##                2.5% 50% 97.5% Rhat n_eff</span></span>
<span><span class="co">## mean(year_fac) 1.60 2.0   2.4 1.00   329</span></span>
<span><span class="co">## sd(year_fac)   0.41 0.6   1.0 1.02   350</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Approximate significance of GAM observation smooths:</span></span>
<span><span class="co">##              edf Chi.sq p-value    </span></span>
<span><span class="co">## s(year_fac) 11.1   2869  &lt;2e-16 ***</span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Stan MCMC diagnostics:</span></span>
<span><span class="co">## n_eff / iter looks reasonable for all parameters</span></span>
<span><span class="co">## Rhat looks reasonable for all parameters</span></span>
<span><span class="co">## 0 of 2000 iterations ended with a divergence (0%)</span></span>
<span><span class="co">## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%)</span></span>
<span><span class="co">## E-FMI indicated no pathological behavior</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Samples were drawn using NUTS(diag_e) at Wed Nov 01 1:35:55 PM 2023.</span></span>
<span><span class="co">## For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">## and Rhat is the potential scale reduction factor on split MCMC chains</span></span>
<span><span class="co">## (at convergence, Rhat = 1)</span></span></code></pre>
<p>Rather than printing the summary each time, we can also quickly look
at the posterior empirical quantiles for the fixed effect of
<code>ndvi</code> (and other linear predictor coefficients) using
<code>coef</code>:</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">model2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     2.5%      50%     97.5% Rhat n_eff</span></span>
<span><span class="co">## ndvi           0.3210034 0.390067 0.4533269    1  1918</span></span>
<span><span class="co">## s(year_fac).1  1.1257462 1.407995 1.6713415    1  2213</span></span>
<span><span class="co">## s(year_fac).2  1.7931752 2.004745 2.1991792    1  2256</span></span>
<span><span class="co">## s(year_fac).3  2.1935115 2.375015 2.5744540    1  1957</span></span>
<span><span class="co">## s(year_fac).4  2.3200965 2.506585 2.6904098    1  1831</span></span>
<span><span class="co">## s(year_fac).5  1.2019287 1.429395 1.6420233    1  2486</span></span>
<span><span class="co">## s(year_fac).6  1.0233382 1.274480 1.5182880    1  2599</span></span>
<span><span class="co">## s(year_fac).7  1.1293855 1.409435 1.6712085    1  2338</span></span>
<span><span class="co">## s(year_fac).8  2.0816930 2.271760 2.4516905    1  2515</span></span>
<span><span class="co">## s(year_fac).9  2.7178790 2.856310 2.9819425    1  2012</span></span>
<span><span class="co">## s(year_fac).10 1.9812335 2.188975 2.3779092    1  2919</span></span>
<span><span class="co">## s(year_fac).11 2.2643295 2.436195 2.5982962    1  2029</span></span>
<span><span class="co">## s(year_fac).12 2.5400090 2.692160 2.8444258    1  2418</span></span>
<span><span class="co">## s(year_fac).13 1.3734145 1.615205 1.8717450    1  2568</span></span>
<span><span class="co">## s(year_fac).14 0.6513878 1.979125 3.2947415    1  1271</span></span>
<span><span class="co">## s(year_fac).15 0.5272483 1.996840 3.3351160    1  1046</span></span>
<span><span class="co">## s(year_fac).16 0.7174889 1.991200 3.3420777    1  1337</span></span>
<span><span class="co">## s(year_fac).17 0.6309596 1.970360 3.2801960    1  1380</span></span></code></pre>
<p>Look at the estimated effect of <code>ndvi</code> using
<code>plot.mvgam</code> with <code>type = 'pterms'</code></p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model2</span>, type <span class="op">=</span> <span class="st">'pterms'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plot%20NDVI%20effect-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>This plot indicates a positive linear effect of <code>ndvi</code> on
<code>log(counts)</code>. But it may be easier to visualise using a
histogram, especially for parametric (linear) effects. This can be done
by first extracting the posterior coefficients as we did in the first
example:</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beta_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">model2</span>, variable <span class="op">=</span> <span class="st">'betas'</span><span class="op">)</span></span>
<span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">beta_post</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Rows: 2,000</span></span>
<span><span class="co">## Columns: 18</span></span>
<span><span class="co">## $ ndvi             <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 0.409732, 0.431930, 0.423620, 0.352534, 0.462468, 0.3…</span></span>
<span><span class="co">## $ `s(year_fac).1`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.47541, 1.46069, 1.34564, 1.55801, 1.22887, 1.47750,…</span></span>
<span><span class="co">## $ `s(year_fac).2`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.85697, 1.73304, 1.88540, 2.09812, 1.81894, 2.16080,…</span></span>
<span><span class="co">## $ `s(year_fac).3`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.29779, 2.19139, 2.38318, 2.50658, 2.27022, 2.49292,…</span></span>
<span><span class="co">## $ `s(year_fac).4`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.39048, 2.41680, 2.36230, 2.56093, 2.42629, 2.66807,…</span></span>
<span><span class="co">## $ `s(year_fac).5`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.35221, 1.42605, 1.27227, 1.54327, 1.21902, 1.53587,…</span></span>
<span><span class="co">## $ `s(year_fac).6`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.23813, 1.18688, 1.22698, 1.24801, 1.20283, 1.26928,…</span></span>
<span><span class="co">## $ `s(year_fac).7`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.27502, 1.24532, 1.15261, 1.34999, 1.41935, 1.60229,…</span></span>
<span><span class="co">## $ `s(year_fac).8`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.24695, 2.36220, 2.18259, 2.32540, 2.20976, 2.38162,…</span></span>
<span><span class="co">## $ `s(year_fac).9`  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.82589, 2.86064, 2.79391, 2.94695, 2.79919, 2.95859,…</span></span>
<span><span class="co">## $ `s(year_fac).10` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.26106, 2.15112, 2.08626, 2.23736, 2.14404, 2.30348,…</span></span>
<span><span class="co">## $ `s(year_fac).11` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.43048, 2.31603, 2.36756, 2.50735, 2.37885, 2.53762,…</span></span>
<span><span class="co">## $ `s(year_fac).12` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.67008, 2.54824, 2.69937, 2.78914, 2.63519, 2.79754,…</span></span>
<span><span class="co">## $ `s(year_fac).13` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.61806, 1.56701, 1.64360, 1.70030, 1.39698, 1.56216,…</span></span>
<span><span class="co">## $ `s(year_fac).14` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.156970, 1.456830, 1.752760, 2.595580, 1.140760, 2.7…</span></span>
<span><span class="co">## $ `s(year_fac).15` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 1.238140, 1.307210, 1.585730, 2.894060, 0.937930, 2.6…</span></span>
<span><span class="co">## $ `s(year_fac).16` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.17918, 1.94021, 2.42255, 1.87969, 2.40144, 1.76901,…</span></span>
<span><span class="co">## $ `s(year_fac).17` <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> 2.35141, 2.31488, 2.34975, 1.52114, 1.84938, 2.29093,…</span></span></code></pre>
<p>The posterior distribution for the effect of <code>ndvi</code> is
stored in the <code>ndvi</code> column. A quick histogram confirms our
inference that <code>log(counts)</code> respond positively to increases
in <code>ndvi</code>:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">beta_post</span><span class="op">$</span><span class="va">ndvi</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">beta_post</span><span class="op">$</span><span class="va">ndvi</span><span class="op">)</span><span class="op">)</span>,</span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">beta_post</span><span class="op">$</span><span class="va">ndvi</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>     col <span class="op">=</span> <span class="st">'darkred'</span>,</span>
<span>     border <span class="op">=</span> <span class="st">'white'</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">beta</span><span class="op">[</span><span class="va">NDVI</span><span class="op">]</span><span class="op">)</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">''</span>,</span>
<span>     yaxt <span class="op">=</span> <span class="st">'n'</span>,</span>
<span>     main <span class="op">=</span> <span class="st">''</span>,</span>
<span>     lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">0</span>, lwd <span class="op">=</span> <span class="fl">2.5</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Histogram%20of%20NDVI%20effects-1.png" width="60%" style="display: block; margin: auto;"></p>
<div class="section level3">
<h3 id="marginaleffects-support">
<code>marginaleffects</code> support<a class="anchor" aria-label="anchor" href="#marginaleffects-support"></a>
</h3>
<p>Given our model used a nonlinear link function (log link in this
example), it can still be difficult to fully understand what
relationship our model is estimating between a predictor and the
response. Fortunately, the <code>marginaleffects</code> package makes
this relatively straightforward. Objects of class <code>mvgam</code> can
be used with <code>marginaleffects</code> to inspect contrasts,
scenario-based predictions, conditional and marginal effects, all on the
outcome scale. Here we will use the <code>plot_predictions</code>
function from <code>marginaleffects</code> to inspect the conditional
effect of <code>ndvi</code> (use <code>?plot_predictions</code> for
guidance on how to modify these plots):</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_predictions</span><span class="op">(</span><span class="va">model2</span>, </span>
<span>                 condition <span class="op">=</span> <span class="st">"ndvi"</span>,</span>
<span>                 <span class="co"># include the observed count values</span></span>
<span>                 <span class="co"># as points, and show rugs for the observed</span></span>
<span>                 <span class="co"># ndvi and count values on the axes</span></span>
<span>                 points <span class="op">=</span> <span class="fl">0.5</span>, rug <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-22-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>Now it is easier to get a sense of the nonlinear but positive
relationship estimated between <code>ndvi</code> and <code>count</code>.
Plotting on the link scale should give an almost identical plot to the
<code>pterms</code> plot from <code>mvgam</code> above, which shows the
linear effect on the link scale:</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_predictions</span><span class="op">(</span><span class="va">model2</span>, </span>
<span>                 condition <span class="op">=</span> <span class="st">"ndvi"</span>,</span>
<span>                 type <span class="op">=</span> <span class="st">'link'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-23-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
</div>
<div class="section level2">
<h2 id="adding-predictors-as-smooths">Adding predictors as smooths<a class="anchor" aria-label="anchor" href="#adding-predictors-as-smooths"></a>
</h2>
<p>Smooth functions, using penalized splines, are a major feature of
<code>mvgam</code>. Nonlinear splines are commonly viewed as variations
of random effects in which the coefficients that control the shape of
the spline are drawn from a joint, penalized distribution. This strategy
is very often used in ecological time series analysis to capture smooth
temporal variation in the processes we seek to study. When we construct
smoothing splines, the workhorse package <code>mgcv</code> will
calculate a set of basis functions that will collectively control the
shape and complexity of the resulting spline. It is often helpful to
visualize these basis functions to get a better sense of how splines
work. We’ll create a set of 6 basis functions to represent possible
variation in the effect of <code>time</code> on our outcome.In addition
to constructing the basis functions, <code>mgcv</code> also creates a
penalty matrix <span class="math inline">\(S\)</span>, which contains
<strong>known</strong> coefficients that work to constrain the
wiggliness of the resulting smooth function. When fitting a GAM to data,
we must estimate the smoothing parameters (<span class="math inline">\(\lambda\)</span>) that will penalize these
matrices, resulting in constrained basis coefficients and smoother
functions that are less likely to overfit the data. This is the key to
fitting GAMs in a Bayesian framework, as we can jointly estimate the
<span class="math inline">\(\lambda\)</span>’s using informative priors
to prevent overfitting and expand the complexity of models we can
tackle. To see this in practice, we can now fit a model that replaces
the yearly random effects with a smooth function of <code>time</code>.
We will need a reasonably complex function (large <code>k</code>) to try
and accommodate the temporal variation in our observations. Following
some <a href="https://fromthebottomoftheheap.net/2020/06/03/extrapolating-with-gams/" target="_blank" class="external-link">useful advice by Gavin Simpson</a>, we will use a
b-spline basis for the temporal smooth. Because we no longer have
intercepts for each year, we also retain the primary intercept term in
this model (there is no <code>-1</code> in the formula now):</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvgam.html">mvgam</a></span><span class="op">(</span><span class="va">count</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">time</span>, bs <span class="op">=</span> <span class="st">'bs'</span>, k <span class="op">=</span> <span class="fl">15</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                  <span class="va">ndvi</span>,</span>
<span>                family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>                data <span class="op">=</span> <span class="va">data_train</span>,</span>
<span>                newdata <span class="op">=</span> <span class="va">data_test</span><span class="op">)</span></span></code></pre></div>
<p>The model can be described mathematically as follows: <span class="math display">\[\begin{align*}
\boldsymbol{count}_t &amp; \sim \text{Poisson}(\lambda_t) \\
log(\lambda_t) &amp; = f(\boldsymbol{time})_t + \beta_{ndvi} *
\boldsymbol{ndvi}_t  \\
f(\boldsymbol{time}) &amp; = \sum_{k=1}^{K}b * \beta_{smooth} \\
\beta_{smooth} &amp; \sim \text{MVNormal}(0, (\Omega * \lambda)^{-1}) \\
\beta_{ndvi} &amp; \sim \text{Normal}(0, 1) \end{align*}\]</span></p>
<p>Where the smooth function <span class="math inline">\(f_{time}\)</span> is built by summing across a set
of weighted basis functions. The basis functions <span class="math inline">\((b)\)</span> are constructed using a thin plate
regression basis in <code>mgcv</code>. The weights <span class="math inline">\((\beta_{smooth})\)</span> are drawn from a
penalized multivariate normal distribution where the precision matrix
<span class="math inline">\((\Omega\)</span>) is multiplied by a
smoothing penalty <span class="math inline">\((\lambda)\)</span>. If
<span class="math inline">\(\lambda\)</span> becomes large, this acts to
<em>squeeze</em> the covariances among the weights <span class="math inline">\((\beta_{smooth})\)</span>, leading to a less
wiggly spline. Note that sometimes there are multiple smoothing
penalties that contribute to the covariance matrix, but I am only
showing one here for simplicity. View the summary as before</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model3</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## GAM formula:</span></span>
<span><span class="co">## count ~ s(time, bs = "bs", k = 15) + ndvi</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Family:</span></span>
<span><span class="co">## poisson</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Link function:</span></span>
<span><span class="co">## log</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Trend model:</span></span>
<span><span class="co">## None</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N series:</span></span>
<span><span class="co">## 1 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N timepoints:</span></span>
<span><span class="co">## 160 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Status:</span></span>
<span><span class="co">## Fitted using Stan </span></span>
<span><span class="co">## 4 chains, each with iter = 1000; warmup = 500; thin = 1 </span></span>
<span><span class="co">## Total post-warmup draws = 2000</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## GAM coefficient (beta) estimates:</span></span>
<span><span class="co">##              2.5%   50%  97.5% Rhat n_eff</span></span>
<span><span class="co">## (Intercept)  2.00  2.10  2.200 1.00  1366</span></span>
<span><span class="co">## ndvi         0.26  0.33  0.390 1.00  1332</span></span>
<span><span class="co">## s(time).1   -2.20 -1.20 -0.075 1.00   482</span></span>
<span><span class="co">## s(time).2    0.43  1.20  2.200 1.00   325</span></span>
<span><span class="co">## s(time).3   -0.58  0.35  1.400 1.00   339</span></span>
<span><span class="co">## s(time).4    1.60  2.40  3.400 1.01   287</span></span>
<span><span class="co">## s(time).5   -1.20 -0.29  0.750 1.00   333</span></span>
<span><span class="co">## s(time).6   -0.63  0.29  1.400 1.00   306</span></span>
<span><span class="co">## s(time).7   -1.60 -0.60  0.460 1.00   353</span></span>
<span><span class="co">## s(time).8    0.53  1.40  2.400 1.00   304</span></span>
<span><span class="co">## s(time).9    1.10  2.00  3.000 1.01   274</span></span>
<span><span class="co">## s(time).10  -0.39  0.45  1.500 1.00   327</span></span>
<span><span class="co">## s(time).11   0.77  1.70  2.700 1.00   286</span></span>
<span><span class="co">## s(time).12   0.61  1.40  2.400 1.01   326</span></span>
<span><span class="co">## s(time).13  -1.20 -0.37  0.480 1.00   424</span></span>
<span><span class="co">## s(time).14  -7.10 -3.90 -1.100 1.00   390</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Approximate significance of GAM observation smooths:</span></span>
<span><span class="co">##         edf Chi.sq p-value    </span></span>
<span><span class="co">## s(time) 8.7    758  &lt;2e-16 ***</span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Stan MCMC diagnostics:</span></span>
<span><span class="co">## n_eff / iter looks reasonable for all parameters</span></span>
<span><span class="co">## Rhat looks reasonable for all parameters</span></span>
<span><span class="co">## 0 of 2000 iterations ended with a divergence (0%)</span></span>
<span><span class="co">## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%)</span></span>
<span><span class="co">## E-FMI indicated no pathological behavior</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Samples were drawn using NUTS(diag_e) at Wed Nov 01 1:36:38 PM 2023.</span></span>
<span><span class="co">## For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">## and Rhat is the potential scale reduction factor on split MCMC chains</span></span>
<span><span class="co">## (at convergence, Rhat = 1)</span></span></code></pre>
<p>The summary above now contains posterior estimates for the smoothing
parameters as well as the basis coefficients for the nonlinear effect of
<code>time</code>. We can visualize the conditional <code>time</code>
effect using the <code>plot</code> function with
<code>type = 'smooths'</code>:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model3</span>, type <span class="op">=</span> <span class="st">'smooths'</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-26-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>By default this plots shows posterior empirical quantiles, but it can
also be helpful to view some realizations of the underlying function
(here, each line is a different potential curve drawn from the posterior
of all possible curves):</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model3</span>, type <span class="op">=</span> <span class="st">'smooths'</span>, realisations <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>     n_realisations <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-27-1.png" width="60%" style="display: block; margin: auto;"></p>
<div class="section level3">
<h3 id="derivatives-of-smooths">Derivatives of smooths<a class="anchor" aria-label="anchor" href="#derivatives-of-smooths"></a>
</h3>
<p>A useful question when modelling using GAMs is to identify where the
function is changing most rapidly. To address this, we can plot
estimated 1st derivatives of the spline:</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model3</span>, type <span class="op">=</span> <span class="st">'smooths'</span>, derivatives <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plot%20smooth%20term%20derivatives-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>Here, values above <code>&gt;0</code> indicate the function was
increasing at that time point, while values <code>&lt;0</code> indicate
the function was declining. The most rapid declines appear to have been
happening around timepoints 50 and again toward the end of the training
period, for example.</p>
</div>
<div class="section level3">
<h3 id="conditional-smooths">Conditional smooths<a class="anchor" aria-label="anchor" href="#conditional-smooths"></a>
</h3>
<p>We can use <code>plot_predictions</code> to view the conditional
smooth of time on the scale of the outcome variable:</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_predictions</span><span class="op">(</span><span class="va">model3</span>, </span>
<span>                 condition <span class="op">=</span> <span class="st">"time"</span>,</span>
<span>                 points <span class="op">=</span> <span class="fl">0.5</span>, rug <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-28-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>Inspect the underlying <code>Stan</code> code to gain some idea of
how the spline is being penalized:</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/code.html">code</a></span><span class="op">(</span><span class="va">model3</span><span class="op">)</span></span></code></pre></div>
<pre class="scroll-300"><code><span><span class="co">## // Stan model code generated by package mvgam</span></span>
<span><span class="co">## data {</span></span>
<span><span class="co">##   int&lt;lower=0&gt; total_obs; // total number of observations</span></span>
<span><span class="co">##   int&lt;lower=0&gt; n; // number of timepoints per series</span></span>
<span><span class="co">##   int&lt;lower=0&gt; n_sp; // number of smoothing parameters</span></span>
<span><span class="co">##   int&lt;lower=0&gt; n_series; // number of series</span></span>
<span><span class="co">##   int&lt;lower=0&gt; num_basis; // total number of basis coefficients</span></span>
<span><span class="co">##   vector[num_basis] zero; // prior locations for basis coefficients</span></span>
<span><span class="co">##   matrix[total_obs, num_basis] X; // mgcv GAM design matrix</span></span>
<span><span class="co">##   array[n, n_series] int&lt;lower=0&gt; ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?)</span></span>
<span><span class="co">##   matrix[14, 28] S1; // mgcv smooth penalty matrix S1</span></span>
<span><span class="co">##   int&lt;lower=0&gt; n_nonmissing; // number of nonmissing observations</span></span>
<span><span class="co">##   array[n_nonmissing] int&lt;lower=0&gt; flat_ys; // flattened nonmissing observations</span></span>
<span><span class="co">##   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations</span></span>
<span><span class="co">##   array[n_nonmissing] int&lt;lower=0&gt; obs_ind; // indices of nonmissing observations</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## parameters {</span></span>
<span><span class="co">##   // raw basis coefficients</span></span>
<span><span class="co">##   vector[num_basis] b_raw;</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // smoothing parameters</span></span>
<span><span class="co">##   vector&lt;lower=0&gt;[n_sp] lambda;</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## transformed parameters {</span></span>
<span><span class="co">##   // basis coefficients</span></span>
<span><span class="co">##   vector[num_basis] b;</span></span>
<span><span class="co">##   b[1 : num_basis] = b_raw[1 : num_basis];</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## model {</span></span>
<span><span class="co">##   // prior for (Intercept)...</span></span>
<span><span class="co">##   b_raw[1] ~ student_t(3, 2.6, 2.5);</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // prior for ndvi...</span></span>
<span><span class="co">##   b_raw[2] ~ student_t(3, 0, 2);</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // prior for s(time)...</span></span>
<span><span class="co">##   b_raw[3 : 16] ~ multi_normal_prec(zero[3 : 16],</span></span>
<span><span class="co">##                                     S1[1 : 14, 1 : 14] * lambda[1]</span></span>
<span><span class="co">##                                     + S1[1 : 14, 15 : 28] * lambda[2]);</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // priors for smoothing parameters</span></span>
<span><span class="co">##   lambda ~ normal(5, 30);</span></span>
<span><span class="co">##   {</span></span>
<span><span class="co">##     // likelihood functions</span></span>
<span><span class="co">##     flat_ys ~ poisson_log_glm(flat_xs, 0.0, b);</span></span>
<span><span class="co">##   }</span></span>
<span><span class="co">## }</span></span>
<span><span class="co">## generated quantities {</span></span>
<span><span class="co">##   vector[total_obs] eta;</span></span>
<span><span class="co">##   matrix[n, n_series] mus;</span></span>
<span><span class="co">##   vector[n_sp] rho;</span></span>
<span><span class="co">##   array[n, n_series] int ypred;</span></span>
<span><span class="co">##   rho = log(lambda);</span></span>
<span><span class="co">##   </span></span>
<span><span class="co">##   // posterior predictions</span></span>
<span><span class="co">##   eta = X * b;</span></span>
<span><span class="co">##   for (s in 1 : n_series) {</span></span>
<span><span class="co">##     mus[1 : n, s] = eta[ytimes[1 : n, s]];</span></span>
<span><span class="co">##     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]);</span></span>
<span><span class="co">##   }</span></span>
<span><span class="co">## }</span></span></code></pre>
<p>The line below <code>// prior for s(time)...</code> shows how the
spline basis coefficients are drawn from a zero-centred multivariate
normal distribution. The precision matrix <span class="math inline">\(S\)</span> is penalized by two different smoothing
parameters (the <span class="math inline">\(\lambda\)</span>’s) to
enforce smoothness and reduce overfitting</p>
</div>
</div>
<div class="section level2">
<h2 id="latent-dynamics-in-mvgam">Latent dynamics in <code>mvgam</code><a class="anchor" aria-label="anchor" href="#latent-dynamics-in-mvgam"></a>
</h2>
<p>Forecasts from the above model are not ideal:</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model3</span>, type <span class="op">=</span> <span class="st">'forecast'</span>, newdata <span class="op">=</span> <span class="va">data_test</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-30-1.png" width="60%" style="display: block; margin: auto;"></p>
<pre><code><span><span class="co">## Out of sample DRPS:</span></span>
<span><span class="co">## [1] 285.565</span></span></code></pre>
<p>Why is this happening? The forecasts are driven almost entirely by
variation in the temporal spline, which is extrapolating linearly
<em>forever</em> beyond the edge of the training data. Any slight
wiggles near the end of the training set will result in wildly different
forecasts. To visualize this, we can plot the extrapolated temporal
functions into the out-of-sample test set for the two models. Here are
the extrapolated functions for the first model, with 15 basis
functions:</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_mvgam_smooth.html">plot_mvgam_smooth</a></span><span class="op">(</span><span class="va">model3</span>, smooth <span class="op">=</span> <span class="st">'s(time)'</span>,</span>
<span>                  <span class="co"># feed newdata to the plot function to generate</span></span>
<span>                  <span class="co"># predictions of the temporal smooth to the end of the </span></span>
<span>                  <span class="co"># testing period</span></span>
<span>                  newdata <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>time <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">data_test</span><span class="op">$</span><span class="va">time</span><span class="op">)</span>,</span>
<span>                                       ndvi <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">data_train</span><span class="op">$</span><span class="va">time</span><span class="op">)</span>, lty <span class="op">=</span> <span class="st">'dashed'</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/Plot%20extrapolated%20temporal%20functions%20using%20newdata-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>This model is not doing well. Clearly we need to somehow account for
the strong temporal autocorrelation when modelling these data without
using a smooth function of <code>time</code>. Now onto another prominent
feature of <code>mvgam</code>: the ability to include (possibly latent)
autocorrelated residuals in regression models. To do so, we use the
<code>trend_model</code> argument (see <code><a href="../reference/mvgam_trends.html">?mvgam_trends</a></code> for
details of different dynamic trend models that are supported). This
model will use a separate sub-model for latent residuals that evolve as
an AR1 process (i.e. the error in the current time point is a function
of the error in the previous time point, plus some stochastic noise). We
also include a smooth function of <code>ndvi</code> in this model,
rather than the parametric term that was used above, to showcase that
<code>mvgam</code> can include combinations of smooths and dynamic
components:</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model4</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvgam.html">mvgam</a></span><span class="op">(</span><span class="va">count</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">ndvi</span>, k <span class="op">=</span> <span class="fl">6</span><span class="op">)</span>,</span>
<span>                family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>                data <span class="op">=</span> <span class="va">data_train</span>,</span>
<span>                newdata <span class="op">=</span> <span class="va">data_test</span>,</span>
<span>                trend_model <span class="op">=</span> <span class="st">'AR1'</span><span class="op">)</span></span></code></pre></div>
<p>The model can be described mathematically as follows: <span class="math display">\[\begin{align*}
\boldsymbol{count}_t &amp; \sim \text{Poisson}(\lambda_t) \\
log(\lambda_t) &amp; = f(\boldsymbol{ndvi})_t + z_t \\
z_t &amp; \sim \text{Normal}(ar1 * z_{t-1}, \sigma_{error}) \\
ar1 &amp; \sim \text{Normal}(0, 1)[-1, 1] \\
\sigma_{error} &amp; \sim \text{Exponential}(2) \\
f(\boldsymbol{ndvi}) &amp; = \sum_{k=1}^{K}b * \beta_{smooth} \\
\beta_{smooth} &amp; \sim \text{MVNormal}(0, (\Omega * \lambda)^{-1})
\end{align*}\]</span></p>
<p>Here the term <span class="math inline">\(z_t\)</span> captures
autocorrelated latent residuals, which are modelled using an AR1
process. You can also notice that this model is estimating
autocorrelated errors for the full time period, even though some of
these time points have missing observations. This is useful for getting
more realistic estimates of the residual autocorrelation parameters.
Summarise the model to see how it now returns posterior summaries for
the latent AR1 process:</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model4</span><span class="op">)</span></span></code></pre></div>
<pre class="scroll-300"><code><span><span class="co">## GAM formula:</span></span>
<span><span class="co">## count ~ s(ndvi, k = 6)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Family:</span></span>
<span><span class="co">## poisson</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Link function:</span></span>
<span><span class="co">## log</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Trend model:</span></span>
<span><span class="co">## AR1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N series:</span></span>
<span><span class="co">## 1 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## N timepoints:</span></span>
<span><span class="co">## 160 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Status:</span></span>
<span><span class="co">## Fitted using Stan </span></span>
<span><span class="co">## 4 chains, each with iter = 1000; warmup = 500; thin = 1 </span></span>
<span><span class="co">## Total post-warmup draws = 2000</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## GAM coefficient (beta) estimates:</span></span>
<span><span class="co">##               2.5%     50% 97.5% Rhat n_eff</span></span>
<span><span class="co">## (Intercept)  1.400  2.0000 2.600 1.03    70</span></span>
<span><span class="co">## s(ndvi).1   -0.140 -0.0076 0.086 1.01   553</span></span>
<span><span class="co">## s(ndvi).2   -0.150  0.0140 0.260 1.01   316</span></span>
<span><span class="co">## s(ndvi).3   -0.057 -0.0015 0.038 1.00   552</span></span>
<span><span class="co">## s(ndvi).4   -0.240  0.1000 1.100 1.01   236</span></span>
<span><span class="co">## s(ndvi).5   -0.052  0.1700 0.360 1.02   512</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Approximate significance of GAM observation smooths:</span></span>
<span><span class="co">##          edf Chi.sq p-value  </span></span>
<span><span class="co">## s(ndvi) 1.46   91.9   0.046 *</span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Latent trend parameter AR estimates:</span></span>
<span><span class="co">##          2.5%  50% 97.5% Rhat n_eff</span></span>
<span><span class="co">## ar1[1]   0.69 0.81  0.90    1   486</span></span>
<span><span class="co">## sigma[1] 0.67 0.80  0.94    1   509</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Stan MCMC diagnostics:</span></span>
<span><span class="co">## n_eff / iter looks reasonable for all parameters</span></span>
<span><span class="co">## Rhat looks reasonable for all parameters</span></span>
<span><span class="co">## 0 of 2000 iterations ended with a divergence (0%)</span></span>
<span><span class="co">## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%)</span></span>
<span><span class="co">## E-FMI indicated no pathological behavior</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Samples were drawn using NUTS(diag_e) at Wed Nov 01 1:37:43 PM 2023.</span></span>
<span><span class="co">## For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">## and Rhat is the potential scale reduction factor on split MCMC chains</span></span>
<span><span class="co">## (at convergence, Rhat = 1)</span></span></code></pre>
<p>View conditional smooths for the <code>ndvi</code> effect:</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_predictions</span><span class="op">(</span><span class="va">model4</span>, </span>
<span>                 condition <span class="op">=</span> <span class="st">"ndvi"</span>,</span>
<span>                 points <span class="op">=</span> <span class="fl">0.5</span>, rug <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-32-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>View posterior hindcasts / forecasts and compare against the out of
sample test data</p>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model4</span>, type <span class="op">=</span> <span class="st">'forecast'</span>, newdata <span class="op">=</span> <span class="va">data_test</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-33-1.png" width="60%" style="display: block; margin: auto;"></p>
<pre><code><span><span class="co">## Out of sample DRPS:</span></span>
<span><span class="co">## [1] 148.5903</span></span></code></pre>
<p>The trend is evolving as an AR1 process, which we can also view:</p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model4</span>, type <span class="op">=</span> <span class="st">'trend'</span>, newdata <span class="op">=</span> <span class="va">data_test</span><span class="op">)</span></span></code></pre></div>
<p><img src="mvgam_overview_files/figure-html/unnamed-chunk-34-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>In-sample model performance can be interrogated using leave-one-out
cross-validation utilities from the <code>loo</code> package (a higher
value is preferred for this metric):</p>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">loo_compare</span><span class="op">(</span><span class="va">model3</span>, <span class="va">model4</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span></span>
<span><span class="co">## Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span></code></pre>
<pre><code><span><span class="co">##        elpd_diff se_diff</span></span>
<span><span class="co">## model4    0.0       0.0 </span></span>
<span><span class="co">## model3 -564.3      66.5</span></span></code></pre>
<p>The higher estimated log predictive density (ELPD) value for the
dynamic model suggests it provides a better fit to the in-sample
data.</p>
<p>Though it should be obvious that this model provides better
forecasts, we can quantify forecast performance for models 3 and 4 using
the <code>forecast</code> and <code>score</code> functions. Here we will
compare models based on their Discrete Ranked Probability Scores (a
lower value is preferred for this metric)</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fc_mod3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/forecast.mvgam.html">forecast</a></span><span class="op">(</span><span class="va">model3</span><span class="op">)</span></span>
<span><span class="va">fc_mod4</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/forecast.mvgam.html">forecast</a></span><span class="op">(</span><span class="va">model4</span><span class="op">)</span></span>
<span><span class="va">score_mod3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/score.mvgam_forecast.html">score</a></span><span class="op">(</span><span class="va">fc_mod3</span>, score <span class="op">=</span> <span class="st">'drps'</span><span class="op">)</span></span>
<span><span class="va">score_mod4</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/score.mvgam_forecast.html">score</a></span><span class="op">(</span><span class="va">fc_mod4</span>, score <span class="op">=</span> <span class="st">'drps'</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">score_mod4</span><span class="op">$</span><span class="va">PP</span><span class="op">$</span><span class="va">score</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">score_mod3</span><span class="op">$</span><span class="va">PP</span><span class="op">$</span><span class="va">score</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] -136.9747</span></span></code></pre>
<p>A strongly negative value here suggests the score for the dynamic
model (model 4) is much smaller than the score for the model with a
smooth function of time (model 3)</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by <a href="https://researchers.uq.edu.au/researcher/15140" class="external-link">Nicholas J Clark</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
