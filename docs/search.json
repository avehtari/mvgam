[{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"required-long-data-format","dir":"Articles","previous_headings":"","what":"Required long data format","title":"Formatting data for use in mvgam","text":"Manipulating data ‘long’ format necessary modelling mvgam. ‘long’ format, mean series x time observation needs entry dataframe list object wish use data modelling. simple example can viewed simulating data using sim_mvgam function. See ?sim_mvgam details","code":"simdat <- sim_mvgam(n_series = 4, T = 24, prop_missing = 0.2) head(simdat$data_train, 16) ##     y season year   series time ## 1   2      1    1 series_1    1 ## 2   3      1    1 series_2    1 ## 3   2      1    1 series_3    1 ## 4   2      1    1 series_4    1 ## 5   0      2    1 series_1    2 ## 6   3      2    1 series_2    2 ## 7   3      2    1 series_3    2 ## 8   0      2    1 series_4    2 ## 9   1      3    1 series_1    3 ## 10  1      3    1 series_2    3 ## 11  4      3    1 series_3    3 ## 12  0      3    1 series_4    3 ## 13  3      4    1 series_1    4 ## 14 NA      4    1 series_2    4 ## 15 NA      4    1 series_3    4 ## 16  3      4    1 series_4    4"},{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"series-as-a-factor-variable","dir":"Articles","previous_headings":"Required long data format","what":"series as a factor variable","title":"Formatting data for use in mvgam","text":"Notice four different time series simulated data, identified series-level indicator factor variable. important number levels matches number unique series data ensure indexing across series works properly underlying modelling functions. Several main workhorse functions package (including mvgam() get_mvgam_priors()) give error case, may worth checking anyway: Note can technically supply data series indicator, package assume using single time series. , better included confusion.","code":"class(simdat$data_train$series) ## [1] \"factor\" levels(simdat$data_train$series) ## [1] \"series_1\" \"series_2\" \"series_3\" \"series_4\" all(levels(simdat$data_train$series) %in% unique(simdat$data_train$series)) ## [1] TRUE"},{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"a-single-outcome-variable","dir":"Articles","previous_headings":"Required long data format","what":"A single outcome variable","title":"Formatting data for use in mvgam","text":"may also notices spread numeric / integer-classed outcome variable different columns. Rather, single column outcome variable, labelled y simulated data (though outcome labelled y). another important requirement mvgam, shouldn’t unfamiliar R users frequently use modelling packages lme4, mgcv, brms many regression modelling packages . advantage format now easy specify effects vary among time series: Depending observation families plan use building models, may restrictions need satisfied within outcome variable. example, Beta regression can handle proportional data, values >= 1 <= 0 allowed. Likewise, Poisson regression can handle non-negative integers. regression functions R assume user knows issue warnings errors choose wrong distribution, often ends leading unhelpful error optimizer difficult interpret diagnose. mvgam attempt provide errors something simply allowed. example, can simulate data zero-centred Gaussian distribution (ensuring values < 1) attempt Beta regression mvgam using betar family: call gam using mgcv package leads model actually fits (though give unhelpful warning message): call mvgam gives us something useful: Please see ?mvgam_families information types responses package can handle restrictions","code":"summary(glm(y ~ series + time,             data = simdat$data_train,             family = poisson())) ##  ## Call: ## glm(formula = y ~ series + time, family = poisson(), data = simdat$data_train) ##  ## Coefficients: ##                Estimate Std. Error z value Pr(>|z|)    ## (Intercept)     0.24304    0.27119   0.896  0.37015    ## seriesseries_2  0.38948    0.27346   1.424  0.15438    ## seriesseries_3  0.78087    0.25731   3.035  0.00241 ** ## seriesseries_4 -0.36133    0.32553  -1.110  0.26701    ## time            0.01246    0.01768   0.705  0.48104    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for poisson family taken to be 1) ##  ##     Null deviance: 161.62  on 60  degrees of freedom ## Residual deviance: 140.99  on 56  degrees of freedom ##   (11 observations deleted due to missingness) ## AIC: 258.79 ##  ## Number of Fisher Scoring iterations: 5 summary(gam(y ~ series + s(time, by = series),             data = simdat$data_train,             family = poisson())) ##  ## Family: poisson  ## Link function: log  ##  ## Formula: ## y ~ series + s(time, by = series) ##  ## Parametric coefficients: ##                Estimate Std. Error z value Pr(>|z|)   ## (Intercept)      0.3629     0.2086   1.740   0.0819 . ## seriesseries_2  -1.5109     1.4864  -1.016   0.3094   ## seriesseries_3  -0.7010     0.6697  -1.047   0.2953   ## seriesseries_4  -0.3985     0.3330  -1.197   0.2314   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Approximate significance of smooth terms: ##                          edf Ref.df Chi.sq  p-value     ## s(time):seriesseries_1 1.000  1.000  0.036 0.850572     ## s(time):seriesseries_2 8.577  8.877 15.670 0.092017 .   ## s(time):seriesseries_3 8.543  8.933 30.274 0.000374 *** ## s(time):seriesseries_4 1.298  1.537  1.230 0.539553     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## R-sq.(adj) =  0.715   Deviance explained = 65.5% ## UBRE = 0.68285  Scale est. = 1         n = 61 gauss_dat <- data.frame(outcome = rnorm(10),                         series = factor('series1',                                         levels = 'series1'),                         time = 1:10) gauss_dat ##          outcome  series time ## 1   0.1660605580 series1    1 ## 2   1.5241908906 series1    2 ## 3   0.2700075110 series1    3 ## 4   1.8622153994 series1    4 ## 5  -1.2011344802 series1    5 ## 6  -1.1331587806 series1    6 ## 7   0.0005641071 series1    7 ## 8  -0.6097032999 series1    8 ## 9   1.2220741287 series1    9 ## 10  1.8483330116 series1   10 gam(outcome ~ time,     family = betar(),     data = gauss_dat) ## Warning in family$saturated.ll(y, prior.weights, theta): saturated likelihood ## may be inaccurate ##  ## Family: Beta regression(0.087)  ## Link function: logit  ##  ## Formula: ## outcome ~ time ## Total model degrees of freedom 2  ##  ## REML score: -182.0205 mvgam(outcome ~ time,       family = betar(),       data = gauss_dat) ## Error: Values <= 0 not allowed for beta responses"},{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"a-time-variable","dir":"Articles","previous_headings":"Required long data format","what":"A time variable","title":"Formatting data for use in mvgam","text":"requirement modelling mvgam numeric / integer-classed variable labelled time ensure modelling software knows arrange time series building models. setup still allows us formulate multivariate time series models. plan use autoregressive dynamic trend functions available mvgam (see ?mvgam_trends details available dynamic processes), need ensure time series entered fixed sampling interval (.e. time timesteps 1 2 time timesteps 2 3, etc…). note can missing observations () series. mvgam check , useful ensure missing timepoint x series combinations data. can generally simple dplyr call: Note models use dynamic components assume smaller values time older (.e. time = 1 came time = 2, etc…)","code":"# A function to ensure all timepoints within a sequence are identical all_times_avail = function(time, min_time, max_time){     identical(as.numeric(sort(time)),               as.numeric(seq.int(from = min_time, to = max_time))) }  # Get min and max times from the data min_time <- min(simdat$data_train$time) max_time <- max(simdat$data_train$time)  # Check that all times are recorded for each series data.frame(series = simdat$data_train$series,            time = simdat$data_train$time) %>%     dplyr::group_by(series) %>%     dplyr::summarise(all_there = all_times_avail(time,                                                  min_time,                                                  max_time)) -> checked_times if(any(checked_times$all_there == FALSE)){   warning(\"One or more series in is missing observations for one or more timepoints\") } else {   cat('All series have observations at all timepoints :)') } ## All series have observations at all timepoints :)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"checking-data-with-get_mvgam_priors","dir":"Articles","previous_headings":"","what":"Checking data with get_mvgam_priors","title":"Formatting data for use in mvgam","text":"get_mvgam_priors function designed return information parameters model whose prior distributions can modified user. , perform series checks ensure data formatted properly. can therefore useful new users ensuring isn’t anything strange going data setup. example, can replicate steps taken (check factor levels timepoint x series combinations) single call get_mvgam_priors. first simulate data timepoints time variable included data: Next call get_mvgam_priors simply specifying intercept-model, enough trigger checks: error useful tells us problem . many ways fill missing timepoints, correct way left user. don’t covariates, pretty easy using expand.grid: Now call get_mvgam_priors, using filled data, work: function also pick misaligned factor levels series variable. can check simulating, time adding additional factor level included data: Another call get_mvgam_priors brings useful error: Following message’s advice tells us level series_2 series variable, observations series data: Re-assigning levels fixes issue:","code":"bad_times <- data.frame(time = seq(1, 16, by = 2),                         series = factor('series_1'),                         outcome = rnorm(8)) bad_times ##   time   series    outcome ## 1    1 series_1 -0.6853424 ## 2    3 series_1 -1.4364053 ## 3    5 series_1  0.2405592 ## 4    7 series_1 -0.7739931 ## 5    9 series_1  0.3248164 ## 6   11 series_1 -0.2119142 ## 7   13 series_1  0.9151188 ## 8   15 series_1  1.0588870 get_mvgam_priors(outcome ~ 1,                  data = bad_times,                  family = gaussian()) ## Error: One or more series in data is missing observations for one or more timepoints bad_times %>%   dplyr::right_join(expand.grid(time = seq(min(bad_times$time),                                            max(bad_times$time)),                                 series = factor(unique(bad_times$series),                                                 levels = levels(bad_times$series)))) %>%   dplyr::arrange(time) -> good_times ## Joining with `by = join_by(time, series)` good_times ##    time   series    outcome ## 1     1 series_1 -0.6853424 ## 2     2 series_1         NA ## 3     3 series_1 -1.4364053 ## 4     4 series_1         NA ## 5     5 series_1  0.2405592 ## 6     6 series_1         NA ## 7     7 series_1 -0.7739931 ## 8     8 series_1         NA ## 9     9 series_1  0.3248164 ## 10   10 series_1         NA ## 11   11 series_1 -0.2119142 ## 12   12 series_1         NA ## 13   13 series_1  0.9151188 ## 14   14 series_1         NA ## 15   15 series_1  1.0588870 get_mvgam_priors(outcome ~ 1,                  data = good_times,                  family = gaussian()) ##                             param_name param_length           param_info ## 1                          (Intercept)            1          (Intercept) ## 2 vector<lower=0>[n_series] sigma_obs;            1 observation error sd ##                                 prior                  example_change ## 1 (Intercept) ~ student_t(3, 0, 2.5);     (Intercept) ~ normal(0, 1); ## 2   sigma_obs ~ student_t(3, 0, 2.5); sigma_obs ~ normal(0.93, 0.33); ##   new_lowerbound new_upperbound ## 1             NA             NA ## 2             NA             NA bad_levels <- data.frame(time = 1:8,                         series = factor('series_1',                                         levels = c('series_1',                                                    'series_2')),                         outcome = rnorm(8))  levels(bad_levels$series) ## [1] \"series_1\" \"series_2\" get_mvgam_priors(outcome ~ 1,                  data = bad_levels,                  family = gaussian()) ## Error: Mismatch between factor levels of \"series\" and unique values of \"series\" ## Use ##   `setdiff(levels(data$series), unique(data$series))`  ## and ##   `intersect(levels(data$series), unique(data$series))` ## for guidance setdiff(levels(bad_levels$series), unique(bad_levels$series)) ## [1] \"series_2\" bad_levels %>%   dplyr::mutate(series = droplevels(series)) -> good_levels levels(good_levels$series) ## [1] \"series_1\" get_mvgam_priors(outcome ~ 1,                  data = good_levels,                  family = gaussian()) ##                             param_name param_length           param_info ## 1                          (Intercept)            1          (Intercept) ## 2 vector<lower=0>[n_series] sigma_obs;            1 observation error sd ##                                    prior               example_change ## 1 (Intercept) ~ student_t(3, -0.8, 2.5);  (Intercept) ~ normal(0, 1); ## 2      sigma_obs ~ student_t(3, 0, 2.5); sigma_obs ~ normal(0, 0.19); ##   new_lowerbound new_upperbound ## 1             NA             NA ## 2             NA             NA"},{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"covariates-with-no-nas","dir":"Articles","previous_headings":"Checking data with get_mvgam_priors","what":"Covariates with no NAs","title":"Formatting data for use in mvgam","text":"Covariates can used models just using mgcv (see ?formula.gam details formula syntax). although outcome variable can NAs, covariates . regression software silently drop raws model matrix NAs, helpful debugging. mvgam get_mvgam_priors functions run simple checks , hopefully return useful errors finds missing values: Just like mgcv package, mvgam can also accept data list object. useful want set linear functional predictors even distributed lag predictors. checks run mvgam still work data. change cov predictor matrix: call mvgam returns error:","code":"miss_dat <- data.frame(outcome = rnorm(10),                        cov = c(NA, rnorm(9)),                        series = factor('series1',                                        levels = 'series1'),                        time = 1:10) miss_dat ##        outcome         cov  series time ## 1   0.52094669          NA series1    1 ## 2  -0.58644030  0.73867095 series1    2 ## 3   1.28310150 -0.58577764 series1    3 ## 4  -0.35030777 -1.07774912 series1    4 ## 5   0.82824135 -0.26907960 series1    5 ## 6   0.18857106  1.65804013 series1    6 ## 7  -0.36209231 -0.67063650 series1    7 ## 8  -0.02767463  2.52337077 series1    8 ## 9   0.63317969  0.02399786 series1    9 ## 10  1.97227522 -0.41125516 series1   10 get_mvgam_priors(outcome ~ cov,                  data = miss_dat,                  family = gaussian()) ## Error: Missing values found in data predictors: ##  Error in na.fail.default(structure(list(outcome = c(0.520946693584384, : missing values in object miss_dat <- list(outcome = rnorm(10),                  series = factor('series1',                                  levels = 'series1'),                  time = 1:10) miss_dat$cov <- matrix(rnorm(50), ncol = 5, nrow = 10) miss_dat$cov[2,3] <- NA get_mvgam_priors(outcome ~ cov,                  data = miss_dat,                  family = gaussian()) ## Error: Missing values found in data predictors: ##  Error in na.fail.default(structure(list(outcome = c(-2.90806279836404, : missing values in object"},{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"plotting-with-plot_mvgam_series","dir":"Articles","previous_headings":"","what":"Plotting with plot_mvgam_series","title":"Formatting data for use in mvgam","text":"Plotting data useful way ensure everything looks ok, ’ve gone throug checks factor levels timepoint x series combinations. plot_mvgam_series function take supplied data plot either series line plots (choose series = '') set plots describe distribution single time series. example, plot time series data, highlight single series plot, can use:  can look closely distribution first time series:  split data training testing folds (.e. forecast evaluation), can include test data plots:","code":"plot_mvgam_series(data = simdat$data_train,                    y = 'y',                    series = 'all') plot_mvgam_series(data = simdat$data_train,                    y = 'y',                    series = 1) plot_mvgam_series(data = simdat$data_train,                   newdata = simdat$data_test,                   y = 'y',                    series = 1)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/data_in_mvgam.html","id":"example-with-neon-tick-data","dir":"Articles","previous_headings":"","what":"Example with NEON tick data","title":"Formatting data for use in mvgam","text":"give one example data can reformatted mvgam modelling, use observations National Ecological Observatory Network (NEON) tick drag cloth samples. Ixodes scapularis widespread tick species capable transmitting diversity parasites animals humans, many zoonotic. Due medical ecological importance tick species, common goal understand factors influence abundances. NEON field team carries standardised long-term monitoring tick abundances well important indicators ecological change. Nymphal abundance . scapularis routinely recorded across NEON plots using field sampling method called drag cloth sampling, common method sampling ticks landscape. Field researchers sample ticks dragging large cloth behind terrain suspected harboring ticks, usually working grid-like pattern. sites sampled since 2014, resulting rich dataset nymph abundance time series. tick time series show strong seasonality incorporate many challenging features associated ecological data including overdispersion, high proportions missingness irregular sampling time, making useful exploring utility dynamic GAMs. begin loading NEON tick data years 2014 - 2021, downloaded NEON prepared described Clark & Wells 2022. can read bit data using call ?all_neon_tick_data exercise, use epiWeek variable index seasonality, work observations sampling plots (labelled plotID column): Now can select target species want (. scapularis), filter correct plot IDs convert epiWeek variable character numeric: Now tricky part: need fill missing observations NAs. tick data sparse field observers go sample possible epiWeek. many particular weeks observations included data. can use expand.grid take care : Create series variable needed mvgam modelling: Now create time variable, needs track Year epiWeek unique series. n function dplyr often useful generating time index grouped dataframes: Check factor levels series: looks good, rigorous check using get_mvgam_priors: can also set model mvgam use run_model = FALSE ensure necessary steps creating modelling code objects run. recommended use cmdstanr backend possible, auto-formatting options available package useful checking package-generated Stan code inefficiencies can fixed lead sampling performance improvements: call runs without issue, resulting object now contains model code data objects needed initiate sampling:","code":"data(\"all_neon_tick_data\") str(dplyr::ungroup(all_neon_tick_data)) ## tibble [3,505 × 24] (S3: tbl_df/tbl/data.frame) ##  $ Year                : num [1:3505] 2015 2015 2015 2015 2015 ... ##  $ epiWeek             : chr [1:3505] \"37\" \"38\" \"39\" \"40\" ... ##  $ yearWeek            : chr [1:3505] \"201537\" \"201538\" \"201539\" \"201540\" ... ##  $ plotID              : chr [1:3505] \"BLAN_005\" \"BLAN_005\" \"BLAN_005\" \"BLAN_005\" ... ##  $ siteID              : chr [1:3505] \"BLAN\" \"BLAN\" \"BLAN\" \"BLAN\" ... ##  $ nlcdClass           : chr [1:3505] \"deciduousForest\" \"deciduousForest\" \"deciduousForest\" \"deciduousForest\" ... ##  $ decimalLatitude     : num [1:3505] 39.1 39.1 39.1 39.1 39.1 ... ##  $ decimalLongitude    : num [1:3505] -78 -78 -78 -78 -78 ... ##  $ elevation           : num [1:3505] 168 168 168 168 168 ... ##  $ totalSampledArea    : num [1:3505] 162 NA NA NA 162 NA NA NA NA 164 ... ##  $ amblyomma_americanum: num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ ixodes_scapularis   : num [1:3505] 2 NA NA NA 0 NA NA NA NA 0 ... ##  $ time                : Date[1:3505], format: \"2015-09-13\" \"2015-09-20\" ... ##  $ RHMin_precent       : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ RHMin_variance      : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ RHMax_precent       : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ RHMax_variance      : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ airTempMin_degC     : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ airTempMin_variance : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ airTempMax_degC     : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ airTempMax_variance : num [1:3505] NA NA NA NA NA NA NA NA NA NA ... ##  $ soi                 : num [1:3505] -18.4 -17.9 -23.5 -28.4 -25.9 ... ##  $ cum_sdd             : num [1:3505] 173 173 173 173 173 ... ##  $ cum_gdd             : num [1:3505] 1129 1129 1129 1129 1129 ... plotIDs <- c('SCBI_013','SCBI_002',              'SERC_001','SERC_005',              'SERC_006','SERC_012',              'BLAN_012','BLAN_005') model_dat <- all_neon_tick_data %>%   dplyr::ungroup() %>%   dplyr::mutate(target = ixodes_scapularis) %>%   dplyr::filter(plotID %in% plotIDs) %>%   dplyr::select(Year, epiWeek, plotID, target) %>%   dplyr::mutate(epiWeek = as.numeric(epiWeek)) model_dat %>%   # Create all possible combos of plotID, Year and epiWeek;    # missing outcomes will be filled in as NA   dplyr::full_join(expand.grid(plotID = unique(model_dat$plotID),                                Year = unique(model_dat$Year),                                epiWeek = seq(1, 52))) %>%      # left_join back to original data so plotID and siteID will   # match up, in case you need the siteID for anything else later on   dplyr::left_join(all_neon_tick_data %>%                      dplyr::select(siteID, plotID) %>%                      dplyr::distinct()) -> model_dat ## Joining with `by = join_by(Year, epiWeek, plotID)` ## Joining with `by = join_by(plotID)` model_dat %>%   dplyr::mutate(series = plotID,                 y = target) %>%   dplyr::mutate(siteID = factor(siteID),                 series = factor(series)) %>%   dplyr::select(-target, -plotID) %>%   dplyr::arrange(Year, epiWeek, series) -> model_dat model_dat %>%   dplyr::ungroup() %>%   dplyr::group_by(series) %>%   dplyr::arrange(Year, epiWeek) %>%   dplyr::mutate(time = seq(1, dplyr::n())) %>%   dplyr::ungroup() -> model_dat levels(model_dat$series) ## [1] \"BLAN_005\" \"BLAN_012\" \"SCBI_002\" \"SCBI_013\" \"SERC_001\" \"SERC_005\" \"SERC_006\" ## [8] \"SERC_012\" get_mvgam_priors(y ~ 1,                  data = model_dat,                  family = poisson()) ##    param_name param_length  param_info                                  prior ## 1 (Intercept)            1 (Intercept) (Intercept) ~ student_t(3, -2.3, 2.5); ##                example_change new_lowerbound new_upperbound ## 1 (Intercept) ~ normal(0, 1);             NA             NA testmod <- mvgam(y ~ s(epiWeek, by = series, bs = 'cc') +                    s(series, bs = 're'),                  trend_model = 'AR1',                  data = model_dat,                  backend = 'cmdstanr',                  run_model = FALSE) str(testmod$model_data) ## List of 25 ##  $ y           : num [1:416, 1:8] -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ... ##  $ n           : int 416 ##  $ X           : num [1:3328, 1:73] 1 1 1 1 1 1 1 1 1 1 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##   .. ..$ : chr [1:3328] \"1\" \"2\" \"3\" \"4\" ... ##   .. ..$ : chr [1:73] \"X.Intercept.\" \"V2\" \"V3\" \"V4\" ... ##  $ S1          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ zero        : num [1:73] 0 0 0 0 0 0 0 0 0 0 ... ##  $ S2          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ S3          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ S4          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ S5          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ S6          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ S7          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ S8          : num [1:8, 1:8] 1.037 -0.416 0.419 0.117 0.188 ... ##  $ p_coefs     : Named num 0.659 ##   ..- attr(*, \"names\")= chr \"(Intercept)\" ##  $ p_taus      : num 387 ##  $ ytimes      : int [1:416, 1:8] 1 9 17 25 33 41 49 57 65 73 ... ##  $ n_series    : int 8 ##  $ sp          : Named num [1:9] 1.19 4.84 4.21 16.59 2.61 ... ##   ..- attr(*, \"names\")= chr [1:9] \"s(epiWeek):seriesBLAN_005\" \"s(epiWeek):seriesBLAN_012\" \"s(epiWeek):seriesSCBI_002\" \"s(epiWeek):seriesSCBI_013\" ... ##  $ y_observed  : num [1:416, 1:8] 0 0 0 0 0 0 0 0 0 0 ... ##  $ total_obs   : int 3328 ##  $ num_basis   : int 73 ##  $ n_sp        : num 9 ##  $ n_nonmissing: int 400 ##  $ obs_ind     : int [1:400] 89 93 98 101 115 118 121 124 127 130 ... ##  $ flat_ys     : num [1:400] 2 0 0 0 0 0 0 25 36 14 ... ##  $ flat_xs     : num [1:400, 1:73] 1 1 1 1 1 1 1 1 1 1 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##   .. ..$ : chr [1:400] \"705\" \"737\" \"777\" \"801\" ... ##   .. ..$ : chr [1:73] \"X.Intercept.\" \"V2\" \"V3\" \"V4\" ... ##  - attr(*, \"trend_model\")= chr \"AR1\" code(testmod) ## // Stan model code generated by package mvgam ## data { ##   int<lower=0> total_obs; // total number of observations ##   int<lower=0> n; // number of timepoints per series ##   int<lower=0> n_sp; // number of smoothing parameters ##   int<lower=0> n_series; // number of series ##   int<lower=0> num_basis; // total number of basis coefficients ##   vector[num_basis] zero; // prior locations for basis coefficients ##   matrix[total_obs, num_basis] X; // mgcv GAM design matrix ##   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) ##   matrix[8, 8] S1; // mgcv smooth penalty matrix S1 ##   matrix[8, 8] S2; // mgcv smooth penalty matrix S2 ##   matrix[8, 8] S3; // mgcv smooth penalty matrix S3 ##   matrix[8, 8] S4; // mgcv smooth penalty matrix S4 ##   matrix[8, 8] S5; // mgcv smooth penalty matrix S5 ##   matrix[8, 8] S6; // mgcv smooth penalty matrix S6 ##   matrix[8, 8] S7; // mgcv smooth penalty matrix S7 ##   matrix[8, 8] S8; // mgcv smooth penalty matrix S8 ##   int<lower=0> n_nonmissing; // number of nonmissing observations ##   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations ##   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations ##   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations ## } ## parameters { ##   // raw basis coefficients ##   vector[num_basis] b_raw; ##    ##   // random effect variances ##   vector<lower=0>[1] sigma_raw; ##    ##   // random effect means ##   vector[1] mu_raw; ##    ##   // latent trend AR1 terms ##   vector<lower=-1.5, upper=1.5>[n_series] ar1; ##    ##   // latent trend variance parameters ##   vector<lower=0>[n_series] sigma; ##    ##   // latent trends ##   matrix[n, n_series] trend; ##    ##   // smoothing parameters ##   vector<lower=0>[n_sp] lambda; ## } ## transformed parameters { ##   // basis coefficients ##   vector[num_basis] b; ##   b[1 : 65] = b_raw[1 : 65]; ##   b[66 : 73] = mu_raw[1] + b_raw[66 : 73] * sigma_raw[1]; ## } ## model { ##   // prior for random effect population variances ##   sigma_raw ~ student_t(3, 0, 2.5); ##    ##   // prior for random effect population means ##   mu_raw ~ std_normal(); ##    ##   // prior for (Intercept)... ##   b_raw[1] ~ student_t(3, -2.3, 2.5); ##    ##   // prior for s(epiWeek):seriesBLAN_005... ##   b_raw[2 : 9] ~ multi_normal_prec(zero[2 : 9], S1[1 : 8, 1 : 8] * lambda[1]); ##    ##   // prior for s(epiWeek):seriesBLAN_012... ##   b_raw[10 : 17] ~ multi_normal_prec(zero[10 : 17], ##                                      S2[1 : 8, 1 : 8] * lambda[2]); ##    ##   // prior for s(epiWeek):seriesSCBI_002... ##   b_raw[18 : 25] ~ multi_normal_prec(zero[18 : 25], ##                                      S3[1 : 8, 1 : 8] * lambda[3]); ##    ##   // prior for s(epiWeek):seriesSCBI_013... ##   b_raw[26 : 33] ~ multi_normal_prec(zero[26 : 33], ##                                      S4[1 : 8, 1 : 8] * lambda[4]); ##    ##   // prior for s(epiWeek):seriesSERC_001... ##   b_raw[34 : 41] ~ multi_normal_prec(zero[34 : 41], ##                                      S5[1 : 8, 1 : 8] * lambda[5]); ##    ##   // prior for s(epiWeek):seriesSERC_005... ##   b_raw[42 : 49] ~ multi_normal_prec(zero[42 : 49], ##                                      S6[1 : 8, 1 : 8] * lambda[6]); ##    ##   // prior for s(epiWeek):seriesSERC_006... ##   b_raw[50 : 57] ~ multi_normal_prec(zero[50 : 57], ##                                      S7[1 : 8, 1 : 8] * lambda[7]); ##    ##   // prior for s(epiWeek):seriesSERC_012... ##   b_raw[58 : 65] ~ multi_normal_prec(zero[58 : 65], ##                                      S8[1 : 8, 1 : 8] * lambda[8]); ##    ##   // prior (non-centred) for s(series)... ##   b_raw[66 : 73] ~ std_normal(); ##    ##   // priors for AR parameters ##   ar1 ~ std_normal(); ##    ##   // priors for smoothing parameters ##   lambda ~ normal(5, 30); ##    ##   // priors for latent trend variance parameters ##   sigma ~ student_t(3, 0, 2.5); ##    ##   // trend estimates ##   trend[1, 1 : n_series] ~ normal(0, sigma); ##   for (s in 1 : n_series) { ##     trend[2 : n, s] ~ normal(ar1[s] * trend[1 : (n - 1), s], sigma[s]); ##   } ##   { ##     // likelihood functions ##     vector[n_nonmissing] flat_trends; ##     flat_trends = to_vector(trend)[obs_ind]; ##     flat_ys ~ poisson_log_glm(append_col(flat_xs, flat_trends), 0.0, ##                               append_row(b, 1.0)); ##   } ## } ## generated quantities { ##   vector[total_obs] eta; ##   matrix[n, n_series] mus; ##   vector[n_sp] rho; ##   vector[n_series] tau; ##   array[n, n_series] int ypred; ##   rho = log(lambda); ##   for (s in 1 : n_series) { ##     tau[s] = pow(sigma[s], -2.0); ##   } ##    ##   // posterior predictions ##   eta = X * b; ##   for (s in 1 : n_series) { ##     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; ##     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]); ##   } ## }"},{"path":"https://nicholasjclark.github.io/mvgam/articles/forecast_evaluation.html","id":"simulating-discrete-time-series","dir":"Articles","previous_headings":"","what":"Simulating discrete time series","title":"Forecasting and forecast evaluation in mvgam","text":"begin simulating data show forecasts computed evaluated mvgam. sim_mvgam() function can used simulate series come variety response distributions well seasonal patterns /dynamic temporal patterns. simulate collection three time count-valued series. series share seasonal pattern different temporal dynamics. setting trend_model = 'GP' prop_trend = 0.75, generating time series smooth underlying temporal trends (evolving Gaussian Processes squared exponential kernel) moderate seasonal patterns. observations Poisson-distributed allow 10% observations missing. returned object list containing training testing data (sim_mvgam() automatically splits data folds us) together information data generating process used simulate data series case shared seasonal pattern, can visualise:  resulting time series similar might encounter dealing count-valued data can take small counts:  individual series, can plot training testing data, well specific features observed data:","code":"set.seed(2345) simdat <- sim_mvgam(T = 100,                      n_series = 3,                      trend_model = 'GP',                     prop_trend = 0.75,                     family = poisson(),                     prop_missing = 0.10) str(simdat) ## List of 6 ##  $ data_train        :'data.frame':  225 obs. of  5 variables: ##   ..$ y     : int [1:225] 0 1 3 0 0 0 1 0 3 1 ... ##   ..$ season: int [1:225] 1 1 1 2 2 2 3 3 3 4 ... ##   ..$ year  : int [1:225] 1 1 1 1 1 1 1 1 1 1 ... ##   ..$ series: Factor w/ 3 levels \"series_1\",\"series_2\",..: 1 2 3 1 2 3 1 2 3 1 ... ##   ..$ time  : int [1:225] 1 1 1 2 2 2 3 3 3 4 ... ##  $ data_test         :'data.frame':  75 obs. of  5 variables: ##   ..$ y     : int [1:75] 0 1 1 0 0 0 2 2 0 NA ... ##   ..$ season: int [1:75] 4 4 4 5 5 5 6 6 6 7 ... ##   ..$ year  : int [1:75] 7 7 7 7 7 7 7 7 7 7 ... ##   ..$ series: Factor w/ 3 levels \"series_1\",\"series_2\",..: 1 2 3 1 2 3 1 2 3 1 ... ##   ..$ time  : int [1:75] 76 76 76 77 77 77 78 78 78 79 ... ##  $ true_corrs        : num [1:3, 1:3] 1 0.465 -0.577 0.465 1 ... ##  $ true_trends       : num [1:100, 1:3] -1.45 -1.54 -1.61 -1.67 -1.73 ... ##  $ global_seasonality: num [1:100] 0.0559 0.6249 1.3746 1.6805 0.5246 ... ##  $ trend_params      :List of 2 ##   ..$ alpha: num [1:3] 0.767 0.988 0.897 ##   ..$ rho  : num [1:3] 6.02 6.94 5.04 plot(simdat$global_seasonality[1:12],       type = 'l', lwd = 2,      ylab = 'Relative effect',      xlab = 'Season',      bty = 'l') plot_mvgam_series(data = simdat$data_train,                    series = 'all') plot_mvgam_series(data = simdat$data_train,                    newdata = simdat$data_test,                   series = 1) plot_mvgam_series(data = simdat$data_train,                    newdata = simdat$data_test,                   series = 2) plot_mvgam_series(data = simdat$data_train,                    newdata = simdat$data_test,                   series = 3)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/forecast_evaluation.html","id":"modelling-dynamics-with-splines","dir":"Articles","previous_headings":"Simulating discrete time series","what":"Modelling dynamics with splines","title":"Forecasting and forecast evaluation in mvgam","text":"first model fit uses shared cyclic spline capture repeated seasonality, well series-specific splines time capture long-term dynamics. allow temporal splines fairly complex can capture much temporal variation possible: model fits without issue: can plot partial effects splines see estimated highly nonlinear","code":"mod1 <- mvgam(y ~ s(season, bs = 'cc', k = 8) +                  s(time, by = series, bs = 'cr', k = 20),               knots = list(season = c(0.5, 12.5)),               trend_model = 'None',               data = simdat$data_train) summary(mod1, include_betas = FALSE) ## GAM formula: ## y ~ s(season, bs = \"cc\", k = 8) + s(time, by = series, bs = \"cr\",  ##     k = 20) ##  ## Family: ## poisson ##  ## Link function: ## log ##  ## Trend model: ## None ##  ## N series: ## 3  ##  ## N timepoints: ## 75  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM coefficient (beta) estimates: ##              2.5%   50%  97.5% Rhat n_eff ## (Intercept) -0.41 -0.21 -0.039    1   813 ##  ## Approximate significance of GAM observation smooths: ##                         edf Chi.sq p-value     ## s(season)              3.77   9.48 0.01603 *   ## s(time):seriesseries_1 6.50  13.64 0.09218 .   ## s(time):seriesseries_2 9.49 256.09 0.00021 *** ## s(time):seriesseries_3 5.93  16.79 0.04680 *   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:52:33 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot(mod1, type = 'smooths')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/forecast_evaluation.html","id":"modelling-dynamics-with-gps","dir":"Articles","previous_headings":"Simulating discrete time series","what":"Modelling dynamics with GPs","title":"Forecasting and forecast evaluation in mvgam","text":"showing produce evaluate forecasts, fit second model data two models can compared. model equivalent , except now use Gaussian Processes model series-specific dynamics. makes use gp() function brms, can fit Hilbert space approximate GPs. See ?brms::gp details. summary model now contains information GP parameters time series: can plot posteriors parameters, parameter matter, using bayesplot routines. First marginal deviation (\\(\\alpha\\)) parameters:  now length scale (\\(\\rho\\)) parameters:  can also plot nonlinear effects : can also plotted using marginaleffects utilities:  estimates temporal trends fairly similar two models, see produce similar forecasts","code":"mod2 <- mvgam(y ~ s(season, bs = 'cc', k = 8) +                  gp(time, by = series, c = 5/4, k = 20,                    scale = FALSE),               knots = list(season = c(0.5, 12.5)),               trend_model = 'None',               data = simdat$data_train) summary(mod2, include_betas = FALSE) ## GAM formula: ## y ~ s(season, bs = \"cc\", k = 8) + gp(time, by = series, c = 5/4,  ##     k = 20, scale = FALSE) ##  ## Family: ## poisson ##  ## Link function: ## log ##  ## Trend model: ## None ##  ## N series: ## 3  ##  ## N timepoints: ## 75  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM coefficient (beta) estimates: ##             2.5%   50% 97.5% Rhat n_eff ## (Intercept) -1.1 -0.52  0.31    1   768 ##  ## GAM gp term marginal deviation (alpha) and length scale (rho) estimates: ##                               2.5%  50% 97.5% Rhat n_eff ## alpha_gp(time):seriesseries_1 0.21  0.8   2.1 1.01   763 ## alpha_gp(time):seriesseries_2 0.74  1.4   2.9 1.00  1028 ## alpha_gp(time):seriesseries_3 0.50  1.1   2.8 1.00  1026 ## rho_gp(time):seriesseries_1   1.20  5.1  23.0 1.00   681 ## rho_gp(time):seriesseries_2   2.20 10.0  17.0 1.00   644 ## rho_gp(time):seriesseries_3   1.50  8.8  23.0 1.00   819 ##  ## Approximate significance of GAM observation smooths: ##           edf Chi.sq p-value     ## s(season)   6     25 0.00016 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 4 of 2000 iterations ended with a divergence (0.2%) ##  *Try running with larger adapt_delta to remove the divergences ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:53:19 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) mcmc_plot(mod2, variable = c('alpha_gp'), regex = TRUE, type = 'areas') mcmc_plot(mod2, variable = c('rho_gp'), regex = TRUE, type = 'areas') plot(mod2, type = 'smooths') require('ggplot2') plot_predictions(mod2,                   condition = c('time', 'series', 'series'),                  type = 'link') +   theme(legend.position = 'none')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/forecast_evaluation.html","id":"forecasting-with-the-forecast-function","dir":"Articles","previous_headings":"","what":"Forecasting with the forecast() function","title":"Forecasting and forecast evaluation in mvgam","text":"Probabilistic forecasts can computed two main ways mvgam. first take model fit training data (two example models) produce temporal predictions posterior predictive distribution feeding newdata forecast() function. crucial newdata fed forecast() function follows sequentially data used fit model (internally checked package might headache data supplied specific time-order). calling forecast() function, option generate different kinds predictions (.e. predicting link scale, response scale produce expectations; see ?forecast.mvgam details). use default produce forecasts response scale, common way evaluate forecast distributions objects created class mvgam_forecast, contain information hindcast distributions, forecast distributions true observations series data: can plot forecasts series model using S3 plot method objects class:       Clearly two models produce equivalent forecasts. come back scoring forecasts moment.","code":"fc_mod1 <- forecast(mod1, newdata = simdat$data_test) fc_mod2 <- forecast(mod2, newdata = simdat$data_test) str(fc_mod1) ## List of 16 ##  $ call              :Class 'formula'  language y ~ s(season, bs = \"cc\", k = 8) + s(time, by = series, bs = \"cr\", k = 20) ##   .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv>  ##  $ trend_call        : NULL ##  $ family            : chr \"poisson\" ##  $ family_pars       : NULL ##  $ trend_model       : chr \"None\" ##  $ drift             : logi FALSE ##  $ use_lv            : logi FALSE ##  $ fit_engine        : chr \"stan\" ##  $ type              : chr \"response\" ##  $ series_names      : Factor w/ 3 levels \"series_1\",\"series_2\",..: 1 2 3 ##  $ train_observations:List of 3 ##   ..$ series_1: int [1:75] 0 0 1 1 0 0 0 0 0 0 ... ##   ..$ series_2: int [1:75] 1 0 0 1 1 0 1 0 1 2 ... ##   ..$ series_3: int [1:75] 3 0 3 NA 2 1 1 1 1 3 ... ##  $ train_times       : int [1:75] 1 2 3 4 5 6 7 8 9 10 ... ##  $ test_observations :List of 3 ##   ..$ series_1: int [1:25] 0 0 2 NA 0 2 2 1 1 1 ... ##   ..$ series_2: int [1:25] 1 0 2 1 1 3 0 1 0 NA ... ##   ..$ series_3: int [1:25] 1 0 0 1 0 0 1 0 1 0 ... ##  $ test_times        : int [1:25] 76 77 78 79 80 81 82 83 84 85 ... ##  $ hindcasts         :List of 3 ##   ..$ series_1: num [1:2000, 1:75] 1 1 0 0 0 1 1 1 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : NULL ##   .. .. ..$ : chr [1:75] \"ypred[1,1]\" \"ypred[2,1]\" \"ypred[3,1]\" \"ypred[4,1]\" ... ##   ..$ series_2: num [1:2000, 1:75] 0 0 0 0 0 0 0 1 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : NULL ##   .. .. ..$ : chr [1:75] \"ypred[1,2]\" \"ypred[2,2]\" \"ypred[3,2]\" \"ypred[4,2]\" ... ##   ..$ series_3: num [1:2000, 1:75] 3 0 2 1 0 1 2 1 5 1 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : NULL ##   .. .. ..$ : chr [1:75] \"ypred[1,3]\" \"ypred[2,3]\" \"ypred[3,3]\" \"ypred[4,3]\" ... ##  $ forecasts         :List of 3 ##   ..$ series_1: num [1:2000, 1:25] 1 3 2 1 0 0 1 1 0 0 ... ##   ..$ series_2: num [1:2000, 1:25] 6 0 0 0 0 2 0 0 0 0 ... ##   ..$ series_3: num [1:2000, 1:25] 0 1 1 3 3 1 3 2 4 2 ... ##  - attr(*, \"class\")= chr \"mvgam_forecast\" plot(fc_mod1, series = 1) ## Out of sample CRPS: ## [1] 14.62964 plot(fc_mod2, series = 1) ## Out of sample DRPS: ## [1] 10.92516 plot(fc_mod1, series = 2) ## Out of sample CRPS: ## [1] 84201962708 plot(fc_mod2, series = 2) ## Out of sample DRPS: ## [1] 14.31168 plot(fc_mod1, series = 3) ## Out of sample CRPS: ## [1] 32.44136 plot(fc_mod2, series = 3) ## Out of sample DRPS: ## [1] 15.44332"},{"path":"https://nicholasjclark.github.io/mvgam/articles/forecast_evaluation.html","id":"forecasting-with-newdata-in-mvgam","dir":"Articles","previous_headings":"","what":"Forecasting with newdata in mvgam()","title":"Forecasting and forecast evaluation in mvgam","text":"second way can produce forecasts mvgam feed testing data directly mvgam() function newdata. include testing data missing observations automatically predicted posterior predictive distribution using generated quantities block Stan. example, can refit mod2 include testing data automatic forecasts: model already contains forecast distribution, need feed newdata forecast() function: forecasts nearly identical calculated previously:","code":"mod2 <- mvgam(y ~ s(season, bs = 'cc', k = 8) +                  gp(time, by = series, c = 5/4, k = 20,                    scale = FALSE),               knots = list(season = c(0.5, 12.5)),               trend_model = 'None',               data = simdat$data_train,               newdata = simdat$data_test) fc_mod2 <- forecast(mod2) plot(fc_mod2, series = 1) ## Out of sample DRPS: ## [1] 10.85762"},{"path":"https://nicholasjclark.github.io/mvgam/articles/forecast_evaluation.html","id":"scoring-forecast-distributions","dir":"Articles","previous_headings":"","what":"Scoring forecast distributions","title":"Forecasting and forecast evaluation in mvgam","text":"primary purpose mvgam_forecast class readily allow forecast evaluations series data, using variety possible scoring functions. See ?mvgam::score.mvgam_forecast view types scores available. useful scoring metric Continuous Rank Probability Score (CRPS). CRPS value similar might get calculated weighted absolute error using full forecast distribution. returned list contains data.frame series data shows CRPS score evaluation testing data, along useful information fit forecast distribution. particular, given logical value (1s 0s) telling us whether true value within pre-specified credible interval (.e. coverage forecast distribution). default interval width 0.9, hope values in_interval column take 1 approximately 90% time. value can changed wish compute different coverages, say using 60% interval: can also compare forecasts sample observations using Expected Log Predictive Density (ELPD; also known log score). ELPD strictly proper scoring rule can applied distributional forecast, compute need predictions link scale rather outcome scale. advantageous change type prediction can get using forecast() function: Finally, multiple time series may also make sense use multivariate proper scoring rule. mvgam offers two options: Energy score Variogram score. first penalizes forecast distributions less well calibrated truth, second penalizes forecasts capture observed true correlation structure. score use depends goals, easy compute: returned object still provides information interval coverage individual series, single score per horizon now (provided all_series slot): can use score(s) choice compare different models. example, can compute plot difference CRPS scores series data. , negative value means Gaussian Process model (mod2) better, positive value means spline model (mod1) better.    GP model consistently gives better forecasts, difference scores grows quickly forecast horizon increases. unexpected given way splines linearly extrapolate outside range training data","code":"crps_mod1 <- score(fc_mod1, score = 'crps') str(crps_mod1) ## List of 4 ##  $ series_1  :'data.frame':  25 obs. of  5 variables: ##   ..$ score         : num [1:25] 0.1938 0.1366 1.355 NA 0.0348 ... ##   ..$ in_interval   : num [1:25] 1 1 1 NA 1 1 1 1 1 1 ... ##   ..$ interval_width: num [1:25] 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 ... ##   ..$ eval_horizon  : int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##   ..$ score_type    : chr [1:25] \"crps\" \"crps\" \"crps\" \"crps\" ... ##  $ series_2  :'data.frame':  25 obs. of  5 variables: ##   ..$ score         : num [1:25] 0.379 0.306 0.941 0.5 0.573 ... ##   ..$ in_interval   : num [1:25] 1 1 1 1 1 1 1 1 1 NA ... ##   ..$ interval_width: num [1:25] 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 ... ##   ..$ eval_horizon  : int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##   ..$ score_type    : chr [1:25] \"crps\" \"crps\" \"crps\" \"crps\" ... ##  $ series_3  :'data.frame':  25 obs. of  5 variables: ##   ..$ score         : num [1:25] 0.32 0.556 0.379 0.362 0.219 ... ##   ..$ in_interval   : num [1:25] 1 1 1 1 1 1 1 1 1 1 ... ##   ..$ interval_width: num [1:25] 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 ... ##   ..$ eval_horizon  : int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##   ..$ score_type    : chr [1:25] \"crps\" \"crps\" \"crps\" \"crps\" ... ##  $ all_series:'data.frame':  25 obs. of  3 variables: ##   ..$ score       : num [1:25] 0.892 0.999 2.675 NA 0.827 ... ##   ..$ eval_horizon: int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##   ..$ score_type  : chr [1:25] \"sum_crps\" \"sum_crps\" \"sum_crps\" \"sum_crps\" ... crps_mod1$series_1 ##         score in_interval interval_width eval_horizon score_type ## 1  0.19375525           1            0.9            1       crps ## 2  0.13663925           1            0.9            2       crps ## 3  1.35502175           1            0.9            3       crps ## 4          NA          NA            0.9            4       crps ## 5  0.03482775           1            0.9            5       crps ## 6  1.55416700           1            0.9            6       crps ## 7  1.51028900           1            0.9            7       crps ## 8  0.62121225           1            0.9            8       crps ## 9  0.62630125           1            0.9            9       crps ## 10 0.59853100           1            0.9           10       crps ## 11 1.30998625           1            0.9           11       crps ## 12 2.04829775           1            0.9           12       crps ## 13 0.61251800           1            0.9           13       crps ## 14 0.14052300           1            0.9           14       crps ## 15 0.65110800           1            0.9           15       crps ## 16 0.07973125           1            0.9           16       crps ## 17 0.07675600           1            0.9           17       crps ## 18 0.09382375           1            0.9           18       crps ## 19 0.12356725           1            0.9           19       crps ## 20         NA          NA            0.9           20       crps ## 21 0.20173600           1            0.9           21       crps ## 22 0.84066825           1            0.9           22       crps ## 23         NA          NA            0.9           23       crps ## 24 1.06489225           1            0.9           24       crps ## 25 0.75528825           1            0.9           25       crps crps_mod1 <- score(fc_mod1, score = 'crps', interval_width = 0.6) crps_mod1$series_1 ##         score in_interval interval_width eval_horizon score_type ## 1  0.19375525           1            0.6            1       crps ## 2  0.13663925           1            0.6            2       crps ## 3  1.35502175           0            0.6            3       crps ## 4          NA          NA            0.6            4       crps ## 5  0.03482775           1            0.6            5       crps ## 6  1.55416700           0            0.6            6       crps ## 7  1.51028900           0            0.6            7       crps ## 8  0.62121225           1            0.6            8       crps ## 9  0.62630125           1            0.6            9       crps ## 10 0.59853100           1            0.6           10       crps ## 11 1.30998625           0            0.6           11       crps ## 12 2.04829775           0            0.6           12       crps ## 13 0.61251800           1            0.6           13       crps ## 14 0.14052300           1            0.6           14       crps ## 15 0.65110800           1            0.6           15       crps ## 16 0.07973125           1            0.6           16       crps ## 17 0.07675600           1            0.6           17       crps ## 18 0.09382375           1            0.6           18       crps ## 19 0.12356725           1            0.6           19       crps ## 20         NA          NA            0.6           20       crps ## 21 0.20173600           1            0.6           21       crps ## 22 0.84066825           1            0.6           22       crps ## 23         NA          NA            0.6           23       crps ## 24 1.06489225           1            0.6           24       crps ## 25 0.75528825           1            0.6           25       crps link_mod1 <- forecast(mod1, newdata = simdat$data_test, type = 'link') score(link_mod1, score = 'elpd')$series_1 ##         score eval_horizon score_type ## 1  -0.5304414            1       elpd ## 2  -0.4298955            2       elpd ## 3  -2.9617583            3       elpd ## 4          NA            4       elpd ## 5  -0.2007644            5       elpd ## 6  -3.3781408            6       elpd ## 7  -3.2729088            7       elpd ## 8  -2.0363750            8       elpd ## 9  -2.0670612            9       elpd ## 10 -2.0844818           10       elpd ## 11 -3.0576463           11       elpd ## 12 -3.6291058           12       elpd ## 13 -2.1692669           13       elpd ## 14 -0.2960899           14       elpd ## 15 -2.3738851           15       elpd ## 16 -0.2160804           16       elpd ## 17 -0.2036782           17       elpd ## 18 -0.2115539           18       elpd ## 19 -0.2235072           19       elpd ## 20         NA           20       elpd ## 21 -0.2413680           21       elpd ## 22 -2.6791984           22       elpd ## 23         NA           23       elpd ## 24 -2.6851981           24       elpd ## 25 -0.2836901           25       elpd energy_mod2 <- score(fc_mod2, score = 'energy') str(energy_mod2) ## List of 4 ##  $ series_1  :'data.frame':  25 obs. of  3 variables: ##   ..$ in_interval   : num [1:25] 1 1 1 NA 1 1 1 1 1 1 ... ##   ..$ interval_width: num [1:25] 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 ... ##   ..$ eval_horizon  : int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##  $ series_2  :'data.frame':  25 obs. of  3 variables: ##   ..$ in_interval   : num [1:25] 1 1 1 1 1 1 1 1 1 NA ... ##   ..$ interval_width: num [1:25] 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 ... ##   ..$ eval_horizon  : int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##  $ series_3  :'data.frame':  25 obs. of  3 variables: ##   ..$ in_interval   : num [1:25] 1 1 1 1 1 1 1 1 1 1 ... ##   ..$ interval_width: num [1:25] 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 ... ##   ..$ eval_horizon  : int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##  $ all_series:'data.frame':  25 obs. of  3 variables: ##   ..$ score       : num [1:25] 0.773 1.147 1.226 NA 0.458 ... ##   ..$ eval_horizon: int [1:25] 1 2 3 4 5 6 7 8 9 10 ... ##   ..$ score_type  : chr [1:25] \"energy\" \"energy\" \"energy\" \"energy\" ... energy_mod2$all_series ##        score eval_horizon score_type ## 1  0.7728517            1     energy ## 2  1.1469836            2     energy ## 3  1.2258781            3     energy ## 4         NA            4     energy ## 5  0.4577536            5     energy ## 6  1.8094487            6     energy ## 7  1.4887317            7     energy ## 8  0.7651593            8     energy ## 9  1.1180634            9     energy ## 10        NA           10     energy ## 11 1.5008324           11     energy ## 12 3.2142460           12     energy ## 13 1.6129732           13     energy ## 14 1.2704438           14     energy ## 15 1.1335958           15     energy ## 16 1.8717420           16     energy ## 17        NA           17     energy ## 18 0.7953392           18     energy ## 19 0.9919119           19     energy ## 20        NA           20     energy ## 21 1.2461964           21     energy ## 22 1.5170615           22     energy ## 23        NA           23     energy ## 24 2.3824552           24     energy ## 25 1.5314557           25     energy crps_mod1 <- score(fc_mod1, score = 'crps') crps_mod2 <- score(fc_mod2, score = 'crps')  diff_scores <- crps_mod2$series_1$score -   crps_mod1$series_1$score plot(diff_scores, pch = 16, cex = 1.25, col = 'darkred',       ylim = c(-1*max(abs(diff_scores), na.rm = TRUE),               max(abs(diff_scores), na.rm = TRUE)),      bty = 'l',      xlab = 'Forecast horizon',      ylab = expression(CRPS[GP]~-~CRPS[spline])) abline(h = 0, lty = 'dashed', lwd = 2) gp_better <- length(which(diff_scores < 0)) title(main = paste0('GP better in ', gp_better, ' of 25 evaluations',                     '\\nMean difference = ',                      round(mean(diff_scores, na.rm = TRUE), 2))) diff_scores <- crps_mod2$series_2$score -   crps_mod1$series_2$score plot(diff_scores, pch = 16, cex = 1.25, col = 'darkred',       ylim = c(-1*max(abs(diff_scores), na.rm = TRUE),               max(abs(diff_scores), na.rm = TRUE)),      bty = 'l',      xlab = 'Forecast horizon',      ylab = expression(CRPS[GP]~-~CRPS[spline])) abline(h = 0, lty = 'dashed', lwd = 2) gp_better <- length(which(diff_scores < 0)) title(main = paste0('GP better in ', gp_better, ' of 25 evaluations',                     '\\nMean difference = ',                      round(mean(diff_scores, na.rm = TRUE), 2))) diff_scores <- crps_mod2$series_3$score -   crps_mod1$series_3$score plot(diff_scores, pch = 16, cex = 1.25, col = 'darkred',       ylim = c(-1*max(abs(diff_scores), na.rm = TRUE),               max(abs(diff_scores), na.rm = TRUE)),      bty = 'l',      xlab = 'Forecast horizon',      ylab = expression(CRPS[GP]~-~CRPS[spline])) abline(h = 0, lty = 'dashed', lwd = 2) gp_better <- length(which(diff_scores < 0)) title(main = paste0('GP better in ', gp_better, ' of 25 evaluations',                     '\\nMean difference = ',                      round(mean(diff_scores, na.rm = TRUE), 2)))"},{"path":"https://nicholasjclark.github.io/mvgam/articles/forecast_evaluation.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further reading","title":"Forecasting and forecast evaluation in mvgam","text":"following papers resources offer useful material Bayesian forecasting proper scoring rules: Hyndman, Rob J., George Athanasopoulos. Forecasting: principles practice. OTexts, 2018. Gneiting, Tilmann, Adrian E. Raftery. Strictly proper scoring rules, prediction, estimation Journal American statistical Association 102.477 (2007) 359-378. Simonis, Juniper L., Ethan P. White, SK Morgan Ernest. Evaluating probabilistic ecological forecasts Ecology 102.8 (2021) e03431.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"dynamic-gams","dir":"Articles","previous_headings":"","what":"Dynamic GAMs","title":"Overview of the mvgam package","text":"mvgam designed propagate unobserved temporal processes capture latent dynamics observed time series. works state-space format, temporal trend evolving independently observation process. introduction package worked examples also shown seminar: Ecological Forecasting Dynamic Generalized Additive Models. Briefly, assume \\(\\tilde{\\boldsymbol{y}}_{,t}\\) conditional expectation response variable \\(\\boldsymbol{}\\) time \\(\\boldsymbol{t}\\). Assuming \\(\\boldsymbol{y_i}\\) drawn exponential distribution invertible link function, linear predictor multivariate Dynamic GAM can written : \\[~~~1:N_{series}~...\\] \\[~t~~1:N_{timepoints}~...\\] \\[g^{-1}(\\tilde{\\boldsymbol{y}}_{,t})=\\alpha_{}+\\sum\\limits_{j=1}^J\\boldsymbol{s}_{,j,t}\\boldsymbol{x}_{j,t}+\\boldsymbol{z}_{,t}\\,,\\] \\(\\alpha\\) unknown intercepts, \\(\\boldsymbol{s}\\)’s unknown smooth functions covariates (\\(\\boldsymbol{x}\\)’s), can potentially vary among response series, \\(\\boldsymbol{z}\\) dynamic latent processes. smooth function \\(\\boldsymbol{s_j}\\) composed basis expansions whose coefficients, must estimated, control functional relationship \\(\\boldsymbol{x}_{j}\\) \\(g^{-1}(\\tilde{\\boldsymbol{y}})\\). size basis expansion limits smooth’s potential complexity. larger set basis functions allows greater flexibility. Several advantages GAMs can model diversity response families, including discrete distributions (.e. Poisson, Negative Binomial, Gamma) accommodate common ecological features zero-inflation overdispersion, can formulated include hierarchical smoothing multivariate responses. mvgam supports number different observation families, summarized :","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"supported-observation-families","dir":"Articles","previous_headings":"","what":"Supported observation families","title":"Overview of the mvgam package","text":"supported observation families, extra parameters need estimated (.e. \\(\\sigma\\) Gaussian model \\(\\phi\\) Negative Binomial model) estimated independently series. Note default link functions currently changed mvgam.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"supported-temporal-dynamic-processes","dir":"Articles","previous_headings":"","what":"Supported temporal dynamic processes","title":"Overview of the mvgam package","text":"dynamic processes can take wide variety forms, can multivariate allow different time series interact correlated. using mvgam() function, user chooses different process models trend_model argument. Available process models described detail .","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"independent-random-walks","dir":"Articles","previous_headings":"Supported temporal dynamic processes","what":"Independent Random Walks","title":"Overview of the mvgam package","text":"Use trend_model = 'RW' trend_model = RW() set model series data independent latent temporal dynamics form: \\[\\begin{align*} z_{,t} & \\sim \\text{Normal}(z_{,t-1}, \\sigma_i) \\end{align*}\\] Process error parameters \\(\\sigma\\) modeled independently series. moving average process required, use trend_model = RW(ma = TRUE) set following: \\[\\begin{align*} z_{,t} & = z_{,t-1} + \\theta_i * error_{,t-1} + error_{,t} \\\\ error_{,t} & \\sim \\text{Normal}(0, \\sigma_i) \\end{align*}\\] Moving average coefficients \\(\\theta\\) independently estimated series forced stationary default \\((abs(\\theta)<1)\\). moving averages order \\(q=1\\) currently allowed.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"multivariate-random-walks","dir":"Articles","previous_headings":"Supported temporal dynamic processes","what":"Multivariate Random Walks","title":"Overview of the mvgam package","text":"one series included data \\((N_{series} > 1)\\), multivariate Random Walk can set using trend_model = RW(cor = TRUE), resulting following: \\[\\begin{align*} z_{t} & \\sim \\text{MVNormal}(z_{t-1}, \\Sigma) \\end{align*}\\] latent process estimate \\(z_t\\) now takes form vector. covariance matrix \\(\\Sigma\\) capture contemporaneously correlated process errors. parameterised using Cholesky factorization, requires priors series-level variances \\(\\sigma\\) strength correlations using Stan’s lkj_corr_cholesky distribution. Moving average terms can also included multivariate random walks, case moving average coefficients \\(\\theta\\) parameterised \\(N_{series} * N_{series}\\) matrix","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"autoregressive-processes","dir":"Articles","previous_headings":"Supported temporal dynamic processes","what":"Autoregressive processes","title":"Overview of the mvgam package","text":"Autoregressive models \\(p=3\\), autoregressive coefficients estimated independently series, can used specifying trend_model = 'AR1', trend_model = 'AR2', trend_model = 'AR3', trend_model = AR(p = 1, 2, 3). example, univariate AR(1) model takes form: \\[\\begin{align*} z_{,t} & \\sim \\text{Normal}(ar1_i * z_{,t-1}, \\sigma_i) \\end{align*}\\] options Random Walks, additional options available placing priors autoregressive coefficients. default, coefficients forced stationarity, users can impose restriction changing upper lower bounds priors. See ?get_mvgam_priors details.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"vector-autoregressive-processes","dir":"Articles","previous_headings":"Supported temporal dynamic processes","what":"Vector Autoregressive processes","title":"Overview of the mvgam package","text":"Vector Autoregression order \\(p=1\\) can specified \\(N_{series} > 1\\) using trend_model = 'VAR1' trend_model = VAR(). VAR(1) model takes form: \\[\\begin{align*} z_{t} & \\sim \\text{Normal}(* z_{t-1}, \\Sigma) \\end{align*}\\] \\(\\) \\(N_{series} * N_{series}\\) matrix autoregressive coefficients diagonals capture lagged self-dependence (.e. effect process time \\(t\\) estimate time \\(t+1\\)), -diagonals capture lagged cross-dependence (.e. effect process time \\(t\\) process another series time \\(t+1\\)). default, covariance matrix \\(\\Sigma\\) assume process error covariance fixing -diagonals \\(0\\). allow correlated errors, use trend_model = 'VAR1cor' trend_model = VAR(cor = TRUE). moving average order \\(q=1\\) can also included using trend_model = VAR(ma = TRUE, cor = TRUE). Note VAR models, stationarity process enforced structured prior distribution described detail Heaps 2022 Heaps, Sarah E. “Enforcing stationarity prior vector autoregressions.” Journal Computational Graphical Statistics 32.1 (2023): 74-83.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"gaussian-processes","dir":"Articles","previous_headings":"Supported temporal dynamic processes","what":"Gaussian Processes","title":"Overview of the mvgam package","text":"final option modelling temporal dynamics use Gaussian Process squared exponential kernel. set independently series (currently multivariate GP option), using trend_model = 'GP'. dynamics latent process modelled : \\[\\begin{align*} z & \\sim \\text{MVNormal}(0, \\Sigma_{error}) \\\\ \\Sigma_{error}[t_i, t_j] & = \\alpha^2 * exp(-0.5 * ((|t_i - t_j| / \\rho))^2) \\end{align*}\\] latent dynamic process evolves complex, high-dimensional Multivariate Normal distribution depends \\(\\rho\\) (often called length scale parameter) control quickly correlations model’s errors decay function time. models, covariance decays exponentially fast squared distance (time) observations. functions also depend parameter \\(\\alpha\\), controls marginal variability temporal function points; words controls much GP term contributes linear predictor. mvgam capitalizes advances allow GPs approximated using Hilbert space basis functions, considerably speed computation little cost accuracy prediction performance.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"piecewise-logistic-and-linear-trends","dir":"Articles","previous_headings":"Supported temporal dynamic processes","what":"Piecewise logistic and linear trends","title":"Overview of the mvgam package","text":"Modeling growth many types time series often similar modeling population growth natural ecosystems, series exhibits nonlinear growth saturates particular carrying capacity. logistic trend model available {mvgam} allows time-varying capacity \\(C(t)\\) well non-constant growth rate. Changes base growth rate \\(k\\) incorporated explicitly defining changepoints throughout training period growth rate allowed vary. changepoint vector \\(\\) represented vector 1s 0s, rate growth time \\(t\\) represented \\(k+(t)^T\\delta\\). Potential changepoints selected uniformly across training period, number changepoints, well flexibility potential rate changes changepoints, can controlled using trend_model = PW(). full piecewise logistic growth model : \\[\\begin{align*} z_t & = \\frac{C_t}{1 + \\exp(-(k+(t)^T\\delta)(t-(m+(t)^T\\gamma)))}  \\end{align*}\\] time series appear exhibit saturating growth, piece-wise constant rate growth can often provide useful trend model. piecewise linear trend defined : \\[\\begin{align*} z_t & = (k+(t)^T\\delta)t + (m+(t)^T\\gamma)  \\end{align*}\\] trend models, \\(m\\) offset parameter controls trend intercept. parameter, recommended include intercept observation formula identifiable. can read full description piecewise linear logistic trends paper Taylor Letham. Sean J. Taylor Benjamin Letham. “Forecasting scale.” American Statistician 72.1 (2018): 37-45.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"regression-formulae","dir":"Articles","previous_headings":"","what":"Regression formulae","title":"Overview of the mvgam package","text":"mvgam supports observation model regression formula, built mvgcv package, well optional process model regression formula. formulae supplied exactly like supplied glm() except smooth terms, s(), te(), ti() t2(), time-varying effects using dynamic(), monotonically increasing (using s(x, bs = 'moi')) decreasing splines (using s(x, bs = 'mod'); see ?smooth.construct.moi.smooth.spec details), well Gaussian Process functions using gp(), can added right hand side (. supported mvgam formulae). See ?mvgam_formulae guidance. setting State-Space models, optional process model formula can used (see State-Space model vignette shared latent states vignette guidance using trend formulae).","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"example-time-series-data","dir":"Articles","previous_headings":"","what":"Example time series data","title":"Overview of the mvgam package","text":"‘portal_data’ object contains time series rodent captures Portal Project, long-term monitoring study based near town Portal, Arizona. Researchers operating standardized set baited traps within 24 experimental plots site since 1970’s. Sampling follows lunar monthly cycle, observations occurring average 28 days apart. However, missing observations occur due difficulties accessing site (weather events, COVID disruptions etc…). can read full sampling protocol preprint Ernest et al Biorxiv. data come pre-loaded mvgam package, can read little help page using ?portal_data. working data, important inspect data structured, first using head: glimpse function dplyr also useful understanding variables structured focus analyses time series captures one specific rodent species, Desert Pocket Mouse Chaetodipus penicillatus. species interesting goes kind “hibernation” colder months, leading low captures winter period","code":"data(\"portal_data\") head(portal_data) ##   moon DM DO PP OT year month mintemp precipitation     ndvi ## 1  329 10  6  0  2 2004     1  -9.710          37.8 1.465889 ## 2  330 14  8  1  0 2004     2  -5.924           8.7 1.558507 ## 3  331  9  1  2  1 2004     3  -0.220          43.5 1.337817 ## 4  332 NA NA NA NA 2004     4   1.931          23.9 1.658913 ## 5  333 15  8 10  1 2004     5   6.568           0.9 1.853656 ## 6  334 NA NA NA NA 2004     6  11.590           1.4 1.761330 dplyr::glimpse(portal_data) ## Rows: 199 ## Columns: 10 ## $ moon          <int> 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 3… ## $ DM            <int> 10, 14, 9, NA, 15, NA, NA, 9, 5, 8, NA, 14, 7, NA, NA, 9… ## $ DO            <int> 6, 8, 1, NA, 8, NA, NA, 3, 3, 4, NA, 3, 8, NA, NA, 3, NA… ## $ PP            <int> 0, 1, 2, NA, 10, NA, NA, 16, 18, 12, NA, 3, 2, NA, NA, 1… ## $ OT            <int> 2, 0, 1, NA, 1, NA, NA, 1, 0, 0, NA, 2, 1, NA, NA, 1, NA… ## $ year          <int> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 20… ## $ month         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6,… ## $ mintemp       <dbl> -9.710, -5.924, -0.220, 1.931, 6.568, 11.590, 14.370, 16… ## $ precipitation <dbl> 37.8, 8.7, 43.5, 23.9, 0.9, 1.4, 20.3, 91.0, 60.5, 25.2,… ## $ ndvi          <dbl> 1.4658889, 1.5585069, 1.3378172, 1.6589129, 1.8536561, 1…"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"manipulating-data-for-modelling","dir":"Articles","previous_headings":"","what":"Manipulating data for modelling","title":"Overview of the mvgam package","text":"Manipulating data ‘long’ format necessary modelling mvgam. ‘long’ format, mean series x time observation needs entry dataframe list object wish use data modelling. simple example can viewed simulating data using sim_mvgam function. See ?sim_mvgam details Notice four different time series simulated data, spread outcome values different columns. Rather, single column outcome variable, labelled y simulated data. also must supply variable labelled time ensure modelling software knows arrange time series building models. setup still allows us formulate multivariate time series models, can see State-Space vignette. steps needed shape portal_data object correct form. First, create time variable, select column representing counts target species (PP), select appropriate variables can use predictors data now contain six variables:series, factor indexing time series observation belongs toyear, year samplingtime, indicator time step observation belongs tocount, response variable representing number captures species PP sampling observationmintemp, monthly average minimum temperature time stepndvi, monthly average Normalized Difference Vegetation Index time step Now check data structure can also summarize multiple variables, helpful search data ranges identify missing values NAs response variable count. Let’s visualize data heatmap get sense distributed (NAs shown red bars plot)  observations generally thrown modelling packages . see work tutorials, mvgam keeps data predictions can automatically returned full dataset. time series descriptive features can plotted using plot_mvgam_series():","code":"data <- sim_mvgam(n_series = 4, T = 24) head(data$data_train, 12) ##     y season year   series time ## 1   1      1    1 series_1    1 ## 2   6      1    1 series_2    1 ## 3  12      1    1 series_3    1 ## 4   0      1    1 series_4    1 ## 5   3      2    1 series_1    2 ## 6   5      2    1 series_2    2 ## 7   3      2    1 series_3    2 ## 8   0      2    1 series_4    2 ## 9   2      3    1 series_1    3 ## 10  4      3    1 series_2    3 ## 11  3      3    1 series_3    3 ## 12  0      3    1 series_4    3 portal_data %>%      # mvgam requires a 'time' variable be present in the data to index   # the temporal observations. This is especially important when tracking    # multiple time series. In the Portal data, the 'moon' variable indexes the   # lunar monthly timestep of the trapping sessions   dplyr::mutate(time = moon - (min(moon)) + 1) %>%      # We can also provide a more informative name for the outcome variable, which    # is counts of the 'PP' species (Chaetodipus penicillatus) across all control   # plots   dplyr::mutate(count = PP) %>%      # The other requirement for mvgam is a 'series' variable, which needs to be a   # factor variable to index which time series each row in the data belongs to.   # Again, this is more useful when you have multiple time series in the data   dplyr::mutate(series = as.factor('PP')) %>%      # Select the variables of interest to keep in the model_data   dplyr::select(series, year, time, count, mintemp, ndvi) -> model_data head(model_data) ##   series year time count mintemp     ndvi ## 1     PP 2004    1     0  -9.710 1.465889 ## 2     PP 2004    2     1  -5.924 1.558507 ## 3     PP 2004    3     2  -0.220 1.337817 ## 4     PP 2004    4    NA   1.931 1.658913 ## 5     PP 2004    5    10   6.568 1.853656 ## 6     PP 2004    6    NA  11.590 1.761330 dplyr::glimpse(model_data) ## Rows: 199 ## Columns: 6 ## $ series  <fct> PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP… ## $ year    <int> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 20… ## $ time    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ count   <int> 0, 1, 2, NA, 10, NA, NA, 16, 18, 12, NA, 3, 2, NA, NA, 13, NA,… ## $ mintemp <dbl> -9.710, -5.924, -0.220, 1.931, 6.568, 11.590, 14.370, 16.520, … ## $ ndvi    <dbl> 1.4658889, 1.5585069, 1.3378172, 1.6589129, 1.8536561, 1.76132… summary(model_data) ##  series        year           time           count          mintemp        ##  PP:199   Min.   :2004   Min.   :  1.0   Min.   : 0.00   Min.   :-24.000   ##           1st Qu.:2008   1st Qu.: 50.5   1st Qu.: 2.50   1st Qu.: -3.884   ##           Median :2012   Median :100.0   Median :12.00   Median :  2.130   ##           Mean   :2012   Mean   :100.0   Mean   :15.14   Mean   :  3.504   ##           3rd Qu.:2016   3rd Qu.:149.5   3rd Qu.:24.00   3rd Qu.: 12.310   ##           Max.   :2020   Max.   :199.0   Max.   :65.00   Max.   : 18.140   ##                                          NA's   :36                        ##       ndvi        ##  Min.   :0.2817   ##  1st Qu.:1.0741   ##  Median :1.3501   ##  Mean   :1.4709   ##  3rd Qu.:1.8178   ##  Max.   :3.9126   ## image(is.na(t(model_data %>%                 dplyr::arrange(dplyr::desc(time)))), axes = F,       col = c('grey80', 'darkred')) axis(3, at = seq(0,1, len = NCOL(model_data)), labels = colnames(model_data)) plot_mvgam_series(data = model_data, series = 1, y = 'count')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"glms-with-temporal-random-effects","dir":"Articles","previous_headings":"","what":"GLMs with temporal random effects","title":"Overview of the mvgam package","text":"first task fit Generalized Linear Model (GLM) can adequately capture features count observations (integer data, lower bound zero, missing values) also attempting model temporal variation. almost ready fit first model, GLM Poisson observations, log link function random (hierarchical) intercepts year. allow us capture prior belief , although year unique, sampled population effects, years connected thus might contain valuable information one another. done capitalizing partial pooling properties hierarchical models. Hierarchical (also known random) effects offer many advantages modelling data grouping structures (.e. multiple species, locations, years etc…). ability incorporate time series models huge advantage traditional models ARIMA Exponential Smoothing. fit model, need convert year factor can use random effect basis mvgam. See ?smooth.terms ?smooth.construct.re.smooth.spec details re basis construction used mvgam mgcv Preview dataset ensure year now factor unique factor level year data now ready first mvgam model. syntax familiar users previously built models mgcv. refresher, see ?formula.gam examples ?gam. Random effects can specified using s wrapper re basis. Note can also suppress primary intercept using usual R formula syntax - 1. mvgam number possible observation families can used, see ?mvgam_families information. use Stan fitting engine, deploys Hamiltonian Monte Carlo (HMC) full Bayesian inference. default, 4 HMC chains run using warmup 500 iterations collecting 500 posterior samples chain. package also aim use Cmdstan backend possible, recommended users --date installation Cmdstan associated cmdstanr interface machines (note can set backend using backend argument: see ?mvgam details). Interested users consult Stan user’s guide information software enormous variety models can tackled HMC. model can described mathematically timepoint \\(t\\) follows: \\[\\begin{align*} \\boldsymbol{count}_t & \\sim \\text{Poisson}(\\lambda_t) \\\\ log(\\lambda_t) & = \\beta_{year[year_t]} \\\\ \\beta_{year} & \\sim \\text{Normal}(\\mu_{year}, \\sigma_{year}) \\end{align*}\\] \\(\\beta_{year}\\) effects drawn population distribution parameterized common mean \\((\\mu_{year})\\) variance \\((\\sigma_{year})\\). Priors model parameters can interrogated changed using similar functionality options available brms. example, default priors \\((\\mu_{year})\\) \\((\\sigma_{year})\\) can viewed using following code: See examples ?get_mvgam_priors find different ways priors can altered. model finished, first step inspect summary ensure major diagnostic warnings produced quickly summarise posterior distributions key parameters diagnostic messages bottom summary show HMC sampler encounter problems difficult posterior spaces. good sign. Posterior distributions model parameters can extracted way object class brmsfit can (see ?mvgam::mvgam_draws details). example, can extract coefficients related GAM linear predictor (.e. \\(\\beta\\)’s) data.frame using: model fitted mvgam, underlying Stan code can viewed using code function:","code":"model_data %>%      # Create a 'year_fac' factor version of 'year'   dplyr::mutate(year_fac = factor(year)) -> model_data dplyr::glimpse(model_data) ## Rows: 199 ## Columns: 7 ## $ series   <fct> PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, PP, P… ## $ year     <int> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2… ## $ time     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18… ## $ count    <int> 0, 1, 2, NA, 10, NA, NA, 16, 18, 12, NA, 3, 2, NA, NA, 13, NA… ## $ mintemp  <dbl> -9.710, -5.924, -0.220, 1.931, 6.568, 11.590, 14.370, 16.520,… ## $ ndvi     <dbl> 1.4658889, 1.5585069, 1.3378172, 1.6589129, 1.8536561, 1.7613… ## $ year_fac <fct> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2… levels(model_data$year_fac) ##  [1] \"2004\" \"2005\" \"2006\" \"2007\" \"2008\" \"2009\" \"2010\" \"2011\" \"2012\" \"2013\" ## [11] \"2014\" \"2015\" \"2016\" \"2017\" \"2018\" \"2019\" \"2020\" model1 <- mvgam(count ~ s(year_fac, bs = 're') - 1,                 family = poisson(),                 data = model_data) get_mvgam_priors(count ~ s(year_fac, bs = 're') - 1,                  family = poisson(),                  data = model_data) ##                      param_name param_length           param_info ## 1             vector[1] mu_raw;            1 s(year_fac) pop mean ## 2 vector<lower=0>[1] sigma_raw;            1   s(year_fac) pop sd ##                               prior                 example_change ## 1            mu_raw ~ std_normal();   mu_raw ~ normal(0.21, 0.23); ## 2 sigma_raw ~ student_t(3, 0, 2.5); sigma_raw ~ exponential(0.29); ##   new_lowerbound new_upperbound ## 1             NA             NA ## 2             NA             NA summary(model1) ## GAM formula: ## count ~ s(year_fac, bs = \"re\") - 1 ##  ## Family: ## poisson ##  ## Link function: ## log ##  ## Trend model: ## None ##  ## N series: ## 1  ##  ## N timepoints: ## 199  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM coefficient (beta) estimates: ##                 2.5% 50% 97.5% Rhat n_eff ## s(year_fac).1   1.80 2.1   2.3 1.00  2678 ## s(year_fac).2   2.50 2.7   2.8 1.00  2668 ## s(year_fac).3   3.00 3.1   3.2 1.00  3090 ## s(year_fac).4   3.10 3.3   3.4 1.00  2636 ## s(year_fac).5   1.90 2.1   2.3 1.00  2405 ## s(year_fac).6   1.50 1.8   2.0 1.00  2637 ## s(year_fac).7   1.80 2.0   2.3 1.00  2381 ## s(year_fac).8   2.80 3.0   3.1 1.00  2866 ## s(year_fac).9   3.10 3.2   3.4 1.00  2801 ## s(year_fac).10  2.60 2.8   2.9 1.00  2844 ## s(year_fac).11  3.00 3.1   3.2 1.00  3150 ## s(year_fac).12  3.10 3.2   3.3 1.00  2307 ## s(year_fac).13  2.00 2.2   2.5 1.00  2857 ## s(year_fac).14  2.50 2.6   2.8 1.00  2939 ## s(year_fac).15  1.90 2.2   2.4 1.00  2610 ## s(year_fac).16  1.90 2.1   2.3 1.00  3129 ## s(year_fac).17 -0.28 1.1   1.9 1.02   367 ##  ## GAM group-level estimates: ##                   2.5%  50% 97.5% Rhat n_eff ## mean(s(year_fac)) 2.00 2.40   2.7 1.02   190 ## sd(s(year_fac))   0.46 0.68   1.1 1.03   203 ##  ## Approximate significance of GAM observation smooths: ##              edf Chi.sq p-value     ## s(year_fac) 12.8  23511  <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:54:28 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) beta_post <- as.data.frame(model1, variable = 'betas') dplyr::glimpse(beta_post) ## Rows: 2,000 ## Columns: 17 ## $ `s(year_fac).1`  <dbl> 1.86190, 2.11388, 2.11600, 2.10553, 2.23891, 1.86875,… ## $ `s(year_fac).2`  <dbl> 2.64166, 2.68429, 2.72846, 2.64397, 2.77831, 2.60079,… ## $ `s(year_fac).3`  <dbl> 3.16581, 3.08324, 3.08527, 2.97360, 3.14883, 3.12684,… ## $ `s(year_fac).4`  <dbl> 3.27785, 3.18822, 3.23306, 3.22290, 3.19447, 3.38818,… ## $ `s(year_fac).5`  <dbl> 2.09716, 2.03221, 2.16466, 2.03947, 2.17555, 2.10229,… ## $ `s(year_fac).6`  <dbl> 1.71619, 1.58724, 1.86737, 1.90242, 1.56511, 1.75312,… ## $ `s(year_fac).7`  <dbl> 1.96664, 2.09183, 2.15583, 2.10924, 2.00211, 2.11828,… ## $ `s(year_fac).8`  <dbl> 2.89847, 2.80166, 2.97784, 2.90876, 3.02493, 2.90480,… ## $ `s(year_fac).9`  <dbl> 3.24516, 3.23472, 3.17024, 3.28808, 3.10487, 3.24116,… ## $ `s(year_fac).10` <dbl> 2.70289, 2.75808, 2.63608, 2.81192, 2.77074, 2.76922,… ## $ `s(year_fac).11` <dbl> 3.03255, 3.04433, 3.03362, 3.01215, 3.01482, 3.19735,… ## $ `s(year_fac).12` <dbl> 3.21954, 3.16691, 3.18440, 3.17227, 3.14342, 3.22443,… ## $ `s(year_fac).13` <dbl> 2.18136, 2.38175, 2.18528, 2.29116, 2.27636, 2.24354,… ## $ `s(year_fac).14` <dbl> 2.68183, 2.68278, 2.65206, 2.68147, 2.67352, 2.62832,… ## $ `s(year_fac).15` <dbl> 1.94873, 2.16423, 2.07559, 2.12836, 2.03424, 2.32574,… ## $ `s(year_fac).16` <dbl> 2.16423, 2.37222, 1.92845, 2.11019, 2.03066, 2.17096,… ## $ `s(year_fac).17` <dbl> 0.9960880, 0.9922320, 0.9462070, 0.6951830, 0.8883960… code(model1) ## // Stan model code generated by package mvgam ## data { ##   int<lower=0> total_obs; // total number of observations ##   int<lower=0> n; // number of timepoints per series ##   int<lower=0> n_series; // number of series ##   int<lower=0> num_basis; // total number of basis coefficients ##   matrix[total_obs, num_basis] X; // mgcv GAM design matrix ##   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) ##   int<lower=0> n_nonmissing; // number of nonmissing observations ##   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations ##   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations ##   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations ## } ## parameters { ##   // raw basis coefficients ##   vector[num_basis] b_raw; ##    ##   // random effect variances ##   vector<lower=0>[1] sigma_raw; ##    ##   // random effect means ##   vector[1] mu_raw; ## } ## transformed parameters { ##   // basis coefficients ##   vector[num_basis] b; ##   b[1 : 17] = mu_raw[1] + b_raw[1 : 17] * sigma_raw[1]; ## } ## model { ##   // prior for random effect population variances ##   sigma_raw ~ student_t(3, 0, 2.5); ##    ##   // prior for random effect population means ##   mu_raw ~ std_normal(); ##    ##   // prior (non-centred) for s(year_fac)... ##   b_raw[1 : 17] ~ std_normal(); ##   { ##     // likelihood functions ##     flat_ys ~ poisson_log_glm(flat_xs, 0.0, b); ##   } ## } ## generated quantities { ##   vector[total_obs] eta; ##   matrix[n, n_series] mus; ##   array[n, n_series] int ypred; ##    ##   // posterior predictions ##   eta = X * b; ##   for (s in 1 : n_series) { ##     mus[1 : n, s] = eta[ytimes[1 : n, s]]; ##     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]); ##   } ## }"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"plotting-effects-and-residuals","dir":"Articles","previous_headings":"GLMs with temporal random effects","what":"Plotting effects and residuals","title":"Overview of the mvgam package","text":"Now interrogating model. can get sense variation yearly intercepts summary , easier understand using targeted plots. Plot posterior distributions temporal random effects using plot.mvgam type = 're'. See ?plot.mvgam details types plots can produced fitted mvgam objects","code":"plot(model1, type = 're')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"bayesplot-support","dir":"Articles","previous_headings":"GLMs with temporal random effects","what":"bayesplot support","title":"Overview of the mvgam package","text":"can also capitalize useful MCMC plotting functions bayesplot package visualize posterior distributions diagnostics (see ?mvgam::mcmc_plot.mvgam details):  clearly variation yearly intercept estimates. translate time-varying predictions? understand , can plot posterior hindcasts model training period using plot.mvgam type = 'forecast'  wish extract hindcasts downstream analyses, hindcast function can used. return list object class mvgam_forecast. hindcasts slot, matrix posterior retrodictions returned series data (one series example): can also extract hindcasts linear predictor scale, case log scale (Poisson GLM used log link function). Sometimes can useful asking targeted questions drivers variation: Objects class mvgam_forecast associated plot function well:  plot can look bit confusing seems like linear interpolation end one year start next. just due way lines automatically connected base plots regression analysis, key question whether residuals show patterns can indicative un-modelled sources variation. GLMs, can use modified residual called Dunn-Smyth, randomized quantile, residual. Inspect Dunn-Smyth residuals model using plot.mvgam type = 'residuals'","code":"mcmc_plot(object = model1,           variable = 'betas',           type = 'areas') plot(model1, type = 'forecast') hc <- hindcast(model1) str(hc) ## List of 15 ##  $ call              :Class 'formula'  language count ~ s(year_fac, bs = \"re\") - 1 ##   .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv>  ##  $ trend_call        : NULL ##  $ family            : chr \"poisson\" ##  $ trend_model       : chr \"None\" ##  $ drift             : logi FALSE ##  $ use_lv            : logi FALSE ##  $ fit_engine        : chr \"stan\" ##  $ type              : chr \"response\" ##  $ series_names      : chr \"PP\" ##  $ train_observations:List of 1 ##   ..$ PP: int [1:199] 0 1 2 NA 10 NA NA 16 18 12 ... ##  $ train_times       : num [1:199] 1 2 3 4 5 6 7 8 9 10 ... ##  $ test_observations : NULL ##  $ test_times        : NULL ##  $ hindcasts         :List of 1 ##   ..$ PP: num [1:2000, 1:199] 7 6 7 5 9 7 4 10 9 8 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : NULL ##   .. .. ..$ : chr [1:199] \"ypred[1,1]\" \"ypred[2,1]\" \"ypred[3,1]\" \"ypred[4,1]\" ... ##  $ forecasts         : NULL ##  - attr(*, \"class\")= chr \"mvgam_forecast\" hc <- hindcast(model1, type = 'link') range(hc$hindcasts$PP) ## [1] -1.79937  3.44340 plot(hc) plot(model1, type = 'residuals')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"automatic-forecasting-for-new-data","dir":"Articles","previous_headings":"","what":"Automatic forecasting for new data","title":"Overview of the mvgam package","text":"temporal random effects sense “time”. , yearly random intercept restricted way similar previous yearly intercept. drawback becomes evident predict new year. , can repeat exercise time split data training testing sets re-running model. can supply test set newdata. splitting, make use filter function dplyr Repeating plots gives insight model’s hierarchical prior formulation provides structure needed sample values un-modelled years   can also view test data forecast plot see predictions capture temporal variation test set  hindcast function, can use forecast function automatically extract posterior distributions predictions. also returns object class mvgam_forecast, now contain hindcasts forecasts series data:","code":"model_data %>%    dplyr::filter(time <= 160) -> data_train  model_data %>%    dplyr::filter(time > 160) -> data_test model1b <- mvgam(count ~ s(year_fac, bs = 're') - 1,                 family = poisson(),                 data = data_train,                 newdata = data_test) plot(model1b, type = 're') plot(model1b, type = 'forecast') ## Out of sample DRPS: ## [1] 184.8855 plot(model1b, type = 'forecast', newdata = data_test) ## Out of sample DRPS: ## [1] 184.8855 fc <- forecast(model1b) str(fc) ## List of 16 ##  $ call              :Class 'formula'  language count ~ s(year_fac, bs = \"re\") - 1 ##   .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv>  ##  $ trend_call        : NULL ##  $ family            : chr \"poisson\" ##  $ family_pars       : NULL ##  $ trend_model       : chr \"None\" ##  $ drift             : logi FALSE ##  $ use_lv            : logi FALSE ##  $ fit_engine        : chr \"stan\" ##  $ type              : chr \"response\" ##  $ series_names      : Factor w/ 1 level \"PP\": 1 ##  $ train_observations:List of 1 ##   ..$ PP: int [1:160] 0 1 2 NA 10 NA NA 16 18 12 ... ##  $ train_times       : num [1:160] 1 2 3 4 5 6 7 8 9 10 ... ##  $ test_observations :List of 1 ##   ..$ PP: int [1:39] NA 0 0 10 3 14 18 NA 28 46 ... ##  $ test_times        : num [1:39] 161 162 163 164 165 166 167 168 169 170 ... ##  $ hindcasts         :List of 1 ##   ..$ PP: num [1:2000, 1:160] 11 9 8 6 9 7 9 7 10 9 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : NULL ##   .. .. ..$ : chr [1:160] \"ypred[1,1]\" \"ypred[2,1]\" \"ypred[3,1]\" \"ypred[4,1]\" ... ##  $ forecasts         :List of 1 ##   ..$ PP: num [1:2000, 1:39] 12 7 11 10 5 12 9 10 6 6 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : NULL ##   .. .. ..$ : chr [1:39] \"ypred[161,1]\" \"ypred[162,1]\" \"ypred[163,1]\" \"ypred[164,1]\" ... ##  - attr(*, \"class\")= chr \"mvgam_forecast\""},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"adding-predictors-as-fixed-effects","dir":"Articles","previous_headings":"","what":"Adding predictors as “fixed” effects","title":"Overview of the mvgam package","text":"users familiar GLMs know nearly always wish include predictor variables may explain variation observations. Predictors easily incorporated GLMs / GAMs. , update model including parametric (fixed) effect ndvi linear predictor: model can described mathematically follows: \\[\\begin{align*} \\boldsymbol{count}_t & \\sim \\text{Poisson}(\\lambda_t) \\\\ log(\\lambda_t) & = \\beta_{year[year_t]} + \\beta_{ndvi} * \\boldsymbol{ndvi}_t \\\\ \\beta_{year} & \\sim \\text{Normal}(\\mu_{year}, \\sigma_{year}) \\\\ \\beta_{ndvi} & \\sim \\text{Normal}(0, 1) \\end{align*}\\] \\(\\beta_{year}\\) effects now another predictor \\((\\beta_{ndvi})\\) applies ndvi value timepoint \\(t\\). Inspect summary model Rather printing summary time, can also quickly look posterior empirical quantiles fixed effect ndvi (linear predictor coefficients) using coef: Look estimated effect ndvi using plot.mvgam type = 'pterms'  plot indicates positive linear effect ndvi log(counts). may easier visualise using histogram, especially parametric (linear) effects. can done first extracting posterior coefficients first example: posterior distribution effect ndvi stored ndvi column. quick histogram confirms inference log(counts) respond positively increases ndvi:","code":"model2 <- mvgam(count ~ s(year_fac, bs = 're') +                    ndvi - 1,                 family = poisson(),                 data = data_train,                 newdata = data_test) summary(model2) ## GAM formula: ## count ~ ndvi + s(year_fac, bs = \"re\") - 1 ##  ## Family: ## poisson ##  ## Link function: ## log ##  ## Trend model: ## None ##  ## N series: ## 1  ##  ## N timepoints: ## 160  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM coefficient (beta) estimates: ##                2.5%  50% 97.5% Rhat n_eff ## ndvi           0.32 0.39  0.46    1  1720 ## s(year_fac).1  1.10 1.40  1.70    1  2505 ## s(year_fac).2  1.80 2.00  2.20    1  2281 ## s(year_fac).3  2.20 2.40  2.60    1  1897 ## s(year_fac).4  2.30 2.50  2.70    1  2232 ## s(year_fac).5  1.20 1.40  1.60    1  2288 ## s(year_fac).6  1.00 1.30  1.50    1  2267 ## s(year_fac).7  1.10 1.40  1.70    1  2556 ## s(year_fac).8  2.10 2.30  2.50    1  2217 ## s(year_fac).9  2.70 2.90  3.00    1  1968 ## s(year_fac).10 2.00 2.20  2.40    1  2603 ## s(year_fac).11 2.30 2.40  2.60    1  2064 ## s(year_fac).12 2.50 2.70  2.80    1  1902 ## s(year_fac).13 1.40 1.60  1.80    1  2325 ## s(year_fac).14 0.63 2.00  3.30    1  1454 ## s(year_fac).15 0.73 2.00  3.20    1  1673 ## s(year_fac).16 0.74 1.90  3.20    1  1613 ## s(year_fac).17 0.73 2.00  3.20    1  1416 ##  ## GAM group-level estimates: ##                   2.5%  50% 97.5% Rhat n_eff ## mean(s(year_fac))  1.6 2.00  2.30 1.02   451 ## sd(s(year_fac))    0.4 0.59  0.96 1.00   546 ##  ## Approximate significance of GAM observation smooths: ##              edf Chi.sq p-value     ## s(year_fac) 10.9   2832  <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:55:20 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) coef(model2) ##                     2.5%       50%     97.5% Rhat n_eff ## ndvi           0.3238703 0.3902365 0.4581023    1  1720 ## s(year_fac).1  1.1365188 1.4058450 1.6577235    1  2505 ## s(year_fac).2  1.8010670 2.0009350 2.2021112    1  2281 ## s(year_fac).3  2.1889132 2.3762450 2.5703225    1  1897 ## s(year_fac).4  2.3193515 2.5045900 2.6835790    1  2232 ## s(year_fac).5  1.1944500 1.4269400 1.6385940    1  2288 ## s(year_fac).6  1.0194370 1.2684500 1.5165563    1  2267 ## s(year_fac).7  1.1363357 1.4122750 1.6805735    1  2556 ## s(year_fac).8  2.0830938 2.2729100 2.4619788    1  2217 ## s(year_fac).9  2.7169883 2.8535000 2.9868788    1  1968 ## s(year_fac).10 1.9698398 2.1826100 2.3704190    1  2603 ## s(year_fac).11 2.2599978 2.4376100 2.5998005    1  2064 ## s(year_fac).12 2.5364615 2.6917000 2.8401345    1  1902 ## s(year_fac).13 1.3762790 1.6143250 1.8473850    1  2325 ## s(year_fac).14 0.6335216 2.0001150 3.3246795    1  1454 ## s(year_fac).15 0.7257230 1.9997600 3.1933355    1  1673 ## s(year_fac).16 0.7395432 1.9439600 3.2223760    1  1613 ## s(year_fac).17 0.7292550 1.9868700 3.2186612    1  1416 plot(model2, type = 'pterms') beta_post <- as.data.frame(model2, variable = 'betas') dplyr::glimpse(beta_post) ## Rows: 2,000 ## Columns: 18 ## $ ndvi             <dbl> 0.425996, 0.413570, 0.419061, 0.422454, 0.398450, 0.3… ## $ `s(year_fac).1`  <dbl> 1.57912, 1.35922, 1.35987, 1.26014, 1.35486, 1.34965,… ## $ `s(year_fac).2`  <dbl> 1.99289, 1.93975, 1.90113, 2.01752, 1.89284, 2.00161,… ## $ `s(year_fac).3`  <dbl> 2.39844, 2.43849, 2.17660, 2.43780, 2.47060, 2.40514,… ## $ `s(year_fac).4`  <dbl> 2.42520, 2.43230, 2.38353, 2.50616, 2.49209, 2.51539,… ## $ `s(year_fac).5`  <dbl> 1.41111, 1.50256, 1.20099, 1.48075, 1.47780, 1.43706,… ## $ `s(year_fac).6`  <dbl> 1.18568, 1.01049, 1.22573, 1.09919, 1.05730, 1.33812,… ## $ `s(year_fac).7`  <dbl> 1.38444, 1.50095, 1.34319, 1.39171, 1.28743, 1.50470,… ## $ `s(year_fac).8`  <dbl> 2.24025, 2.19628, 2.22380, 2.18654, 2.29103, 2.33180,… ## $ `s(year_fac).9`  <dbl> 2.85087, 2.82355, 2.77289, 2.91273, 2.70009, 2.73278,… ## $ `s(year_fac).10` <dbl> 2.26549, 2.02703, 2.24575, 2.09158, 2.15786, 2.19188,… ## $ `s(year_fac).11` <dbl> 2.27807, 2.21506, 2.36005, 2.40034, 2.35533, 2.38627,… ## $ `s(year_fac).12` <dbl> 2.63560, 2.58363, 2.65288, 2.62733, 2.62621, 2.62781,… ## $ `s(year_fac).13` <dbl> 1.67680, 1.55301, 1.66027, 1.45560, 1.65408, 1.56315,… ## $ `s(year_fac).14` <dbl> 2.898330, 4.072930, 3.201270, 3.381070, 1.957030, 2.3… ## $ `s(year_fac).15` <dbl> 3.015740, 2.935880, 3.108230, 3.318080, 1.149890, 2.9… ## $ `s(year_fac).16` <dbl> 3.347350, 2.120660, 1.605260, 1.202070, 1.962580, 2.2… ## $ `s(year_fac).17` <dbl> 2.893970, 2.884200, 2.368160, 1.820480, 1.562180, 2.3… hist(beta_post$ndvi,      xlim = c(-1 * max(abs(beta_post$ndvi)),               max(abs(beta_post$ndvi))),      col = 'darkred',      border = 'white',      xlab = expression(beta[NDVI]),      ylab = '',      yaxt = 'n',      main = '',      lwd = 2) abline(v = 0, lwd = 2.5)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"marginaleffects-support","dir":"Articles","previous_headings":"Adding predictors as “fixed” effects","what":"marginaleffects support","title":"Overview of the mvgam package","text":"Given model used nonlinear link function (log link example), can still difficult fully understand relationship model estimating predictor response. Fortunately, marginaleffects package makes relatively straightforward. Objects class mvgam can used marginaleffects inspect contrasts, scenario-based predictions, conditional marginal effects, outcome scale. use plot_predictions function marginaleffects inspect conditional effect ndvi (use ?plot_predictions guidance modify plots):  Now easier get sense nonlinear positive relationship estimated ndvi count. Like brms, mvgam simple conditional_effects function make quick informative plots main effects. likely go-function quickly understanding patterns fitted mvgam models","code":"plot_predictions(model2,                   condition = \"ndvi\",                  # include the observed count values                  # as points, and show rugs for the observed                  # ndvi and count values on the axes                  points = 0.5, rug = TRUE) plot(conditional_effects(model2), ask = FALSE)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"adding-predictors-as-smooths","dir":"Articles","previous_headings":"","what":"Adding predictors as smooths","title":"Overview of the mvgam package","text":"Smooth functions, using penalized splines, major feature mvgam. Nonlinear splines commonly viewed variations random effects coefficients control shape spline drawn joint, penalized distribution. strategy often used ecological time series analysis capture smooth temporal variation processes seek study. construct smoothing splines, workhorse package mgcv calculate set basis functions collectively control shape complexity resulting spline. often helpful visualize basis functions get better sense splines work. ’ll create set 6 basis functions represent possible variation effect time outcome.addition constructing basis functions, mgcv also creates penalty matrix \\(S\\), contains known coefficients work constrain wiggliness resulting smooth function. fitting GAM data, must estimate smoothing parameters (\\(\\lambda\\)) penalize matrices, resulting constrained basis coefficients smoother functions less likely overfit data. key fitting GAMs Bayesian framework, can jointly estimate \\(\\lambda\\)’s using informative priors prevent overfitting expand complexity models can tackle. see practice, can now fit model replaces yearly random effects smooth function time. need reasonably complex function (large k) try accommodate temporal variation observations. Following useful advice Gavin Simpson, use b-spline basis temporal smooth. longer intercepts year, also retain primary intercept term model (-1 formula now): model can described mathematically follows: \\[\\begin{align*} \\boldsymbol{count}_t & \\sim \\text{Poisson}(\\lambda_t) \\\\ log(\\lambda_t) & = f(\\boldsymbol{time})_t + \\beta_{ndvi} * \\boldsymbol{ndvi}_t  \\\\ f(\\boldsymbol{time}) & = \\sum_{k=1}^{K}b * \\beta_{smooth} \\\\ \\beta_{smooth} & \\sim \\text{MVNormal}(0, (\\Omega * \\lambda)^{-1}) \\\\ \\beta_{ndvi} & \\sim \\text{Normal}(0, 1) \\end{align*}\\] smooth function \\(f_{time}\\) built summing across set weighted basis functions. basis functions \\((b)\\) constructed using thin plate regression basis mgcv. weights \\((\\beta_{smooth})\\) drawn penalized multivariate normal distribution precision matrix \\((\\Omega\\)) multiplied smoothing penalty \\((\\lambda)\\). \\(\\lambda\\) becomes large, acts squeeze covariances among weights \\((\\beta_{smooth})\\), leading less wiggly spline. Note sometimes multiple smoothing penalties contribute covariance matrix, showing one simplicity. View summary summary now contains posterior estimates smoothing parameters well basis coefficients nonlinear effect time. can visualize conditional time effect using plot function type = 'smooths':  default plots shows posterior empirical quantiles, can also helpful view realizations underlying function (, line different potential curve drawn posterior possible curves):","code":"model3 <- mvgam(count ~ s(time, bs = 'bs', k = 15) +                    ndvi,                 family = poisson(),                 data = data_train,                 newdata = data_test) summary(model3) ## GAM formula: ## count ~ s(time, bs = \"bs\", k = 15) + ndvi ##  ## Family: ## poisson ##  ## Link function: ## log ##  ## Trend model: ## None ##  ## N series: ## 1  ##  ## N timepoints: ## 160  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM coefficient (beta) estimates: ##              2.5%   50%  97.5% Rhat n_eff ## (Intercept)  2.00  2.10  2.200 1.01  1231 ## ndvi         0.26  0.33  0.390 1.01  1215 ## s(time).1   -2.10 -1.10  0.078 1.01   517 ## s(time).2    0.50  1.30  2.400 1.00   395 ## s(time).3   -0.46  0.46  1.500 1.01   359 ## s(time).4    1.60  2.50  3.600 1.01   340 ## s(time).5   -1.10 -0.20  0.840 1.01   359 ## s(time).6   -0.54  0.39  1.600 1.00   380 ## s(time).7   -1.50 -0.51  0.550 1.01   381 ## s(time).8    0.60  1.50  2.600 1.01   350 ## s(time).9    1.20  2.10  3.200 1.01   325 ## s(time).10  -0.32  0.55  1.600 1.01   355 ## s(time).11   0.88  1.80  2.900 1.01   324 ## s(time).12   0.71  1.50  2.500 1.01   368 ## s(time).13  -1.10 -0.29  0.650 1.01   428 ## s(time).14  -7.60 -4.30 -1.200 1.00   417 ##  ## Approximate significance of GAM observation smooths: ##          edf Chi.sq p-value     ## s(time) 9.44    793  <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:56:04 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot(model3, type = 'smooths') plot(model3, type = 'smooths', realisations = TRUE,      n_realisations = 30)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"derivatives-of-smooths","dir":"Articles","previous_headings":"Adding predictors as smooths","what":"Derivatives of smooths","title":"Overview of the mvgam package","text":"useful question modelling using GAMs identify function changing rapidly. address , can plot estimated 1st derivatives spline:  , values >0 indicate function increasing time point, values <0 indicate function declining. rapid declines appear happening around timepoints 50 toward end training period, example.","code":"plot(model3, type = 'smooths', derivatives = TRUE)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"conditional-effects","dir":"Articles","previous_headings":"Adding predictors as smooths","what":"Conditional effects","title":"Overview of the mvgam package","text":"Use conditional_effects useful plots outcome scale:  link scale:  Inspect underlying Stan code gain idea spline penalized: line // prior s(time)... shows spline basis coefficients drawn zero-centred multivariate normal distribution. precision matrix \\(S\\) penalized two different smoothing parameters (\\(\\lambda\\)’s) enforce smoothness reduce overfitting","code":"plot(conditional_effects(model3), ask = FALSE) plot(conditional_effects(model3, type = 'link'), ask = FALSE) code(model3) ## // Stan model code generated by package mvgam ## data { ##   int<lower=0> total_obs; // total number of observations ##   int<lower=0> n; // number of timepoints per series ##   int<lower=0> n_sp; // number of smoothing parameters ##   int<lower=0> n_series; // number of series ##   int<lower=0> num_basis; // total number of basis coefficients ##   vector[num_basis] zero; // prior locations for basis coefficients ##   matrix[total_obs, num_basis] X; // mgcv GAM design matrix ##   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) ##   matrix[14, 28] S1; // mgcv smooth penalty matrix S1 ##   int<lower=0> n_nonmissing; // number of nonmissing observations ##   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations ##   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations ##   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations ## } ## parameters { ##   // raw basis coefficients ##   vector[num_basis] b_raw; ##    ##   // smoothing parameters ##   vector<lower=0>[n_sp] lambda; ## } ## transformed parameters { ##   // basis coefficients ##   vector[num_basis] b; ##   b[1 : num_basis] = b_raw[1 : num_basis]; ## } ## model { ##   // prior for (Intercept)... ##   b_raw[1] ~ student_t(3, 2.6, 2.5); ##    ##   // prior for ndvi... ##   b_raw[2] ~ student_t(3, 0, 2); ##    ##   // prior for s(time)... ##   b_raw[3 : 16] ~ multi_normal_prec(zero[3 : 16], ##                                     S1[1 : 14, 1 : 14] * lambda[1] ##                                     + S1[1 : 14, 15 : 28] * lambda[2]); ##    ##   // priors for smoothing parameters ##   lambda ~ normal(5, 30); ##   { ##     // likelihood functions ##     flat_ys ~ poisson_log_glm(flat_xs, 0.0, b); ##   } ## } ## generated quantities { ##   vector[total_obs] eta; ##   matrix[n, n_series] mus; ##   vector[n_sp] rho; ##   array[n, n_series] int ypred; ##   rho = log(lambda); ##    ##   // posterior predictions ##   eta = X * b; ##   for (s in 1 : n_series) { ##     mus[1 : n, s] = eta[ytimes[1 : n, s]]; ##     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]); ##   } ## }"},{"path":"https://nicholasjclark.github.io/mvgam/articles/mvgam_overview.html","id":"latent-dynamics-in-mvgam","dir":"Articles","previous_headings":"","what":"Latent dynamics in mvgam","title":"Overview of the mvgam package","text":"Forecasts model ideal:  happening? forecasts driven almost entirely variation temporal spline, extrapolating linearly forever beyond edge training data. slight wiggles near end training set result wildly different forecasts. visualize , can plot extrapolated temporal functions --sample test set two models. extrapolated functions first model, 15 basis functions:  model well. Clearly need somehow account strong temporal autocorrelation modelling data without using smooth function time. Now onto another prominent feature mvgam: ability include (possibly latent) autocorrelated residuals regression models. , use trend_model argument (see ?mvgam_trends details different dynamic trend models supported). model use separate sub-model latent residuals evolve AR1 process (.e. error current time point function error previous time point, plus stochastic noise). also include smooth function ndvi model, rather parametric term used , showcase mvgam can include combinations smooths dynamic components: model can described mathematically follows: \\[\\begin{align*} \\boldsymbol{count}_t & \\sim \\text{Poisson}(\\lambda_t) \\\\ log(\\lambda_t) & = f(\\boldsymbol{ndvi})_t + z_t \\\\ z_t & \\sim \\text{Normal}(ar1 * z_{t-1}, \\sigma_{error}) \\\\ ar1 & \\sim \\text{Normal}(0, 1)[-1, 1] \\\\ \\sigma_{error} & \\sim \\text{Exponential}(2) \\\\ f(\\boldsymbol{ndvi}) & = \\sum_{k=1}^{K}b * \\beta_{smooth} \\\\ \\beta_{smooth} & \\sim \\text{MVNormal}(0, (\\Omega * \\lambda)^{-1}) \\end{align*}\\] term \\(z_t\\) captures autocorrelated latent residuals, modelled using AR1 process. can also notice model estimating autocorrelated errors full time period, even though time points missing observations. useful getting realistic estimates residual autocorrelation parameters. Summarise model see now returns posterior summaries latent AR1 process: View conditional smooths ndvi effect:  View posterior hindcasts / forecasts compare sample test data  trend evolving AR1 process, can also view:  -sample model performance can interrogated using leave-one-cross-validation utilities loo package (higher value preferred metric): higher estimated log predictive density (ELPD) value dynamic model suggests provides better fit -sample data. Though obvious model provides better forecasts, can quantify forecast performance models 3 4 using forecast score functions. compare models based Discrete Ranked Probability Scores (lower value preferred metric) strongly negative value suggests score dynamic model (model 4) much smaller score model smooth function time (model 3)","code":"plot(model3, type = 'forecast', newdata = data_test) ## Out of sample DRPS: ## [1] 288.607 plot_mvgam_smooth(model3, smooth = 's(time)',                   # feed newdata to the plot function to generate                   # predictions of the temporal smooth to the end of the                    # testing period                   newdata = data.frame(time = 1:max(data_test$time),                                        ndvi = 0)) abline(v = max(data_train$time), lty = 'dashed', lwd = 2) model4 <- mvgam(count ~ s(ndvi, k = 6),                 family = poisson(),                 data = data_train,                 newdata = data_test,                 trend_model = 'AR1') summary(model4) ## GAM formula: ## count ~ s(ndvi, k = 6) ##  ## Family: ## poisson ##  ## Link function: ## log ##  ## Trend model: ## AR1 ##  ## N series: ## 1  ##  ## N timepoints: ## 160  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM coefficient (beta) estimates: ##               2.5%     50% 97.5% Rhat n_eff ## (Intercept)  0.640  1.9000 2.400 1.08    72 ## s(ndvi).1   -0.083  0.0110 0.170 1.00   599 ## s(ndvi).2   -0.160  0.0180 0.320 1.00   465 ## s(ndvi).3   -0.062 -0.0012 0.052 1.00   755 ## s(ndvi).4   -0.280  0.1300 1.300 1.01   266 ## s(ndvi).5   -0.073  0.1500 0.340 1.00   643 ##  ## Approximate significance of GAM observation smooths: ##         edf Chi.sq p-value   ## s(ndvi)   1   84.1   0.078 . ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Latent trend parameter AR estimates: ##          2.5%  50% 97.5% Rhat n_eff ## ar1[1]   0.70 0.81  0.94 1.03   164 ## sigma[1] 0.67 0.79  0.95 1.01   498 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhats above 1.05 found for 79 parameters ##  *Diagnose further to investigate why the chains have not mixed ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:57:03 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot_predictions(model4,                   condition = \"ndvi\",                  points = 0.5, rug = TRUE) plot(model4, type = 'forecast', newdata = data_test) ## Out of sample DRPS: ## [1] 150.1069 plot(model4, type = 'trend', newdata = data_test) loo_compare(model3, model4) ## Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.  ## Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. ##        elpd_diff se_diff ## model4    0.0       0.0  ## model3 -557.6      66.2 fc_mod3 <- forecast(model3) fc_mod4 <- forecast(model4) score_mod3 <- score(fc_mod3, score = 'drps') score_mod4 <- score(fc_mod4, score = 'drps') sum(score_mod4$PP$score, na.rm = TRUE) - sum(score_mod3$PP$score, na.rm = TRUE) ## [1] -138.5"},{"path":"https://nicholasjclark.github.io/mvgam/articles/nmixtures.html","id":"n-mixture-models","dir":"Articles","previous_headings":"","what":"N-mixture models","title":"N-mixtures in mvgam","text":"N-mixture model fairly recent addition ecological modeller’s toolkit designed make inferences variation abundance species observations imperfect (Royle 2004). Briefly, assume \\(\\boldsymbol{Y_{,r}}\\) number individuals recorded site \\(\\) replicate sampling observation \\(r\\) (recorded non-negative integer). multiple replicate surveys done within short enough period satisfy assumption population remained closed (.e. substantial change true population size replicate surveys), can account fact observations aren’t perfect. done assuming replicate observations Binomial random variables parameterized true “latent” abundance \\(N\\) detection probability \\(p\\): \\[\\begin{align*} \\boldsymbol{Y_{,r}} & \\sim \\text{Binomial}(N_i, p_r) \\\\ N_{} & \\sim \\text{Poisson}(\\lambda_i)  \\end{align*}\\] Using set linear predictors, can estimate effects covariates \\(\\boldsymbol{X}\\) expected latent abundance (log link \\(\\lambda\\)) , jointly, effects possibly different covariates (call \\(\\boldsymbol{Q}\\)) detection probability (logit link \\(p\\)): \\[\\begin{align*} log(\\lambda) & = \\beta \\boldsymbol{X} \\\\ logit(p) & = \\gamma \\boldsymbol{Q}\\end{align*}\\] mvgam can handle type model designed propagate unobserved temporal processes evolve independently observation process State-space format. setup adapts well N-mixture models can thought State-space models latent state discrete variable representing “true” unknown population size. convenient can incorporate package’s diverse effect types (.e. multidimensional splines, time-varying effects, monotonic effects, random effects etc…) linear predictors. required work marginalization trick allows Stan’s sampling algorithms handle discrete parameters (see method “integrating ” discrete parameters works nice blog post Maxwell Joseph). family nmix() used set N-mixture models mvgam, still need little bit data wrangling ensure data set correct format (especially true one replicate survey per time period). important aspects : (1) set observation series trend_map arguments ensure replicate surveys mapped correct latent abundance model (2) inclusion cap variable defines maximum possible integer value use observation estimating latent abundance. two examples give reasonable overview can done.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/nmixtures.html","id":"example-1-a-two-species-system-with-nonlinear-trends","dir":"Articles","previous_headings":"","what":"Example 1: a two-species system with nonlinear trends","title":"N-mixtures in mvgam","text":"First use simple simulation multiple replicate observations taken timepoint two different species. simulation produces observations single site six years, five replicate surveys per year. species simulated different nonlinear temporal trends different detection probabilities. now, detection probability fixed (.e. change time association covariates). Notice add cap variable, need static, define maximum possible value think latent abundance timepoint. simply needs large enough get reasonable idea latent N values likely, without adding much computational cost: data format isn’t difficult set , differ traditional multidimensional array setup commonly used fitting N-mixture models software packages. Next ensure species series IDs included factor variables, case ’d like allow certain effects vary species Preview dataset get idea structured:","code":"set.seed(999) # Simulate observations for species 1, which shows a declining trend and 0.7 detection probability data.frame(site = 1,            # five replicates per year; six years            replicate = rep(1:5, 6),            time = sort(rep(1:6, 5)),            species = 'sp_1',            # true abundance declines nonlinearly            truth = c(rep(28, 5),                      rep(26, 5),                      rep(23, 5),                      rep(16, 5),                      rep(14, 5),                      rep(14, 5)),            # observations are taken with detection prob = 0.7            obs = c(rbinom(5, 28, 0.7),                    rbinom(5, 26, 0.7),                    rbinom(5, 23, 0.7),                    rbinom(5, 15, 0.7),                    rbinom(5, 14, 0.7),                    rbinom(5, 14, 0.7))) %>%   # add 'series' information, which is an identifier of site, replicate and species   dplyr::mutate(series = paste0('site_', site,                                 '_', species,                                 '_rep_', replicate),                 time = as.numeric(time),                 # add a 'cap' variable that defines the maximum latent N to                  # marginalize over when estimating latent abundance; in other words                 # how large do we realistically think the true abundance could be?                 cap = 100) %>%   dplyr::select(- replicate) -> testdat  # Now add another species that has a different temporal trend and a smaller  # detection probability (0.45 for this species) testdat = testdat %>%   dplyr::bind_rows(data.frame(site = 1,                               replicate = rep(1:5, 6),                               time = sort(rep(1:6, 5)),                               species = 'sp_2',                               truth = c(rep(4, 5),                                         rep(7, 5),                                         rep(15, 5),                                         rep(16, 5),                                         rep(19, 5),                                         rep(18, 5)),                               obs = c(rbinom(5, 4, 0.45),                                       rbinom(5, 7, 0.45),                                       rbinom(5, 15, 0.45),                                       rbinom(5, 16, 0.45),                                       rbinom(5, 19, 0.45),                                       rbinom(5, 18, 0.45))) %>%                      dplyr::mutate(series = paste0('site_', site,                                                    '_', species,                                                    '_rep_', replicate),                                    time = as.numeric(time),                                    cap = 50) %>%                      dplyr::select(-replicate)) testdat$species <- factor(testdat$species,                           levels = unique(testdat$species)) testdat$series <- factor(testdat$series,                          levels = unique(testdat$series)) dplyr::glimpse(testdat) ## Rows: 60 ## Columns: 7 ## $ site    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ time    <dbl> 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5,… ## $ species <fct> sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp… ## $ truth   <dbl> 28, 28, 28, 28, 28, 26, 26, 26, 26, 26, 23, 23, 23, 23, 23, 16… ## $ obs     <int> 20, 19, 23, 17, 18, 21, 18, 21, 19, 18, 17, 16, 20, 11, 19, 9,… ## $ series  <fct> site_1_sp_1_rep_1, site_1_sp_1_rep_2, site_1_sp_1_rep_3, site_… ## $ cap     <dbl> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 10… head(testdat, 12) ##    site time species truth obs            series cap ## 1     1    1    sp_1    28  20 site_1_sp_1_rep_1 100 ## 2     1    1    sp_1    28  19 site_1_sp_1_rep_2 100 ## 3     1    1    sp_1    28  23 site_1_sp_1_rep_3 100 ## 4     1    1    sp_1    28  17 site_1_sp_1_rep_4 100 ## 5     1    1    sp_1    28  18 site_1_sp_1_rep_5 100 ## 6     1    2    sp_1    26  21 site_1_sp_1_rep_1 100 ## 7     1    2    sp_1    26  18 site_1_sp_1_rep_2 100 ## 8     1    2    sp_1    26  21 site_1_sp_1_rep_3 100 ## 9     1    2    sp_1    26  19 site_1_sp_1_rep_4 100 ## 10    1    2    sp_1    26  18 site_1_sp_1_rep_5 100 ## 11    1    3    sp_1    23  17 site_1_sp_1_rep_1 100 ## 12    1    3    sp_1    23  16 site_1_sp_1_rep_2 100"},{"path":"https://nicholasjclark.github.io/mvgam/articles/nmixtures.html","id":"setting-up-the-trend_map","dir":"Articles","previous_headings":"Example 1: a two-species system with nonlinear trends","what":"Setting up the trend_map","title":"N-mixtures in mvgam","text":"Finally, need set trend_map object. crucial allowing multiple observations linked latent process model (see information argument Shared latent states vignette. case, mapping operates species site state set replicate observations time point share exact latent abundance model: Notice replicates species 1 site 1 share process (.e. trend). ensure replicates Binomial draws latent N.","code":"testdat %>%   # each unique combination of site*species is a separate process   dplyr::mutate(trend = as.numeric(factor(paste0(site, species)))) %>%   dplyr::select(trend, series) %>%   dplyr::distinct() -> trend_map trend_map ##    trend            series ## 1      1 site_1_sp_1_rep_1 ## 2      1 site_1_sp_1_rep_2 ## 3      1 site_1_sp_1_rep_3 ## 4      1 site_1_sp_1_rep_4 ## 5      1 site_1_sp_1_rep_5 ## 6      2 site_1_sp_2_rep_1 ## 7      2 site_1_sp_2_rep_2 ## 8      2 site_1_sp_2_rep_3 ## 9      2 site_1_sp_2_rep_4 ## 10     2 site_1_sp_2_rep_5"},{"path":"https://nicholasjclark.github.io/mvgam/articles/nmixtures.html","id":"modelling-with-the-nmix-family","dir":"Articles","previous_headings":"Example 1: a two-species system with nonlinear trends","what":"Modelling with the nmix() family","title":"N-mixtures in mvgam","text":"Now ready fit model using mvgam(). model allow species different detection probabilities different temporal trends. use Cmdstan backend, default use Hamiltonian Monte Carlo full Bayesian inference View automatically-generated Stan code get sense marginalization latent N works summary model shows converged nicely loo() functionality works just mvgam models aid model comparison / selection Plot estimated smooths time species’ latent abundance process (log scale)  marginaleffects support allows useful prediction-based interrogations different scales. Objects use family nmix() additional prediction scales can used (.e. link, response, detection latent_N). example, estimated detection probabilities per species, shows model -estimated detection probability species 2 (originally simulated 0.45):  common goal N-mixture modelling estimate true latent abundance. model automatically generated predictions latent abundance conditional observations. can extract produce decent plots using small function Latent abundance plots vs simulated truths species shown . , red points show imperfect observations, black line shows true latent abundance, ribbons show credible intervals estimates:   can see estimates species correctly captured true temporal variation abundance. However, also apparent low detection probabilities (like species 2) make difficult accurately estimate latent abundance. likely improve estimates additional information inform estimates detection probability, covariates reflect ability take accurate measurements","code":"mod <- mvgam(   # the observation formula sets up linear predictors for   # detection probability on the logit scale   formula = obs ~ species - 1,      # the trend_formula sets up the linear predictors for    # the latent abundance processes on the log scale   trend_formula = ~ s(time, by = trend, k = 4) + species,      # the trend_map takes care of the mapping   trend_map = trend_map,      # nmix() family and data   family = nmix(),   data = testdat,      # priors can be set in the usual way   priors = c(prior(std_normal(), class = b),              prior(normal(1, 1.5), class = Intercept_trend))) code(mod) ## // Stan model code generated by package mvgam ## functions { ##   /* Functions to return the log probability of a Poisson Binomial Mixture */ ##    ##   /* see Bollen et al 2023 for details (https://doi.org/10.1002/ece3.10595)*/ ##   real poisbin_lpmf(array[] int count, int k, array[] real lambda, ##                     array[] real p) { ##     if (max(count) > k) { ##       return negative_infinity(); ##     } ##     return poisson_log_lpmf(k | lambda) + binomial_logit_lpmf(count | k, p); ##   } ##   vector pb_logp(array[] int count, int max_k, array[] real lambda, ##                  array[] real p) { ##     int c_max = max(count); ##     if (max_k < c_max) { ##       reject(\"cap variable max_k must be >= observed counts\"); ##     } ##     vector[max_k + 1] lp; ##     for (k in 0 : (c_max - 1)) { ##       lp[k + 1] = negative_infinity(); ##     } ##     for (k in c_max : max_k) { ##       lp[k + 1] = poisbin_lpmf(count | k, lambda, p); ##     } ##     return lp; ##   } ##   real pb_lpmf(array[] int count, array[] int max_k, array[] real lambda, ##                array[] real p) { ##     // Take maximum of all supplied caps, in case they vary for some reason ##     int max_k_max = max(max_k); ##     vector[max_k_max + 1] lp; ##     lp = pb_logp(count, max_k_max, lambda, p); ##     return log_sum_exp(lp); ##   } ##   /* Functions to generate truncated Poisson variates */ ##   array[] int nmix_rng(array[] int count, array[] int max_k, ##                        array[] real lambda, array[] real p) { ##     // Take maximum of all supplied caps, in case they vary for some reason ##     int max_k_max = max(max_k); ##     vector[max_k_max + 1] lp; ##     lp = pb_logp(count, max_k_max, lambda, p); ##     return rep_array(categorical_rng(softmax(lp)) - 1, size(count)); ##   } ##   int trunc_pois_rng(int max_k, real lambda) { ##     real p_ub = poisson_cdf(max_k | lambda); ##     if (p_ub < 1e-9) { ##       return max_k; ##     } ##     real u = uniform_rng(0, p_ub); ##     int i = 0; ##     int X = 0; ##     real p = exp(-lambda); ##     real F = p; ##     while (1) { ##       if (u < F) { ##         X = i; ##         break; ##       } ##       i = i + 1; ##       p = lambda * p / i; ##       F = F + p; ##     } ##     return X; ##   } ## } ## data { ##   int<lower=0> total_obs; // total number of observations ##   int<lower=0> n; // number of timepoints per series ##   int<lower=0> n_sp_trend; // number of trend smoothing parameters ##   int<lower=0> n_lv; // number of dynamic factors ##   int<lower=0> n_series; // number of series ##   matrix[n_series, n_lv] Z; // matrix mapping series to latent states ##   int<lower=0> num_basis; // total number of basis coefficients ##   int<lower=0> num_basis_trend; // number of trend basis coefficients ##   vector[num_basis_trend] zero_trend; // prior locations for trend basis coefficients ##   matrix[total_obs, num_basis] X; // mgcv GAM design matrix ##   matrix[n * n_lv, num_basis_trend] X_trend; // trend model design matrix ##   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) ##   array[n, n_lv] int ytimes_trend; ##   int<lower=0> n_nonmissing; // number of nonmissing observations ##   array[total_obs] int<lower=0> cap; // upper limits of latent abundances ##   array[total_obs] int ytimes_array; // sorted ytimes ##   array[n, n_series] int<lower=0> ytimes_pred; // time-ordered matrix for prediction ##   int<lower=0> K_groups; // number of unique replicated observations ##   int<lower=0> K_reps; // maximum number of replicate observations ##   array[K_groups] int<lower=0> K_starts; // col of K_inds where each group starts ##   array[K_groups] int<lower=0> K_stops; // col of K_inds where each group ends ##   array[K_groups, K_reps] int<lower=0> K_inds; // indices of replicated observations ##   matrix[3, 6] S_trend1; // mgcv smooth penalty matrix S_trend1 ##   matrix[3, 6] S_trend2; // mgcv smooth penalty matrix S_trend2 ##   array[total_obs] int<lower=0> flat_ys; // flattened observations ## } ## transformed data { ##    ## } ## parameters { ##   // raw basis coefficients ##   vector[num_basis] b_raw; ##   vector[num_basis_trend] b_raw_trend; ##    ##   // smoothing parameters ##   vector<lower=0>[n_sp_trend] lambda_trend; ## } ## transformed parameters { ##   // detection probability ##   vector[total_obs] p; ##    ##   // latent states ##   matrix[n, n_lv] LV; ##    ##   // latent states and loading matrix ##   vector[n * n_lv] trend_mus; ##   matrix[n, n_series] trend; ##   matrix[n_series, n_lv] lv_coefs; ##    ##   // basis coefficients ##   vector[num_basis] b; ##   vector[num_basis_trend] b_trend; ##    ##   // observation model basis coefficients ##   b[1 : num_basis] = b_raw[1 : num_basis]; ##    ##   // process model basis coefficients ##   b_trend[1 : num_basis_trend] = b_raw_trend[1 : num_basis_trend]; ##    ##   // detection probability ##   p = X[ytimes_array,  : ] * b; ##    ##   // latent process linear predictors ##   trend_mus = X_trend * b_trend; ##   for (j in 1 : n_lv) { ##     LV[1 : n, j] = trend_mus[ytimes_trend[1 : n, j]]; ##   } ##    ##   // derived latent states ##   lv_coefs = Z; ##   for (i in 1 : n) { ##     for (s in 1 : n_series) { ##       trend[i, s] = dot_product(lv_coefs[s,  : ], LV[i,  : ]); ##     } ##   } ## } ## model { ##   // prior for speciessp_1... ##   b_raw[1] ~ std_normal(); ##    ##   // prior for speciessp_2... ##   b_raw[2] ~ std_normal(); ##    ##   // dynamic process models ##    ##   // prior for (Intercept)_trend... ##   b_raw_trend[1] ~ normal(1, 1.5); ##    ##   // prior for speciessp_2_trend... ##   b_raw_trend[2] ~ std_normal(); ##    ##   // prior for s(time):trendtrend1_trend... ##   b_raw_trend[3 : 5] ~ multi_normal_prec(zero_trend[3 : 5], ##                                          S_trend1[1 : 3, 1 : 3] ##                                          * lambda_trend[1] ##                                          + S_trend1[1 : 3, 4 : 6] ##                                            * lambda_trend[2]); ##    ##   // prior for s(time):trendtrend2_trend... ##   b_raw_trend[6 : 8] ~ multi_normal_prec(zero_trend[6 : 8], ##                                          S_trend2[1 : 3, 1 : 3] ##                                          * lambda_trend[3] ##                                          + S_trend2[1 : 3, 4 : 6] ##                                            * lambda_trend[4]); ##   lambda_trend ~ normal(5, 30); ##   { ##     // likelihood functions ##     vector[total_obs] flat_trends; ##     flat_trends = to_vector(trend); ##     for (k in 1 : K_groups) { ##       target += pb_lpmf(flat_ys[K_inds[k, K_starts[k] : K_stops[k]]] | cap[K_inds[k, K_starts[k] : K_stops[k]]], to_array_1d(flat_trends[K_inds[k, K_starts[k] : K_stops[k]]]), to_array_1d(p[K_inds[k, K_starts[k] : K_stops[k]]])); ##     } ##   } ## } ## generated quantities { ##   vector[total_obs] eta; ##   matrix[n, n_series] mus; ##   vector[n_sp_trend] rho_trend; ##   vector[n_lv] penalty; ##   array[n, n_series] int ypred; ##   array[n, n_series] int latent_ypred; ##   array[total_obs] int latent_truncpred; ##   vector[total_obs] flat_trends; ##   vector[total_obs] detprob; ##   detprob = inv_logit(p); ##   penalty = rep_vector(1e12, n_lv); ##   rho_trend = log(lambda_trend); ##    ##   // posterior predictions ##   eta = X * b; ##   { ##     flat_trends = to_vector(trend); ##      ##     // prediction for all timepoints that ignore detection prob ##     for (i in 1 : total_obs) { ##       latent_truncpred[i] = trunc_pois_rng(cap[i], exp(flat_trends[i])); ##     } ##      ##     // prediction for the nonmissing timepoints using actual obs ##     for (k in 1 : K_groups) { ##       latent_truncpred[K_inds[k, K_starts[k] : K_stops[k]]] = nmix_rng(flat_ys[K_inds[k, K_starts[k] : K_stops[k]]], ##                                                                     cap[K_inds[k, K_starts[k] : K_stops[k]]], ##                                                                     to_array_1d( ##                                                                     flat_trends[K_inds[k, K_starts[k] : K_stops[k]]]), ##                                                                     to_array_1d( ##                                                                     p[K_inds[k, K_starts[k] : K_stops[k]]])); ##     } ##     for (s in 1 : n_series) { ##       for (i in 1 : n) { ##         // true latent abundance ##         latent_ypred[i, s] = latent_truncpred[ytimes_pred[i, s]]; ##          ##         // observed abundance ##         ypred[i, s] = binomial_rng(latent_ypred[i, s], ##                                    detprob[ytimes_pred[i, s]]); ##          ##         // expected values ##         mus[i, s] = detprob[ytimes[i, s]] * latent_ypred[i, s]; ##       } ##     } ##   } ## } summary(mod) ## GAM observation formula: ## obs ~ species - 1 ##  ## GAM process formula: ## ~s(time, by = trend, k = 4) + species ##  ## Family: ## nmix ##  ## Link function: ## log ##  ## Trend model: ## None ##  ## N process models: ## 2  ##  ## N series: ## 10  ##  ## N timepoints: ## 6  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM observation model coefficient (beta) estimates: ##              2.5%  50% 97.5% Rhat n_eff ## speciessp_1 0.520 1.10   1.6    1   982 ## speciessp_2 0.031 0.71   1.2    1  1302 ##  ## GAM process model coefficient (beta) estimates: ##                               2.5%    50%  97.5% Rhat n_eff ## (Intercept)_trend            2.700  2.900  3.100    1   972 ## speciessp_2_trend           -1.100 -0.820 -0.530    1   881 ## s(time):trendtrend1.1_trend -0.061  0.027  0.220    1   821 ## s(time):trendtrend1.2_trend -0.150  0.028  0.250    1  1523 ## s(time):trendtrend1.3_trend -0.410 -0.280 -0.094    1  1102 ## s(time):trendtrend2.1_trend -0.310 -0.021  0.092    1   481 ## s(time):trendtrend2.2_trend -0.110  0.110  0.750    1   481 ## s(time):trendtrend2.3_trend  0.170  0.410  0.630    1   917 ##  ## Approximate significance of GAM process smooths: ##                        edf    F p-value    ## s(time):seriestrend1 0.596 0.26  0.0013 ** ## s(time):seriestrend2 0.881 0.41  0.0269 *  ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Mon Jan 29 1:08:01 PM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) loo(mod) ## Warning: Some Pareto k diagnostic values are slightly high. See help('pareto-k-diagnostic') for details. ##  ## Computed from 2000 by 60 log-likelihood matrix ##  ##          Estimate  SE ## elpd_loo   -140.0 3.2 ## p_loo         4.2 0.7 ## looic       280.0 6.3 ## ------ ## Monte Carlo SE of elpd_loo is 0.1. ##  ## Pareto k diagnostic values: ##                          Count Pct.    Min. n_eff ## (-Inf, 0.5]   (good)     57    95.0%   386        ##  (0.5, 0.7]   (ok)        3     5.0%   567        ##    (0.7, 1]   (bad)       0     0.0%   <NA>       ##    (1, Inf)   (very bad)  0     0.0%   <NA>       ##  ## All Pareto k estimates are ok (k < 0.7). ## See help('pareto-k-diagnostic') for details. plot(mod, type = 'smooths', trend_effects = TRUE) plot_predictions(mod, condition = 'species',                  type = 'detection') +   ylab('Pr(detection)') +   ylim(c(0, 1)) +   theme_classic() +   theme(legend.position = 'none') hc <- hindcast(mod, type = 'latent_N')  # Function to plot latent abundance estimates vs truth plot_latentN = function(hindcasts, data, species = 'sp_1'){   all_series <- unique(data %>%                          dplyr::filter(species == !!species) %>%                          dplyr::pull(series))      # Grab the first replicate that represents this series   # so we can get the true simulated values   series <- as.numeric(all_series[1])   truths <- data %>%     dplyr::arrange(time, series) %>%     dplyr::filter(series == !!levels(data$series)[series]) %>%     dplyr::pull(truth)      # In case some replicates have missing observations,   # pull out predictions for ALL replicates and average over them   hcs <- do.call(rbind, lapply(all_series, function(x){     ind <- which(names(hindcasts$hindcasts) %in% as.character(x))     hindcasts$hindcasts[[ind]]   }))      # Calculate posterior empirical quantiles of predictions   pred_quantiles <- data.frame(t(apply(hcs, 2, function(x)      quantile(x, probs = c(0.05, 0.2, 0.3, 0.4,                            0.5, 0.6, 0.7, 0.8, 0.95)))))   pred_quantiles$time <- 1:NROW(pred_quantiles)   pred_quantiles$truth <- truths      # Grab observations   data %>%     dplyr::filter(series %in% all_series) %>%     dplyr::select(time, obs) -> observations      # Plot   ggplot(pred_quantiles, aes(x = time, group = 1)) +     geom_ribbon(aes(ymin = X5., ymax = X95.), fill = \"#DCBCBC\") +      geom_ribbon(aes(ymin = X30., ymax = X70.), fill = \"#B97C7C\") +     geom_line(aes(x = time, y = truth),               colour = 'black', linewidth = 1) +     geom_point(aes(x = time, y = truth),                shape = 21, colour = 'white', fill = 'black',                size = 2.5) +     geom_jitter(data = observations, aes(x = time, y = obs),                 width = 0.06,                  shape = 21, fill = 'darkred', colour = 'white', size = 2.5) +     labs(y = 'Latent abundance (N)',          x = 'Time',          title = species) } plot_latentN(hc, testdat, species = 'sp_1') plot_latentN(hc, testdat, species = 'sp_2')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/nmixtures.html","id":"example-2-a-two-species-system-with-nonlinear-trends","dir":"Articles","previous_headings":"","what":"Example 2: a two-species system with nonlinear trends","title":"N-mixtures in mvgam","text":"Now another example larger dataset. use data Jeff Doser’s simulation example wonderful spAbundance package. simulated data include one continuous site-level covariate, one factor site-level covariate two continuous sample-level covariates. example allow us examine can include possibly nonlinear effects latent process detection probability models. Download data grab observations / covariate measurements one species Next wrangle appropriate ‘long’ data format, adding indicators time series working mvgam. also add cap variable represent maximum latent N marginalize observation data include observations 225 sites three replicates per site, though observations missing final step data preparation course trend_map, sets mapping observation replicates latent abundance models. done way example Now ready fit model using mvgam(). use penalized splines continuous covariate effects detect possible nonlinear associations. also showcase mvgam can make use different approximation algorithms available Stan using meanfield variational Bayes approximator (reduces computation time substantially) Inspect model summary don’t bother looking estimates individual spline coefficients. Notice longer receive information convergence use MCMC sampling model can make use marginaleffects support interrogating model targeted predictions. First, can inspect estimated average detection probability Next investigate estimated effects covariates latent abundance using conditional_effects() function specifying type = 'link'; return plots expectation scale effect continuous covariate expected latent abundance  effect factor covariate expected latent abundance, estimated hierarchical random effect  Now can investigate estimated effects covariates detection probability using type = 'detection' covariate smooths estimated somewhat nonlinear logit scale according model summary (based approximate significances). inspecting conditional effects covariate probability scale intuitive useful   targeted predictions also easy marginaleffects support. example, can ask: detection probability change change detection covariates?  model found support important covariate effects, course ’d want interrogate well model predicts think possible spatial effects capture unmodelled variation latent abundance.","code":"# Date link load(url('https://github.com/doserjef/spAbundance/raw/main/data/dataNMixSim.rda')) data.one.sp <- dataNMixSim  # Pull out observations for one species data.one.sp$y <- data.one.sp$y[1, , ]  # Abundance covariates that don't change across repeat sampling observations abund.cov <- dataNMixSim$abund.covs[, 1] abund.factor <- as.factor(dataNMixSim$abund.covs[, 2])  # Detection covariates that can change across repeat sampling observations # Note that `NA`s are not allowed for covariates in mvgam, so we randomly # impute them here det.cov <- dataNMixSim$det.covs$det.cov.1[,] det.cov[is.na(det.cov)] <- rnorm(length(which(is.na(det.cov)))) det.cov2 <- dataNMixSim$det.covs$det.cov.2 det.cov2[is.na(det.cov2)] <- rnorm(length(which(is.na(det.cov2)))) mod_data <- do.call(rbind,                     lapply(1:NROW(data.one.sp$y), function(x){                       data.frame(y = data.one.sp$y[x,],                                  abund_cov = abund.cov[x],                                  abund_fac = abund.factor[x],                                  det_cov = det.cov[x,],                                  det_cov2 = det.cov2[x,],                                  replicate = 1:NCOL(data.one.sp$y),                                  site = paste0('site', x))                     })) %>%   dplyr::mutate(species = 'sp_1',                 series = as.factor(paste0(site, '_', species, '_', replicate))) %>%   dplyr::mutate(site = factor(site, levels = unique(site)),                 species = factor(species, levels = unique(species)),                 time = 1,                 cap = max(data.one.sp$y, na.rm = TRUE) + 20) NROW(mod_data) ## [1] 675 dplyr::glimpse(mod_data) ## Rows: 675 ## Columns: 11 ## $ y         <int> 1, NA, NA, NA, 2, 2, NA, 1, NA, NA, 0, 1, 0, 0, 0, 0, NA, NA… ## $ abund_cov <dbl> -0.3734384, -0.3734384, -0.3734384, 0.7064305, 0.7064305, 0.… ## $ abund_fac <fct> 3, 3, 3, 4, 4, 4, 9, 9, 9, 2, 2, 2, 3, 3, 3, 2, 2, 2, 1, 1, … ## $ det_cov   <dbl> -1.2827999, -0.6412036, 1.7083192, 0.7640157, 0.1954809, 0.9… ## $ det_cov2  <dbl> 2.030473137, 0.151511085, -0.439251153, -1.481393226, 1.0455… ## $ replicate <int> 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, … ## $ site      <fct> site1, site1, site1, site2, site2, site2, site3, site3, site… ## $ species   <fct> sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, sp_1, … ## $ series    <fct> site1_sp_1_1, site1_sp_1_2, site1_sp_1_3, site2_sp_1_1, site… ## $ time      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ cap       <dbl> 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, … head(mod_data) ##    y  abund_cov abund_fac    det_cov   det_cov2 replicate  site species ## 1  1 -0.3734384         3 -1.2827999  2.0304731         1 site1    sp_1 ## 2 NA -0.3734384         3 -0.6412036  0.1515111         2 site1    sp_1 ## 3 NA -0.3734384         3  1.7083192 -0.4392512         3 site1    sp_1 ## 4 NA  0.7064305         4  0.7640157 -1.4813932         1 site2    sp_1 ## 5  2  0.7064305         4  0.1954809  1.0455536         2 site2    sp_1 ## 6  2  0.7064305         4  0.9673034  1.9197118         3 site2    sp_1 ##         series time cap ## 1 site1_sp_1_1    1  33 ## 2 site1_sp_1_2    1  33 ## 3 site1_sp_1_3    1  33 ## 4 site2_sp_1_1    1  33 ## 5 site2_sp_1_2    1  33 ## 6 site2_sp_1_3    1  33 mod_data %>%   # each unique combination of site*species is a separate process   dplyr::mutate(trend = as.numeric(factor(paste0(site, species)))) %>%   dplyr::select(trend, series) %>%   dplyr::distinct() -> trend_map  trend_map %>%   dplyr::arrange(trend) %>%   head(12) ##    trend         series ## 1      1 site100_sp_1_1 ## 2      1 site100_sp_1_2 ## 3      1 site100_sp_1_3 ## 4      2 site101_sp_1_1 ## 5      2 site101_sp_1_2 ## 6      2 site101_sp_1_3 ## 7      3 site102_sp_1_1 ## 8      3 site102_sp_1_2 ## 9      3 site102_sp_1_3 ## 10     4 site103_sp_1_1 ## 11     4 site103_sp_1_2 ## 12     4 site103_sp_1_3 mod <- mvgam(   # effects of covariates on detection probability;   # here we use penalized splines for both continuous covariates   formula = y ~ s(det_cov, k = 3) + s(det_cov2, k = 3),      # effects of the covariates on latent abundance;   # here we use a penalized spline for the continuous covariate and   # hierarchical intercepts for the factor covariate   trend_formula = ~ s(abund_cov, k = 3) +     s(abund_fac, bs = 're'),      # link multiple observations to each site   trend_map = trend_map,      # nmix() family and supplied data   family = nmix(),   data = mod_data,      # standard normal priors on key regression parameters   priors = c(prior(std_normal(), class = 'b'),              prior(std_normal(), class = 'Intercept'),              prior(std_normal(), class = 'Intercept_trend')),      # use Stan's variational inference for quicker results   algorithm = 'meanfield',   samples = 1000) summary(mod, include_betas = FALSE) ## GAM observation formula: ## y ~ s(det_cov, k = 3) + s(det_cov2, k = 3) ##  ## GAM process formula: ## ~s(abund_cov, k = 3) + s(abund_fac, bs = \"re\") ##  ## Family: ## nmix ##  ## Link function: ## log ##  ## Trend model: ## None ##  ## N process models: ## 225  ##  ## N series: ## 675  ##  ## N timepoints: ## 1  ##  ## Status: ## Fitted using Stan  ## 1 chains, each with iter = 1000; warmup = ; thin = 1  ## Total post-warmup draws = 1000 ##  ##  ## GAM observation model coefficient (beta) estimates: ##             2.5%  50% 97.5% Rhat n.eff ## (Intercept) 0.35 0.75   1.2  NaN   NaN ##  ## Approximate significance of GAM observation smooths: ##              edf Chi.sq p-value     ## s(det_cov)  1.99   86.7 0.00086 *** ## s(det_cov2) 2.00  359.2 < 2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## GAM process model coefficient (beta) estimates: ##                   2.5% 50% 97.5% Rhat n.eff ## (Intercept)_trend 0.91 1.2   1.4  NaN   NaN ##  ## GAM process model group-level estimates: ##                           2.5%   50% 97.5% Rhat n.eff ## mean(s(abund_fac))_trend -1.70 -1.40 -1.20  NaN   NaN ## sd(s(abund_fac))_trend    0.17  0.28  0.48  NaN   NaN ##  ## Approximate significance of GAM process smooths: ##               edf    F p-value   ## s(abund_cov) 1.90 2.13   0.978   ## s(abund_fac) 8.87 1.28   0.039 * ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Posterior approximation used: no diagnostics to compute avg_predictions(mod, type = 'detection') ##  ##  Estimate 2.5 % 97.5 % ##     0.647 0.568  0.721 ##  ## Columns: estimate, conf.low, conf.high  ## Type:  detection abund_plots <- plot(conditional_effects(mod,                                         type = 'link',                                         effects = c('abund_cov',                                                     'abund_fac')),                     plot = FALSE) abund_plots[[1]] +   ylab('Expected latent abundance') abund_plots[[2]] +   ylab('Expected latent abundance') det_plots <- plot(conditional_effects(mod,                                       type = 'detection',                                       effects = c('det_cov',                                                   'det_cov2')),                   plot = FALSE) det_plots[[1]] +   ylab('Pr(detection)') det_plots[[2]] +   ylab('Pr(detection)') fivenum_round = function(x)round(fivenum(x, na.rm = TRUE), 2)  plot_predictions(mod,                   newdata = datagrid(det_cov = unique,                                     det_cov2 = fivenum_round),                  by = c('det_cov', 'det_cov2'),                  type = 'detection') +   theme_classic() +   ylab('Pr(detection)')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/nmixtures.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further reading","title":"N-mixtures in mvgam","text":"following papers resources offer useful material N-mixture models ecological population dynamics investigations: Guélat, Jérôme, Kéry, Marc. “Effects Spatial Autocorrelation Imperfect Detection Species Distribution Models.” Methods Ecology Evolution 9 (2018): 1614–25. Kéry, Marc, Royle Andrew J. “Applied hierarchical modeling ecology: Analysis distribution, abundance species richness R BUGS: Volume 2: Dynamic advanced models”. London, UK: Academic Press (2020). Royle, Andrew J. “N‐mixture models estimating population size spatially replicated counts.” Biometrics 60.1 (2004): 108-115.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"the-trend_map-argument","dir":"Articles","previous_headings":"","what":"The trend_map argument","title":"Shared latent states in mvgam","text":"trend_map argument mvgam() function optional data.frame can used specify series depend latent process models (called “trends” mvgam). can particularly useful wish force multiple observed time series depend latent trend process, different observation processes. argument supplied, latent factor model set setting use_lv = TRUE using supplied trend_map set shared trends. Users familiar MARSS family packages recognize way specifying \\(Z\\) matrix. data.frame needs column names series trend, integer values trend column state trend series depend . series column single unique entry time series data, names perfectly match factor levels series variable data). example, simulate collection three integer-valued time series (using sim_mvgam), following trend_map force first two series share latent trend process: can see factor levels trend_map match data:","code":"set.seed(122) simdat <- sim_mvgam(trend_model = 'AR1',                     prop_trend = 0.6,                     mu = c(0, 1, 2),                     family = poisson()) trend_map <- data.frame(series = unique(simdat$data_train$series),                         trend = c(1, 1, 2)) trend_map ##     series trend ## 1 series_1     1 ## 2 series_2     1 ## 3 series_3     2 all.equal(levels(trend_map$series), levels(simdat$data_train$series)) ## [1] TRUE"},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"checking-trend_map-with-run_model-false","dir":"Articles","previous_headings":"The trend_map argument","what":"Checking trend_map with run_model = FALSE","title":"Shared latent states in mvgam","text":"Supplying trend_map mvgam function simple model, setting run_model = FALSE, allows us inspect constructed Stan code data objects used condition model. set model series different observation process (different intercept per series case), two latent dynamic process models evolve independent AR1 processes also contain shared nonlinear smooth function capture repeated seasonality. model complicated show can learn shared independent effects collections time series mvgam framework: Inspecting Stan code shows model dynamic factor model loadings constructed reflect supplied trend_map: Notice line states “lv_coefs = Z;”. uses supplied \\(Z\\) matrix construct loading coefficients. supplied matrix now looks exactly like ’d use create similar model MARSS package:","code":"fake_mod <- mvgam(y ~                      # observation model formula, which has a                      # different intercept per series                     series - 1,                                      # process model formula, which has a shared seasonal smooth                   # (each latent process model shares the SAME smooth)                   trend_formula = ~ s(season, bs = 'cc', k = 6),                                      # AR1 dynamics (each latent process model has DIFFERENT)                   # dynamics                   trend_model = 'AR1',                                      # supplied trend_map                   trend_map = trend_map,                                      # data and observation family                   family = poisson(),                   data = simdat$data_train,                   run_model = FALSE) code(fake_mod) ## // Stan model code generated by package mvgam ## data { ##   int<lower=0> total_obs; // total number of observations ##   int<lower=0> n; // number of timepoints per series ##   int<lower=0> n_sp_trend; // number of trend smoothing parameters ##   int<lower=0> n_lv; // number of dynamic factors ##   int<lower=0> n_series; // number of series ##   matrix[n_series, n_lv] Z; // matrix mapping series to latent states ##   int<lower=0> num_basis; // total number of basis coefficients ##   int<lower=0> num_basis_trend; // number of trend basis coefficients ##   vector[num_basis_trend] zero_trend; // prior locations for trend basis coefficients ##   matrix[total_obs, num_basis] X; // mgcv GAM design matrix ##   matrix[n * n_lv, num_basis_trend] X_trend; // trend model design matrix ##   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) ##   array[n, n_lv] int ytimes_trend; ##   int<lower=0> n_nonmissing; // number of nonmissing observations ##   matrix[4, 4] S_trend1; // mgcv smooth penalty matrix S_trend1 ##   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations ##   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations ##   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations ## } ## transformed data { ##    ## } ## parameters { ##   // raw basis coefficients ##   vector[num_basis] b_raw; ##   vector[num_basis_trend] b_raw_trend; ##    ##   // latent state SD terms ##   vector<lower=0>[n_lv] sigma; ##    ##   // latent state AR1 terms ##   vector<lower=-1.5, upper=1.5>[n_lv] ar1; ##    ##   // latent states ##   matrix[n, n_lv] LV; ##    ##   // smoothing parameters ##   vector<lower=0>[n_sp_trend] lambda_trend; ## } ## transformed parameters { ##   // latent states and loading matrix ##   vector[n * n_lv] trend_mus; ##   matrix[n, n_series] trend; ##   matrix[n_series, n_lv] lv_coefs; ##    ##   // basis coefficients ##   vector[num_basis] b; ##   vector[num_basis_trend] b_trend; ##    ##   // observation model basis coefficients ##   b[1 : num_basis] = b_raw[1 : num_basis]; ##    ##   // process model basis coefficients ##   b_trend[1 : num_basis_trend] = b_raw_trend[1 : num_basis_trend]; ##    ##   // latent process linear predictors ##   trend_mus = X_trend * b_trend; ##    ##   // derived latent states ##   lv_coefs = Z; ##   for (i in 1 : n) { ##     for (s in 1 : n_series) { ##       trend[i, s] = dot_product(lv_coefs[s,  : ], LV[i,  : ]); ##     } ##   } ## } ## model { ##   // prior for seriesseries_1... ##   b_raw[1] ~ student_t(3, 0, 2); ##    ##   // prior for seriesseries_2... ##   b_raw[2] ~ student_t(3, 0, 2); ##    ##   // prior for seriesseries_3... ##   b_raw[3] ~ student_t(3, 0, 2); ##    ##   // priors for AR parameters ##   ar1 ~ std_normal(); ##    ##   // priors for latent state SD parameters ##   sigma ~ student_t(3, 0, 2.5); ##    ##   // dynamic process models ##    ##   // prior for s(season)_trend... ##   b_raw_trend[1 : 4] ~ multi_normal_prec(zero_trend[1 : 4], ##                                          S_trend1[1 : 4, 1 : 4] ##                                          * lambda_trend[1]); ##   lambda_trend ~ normal(5, 30); ##   for (j in 1 : n_lv) { ##     LV[1, j] ~ normal(trend_mus[ytimes_trend[1, j]], sigma[j]); ##     for (i in 2 : n) { ##       LV[i, j] ~ normal(trend_mus[ytimes_trend[i, j]] ##                         + ar1[j] ##                           * (LV[i - 1, j] - trend_mus[ytimes_trend[i - 1, j]]), ##                         sigma[j]); ##     } ##   } ##   { ##     // likelihood functions ##     vector[n_nonmissing] flat_trends; ##     flat_trends = to_vector(trend)[obs_ind]; ##     flat_ys ~ poisson_log_glm(append_col(flat_xs, flat_trends), 0.0, ##                               append_row(b, 1.0)); ##   } ## } ## generated quantities { ##   vector[total_obs] eta; ##   matrix[n, n_series] mus; ##   vector[n_sp_trend] rho_trend; ##   vector[n_lv] penalty; ##   array[n, n_series] int ypred; ##   penalty = 1.0 / (sigma .* sigma); ##   rho_trend = log(lambda_trend); ##    ##   // posterior predictions ##   eta = X * b; ##   for (s in 1 : n_series) { ##     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; ##     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]); ##   } ## } fake_mod$model_data$Z ##      [,1] [,2] ## [1,]    1    0 ## [2,]    1    0 ## [3,]    0    1"},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"fitting-and-inspecting-the-model","dir":"Articles","previous_headings":"The trend_map argument","what":"Fitting and inspecting the model","title":"Shared latent states in mvgam","text":"Though model doesn’t perfectly match data-generating process (allowed series different underlying dynamics), can still fit show resulting inferences look like: summary model informative shows two latent process models estimated, even though three observed time series. model converges well Quick plots main effects can made using conditional_effects():  Even informative plots latent processes. series 1 2 share exact estimates, estimates series 3 different:    However, forecasts series’ 1 2 differ different intercepts observation model","code":"full_mod <- mvgam(y ~ series - 1,                   trend_formula = ~ s(season, bs = 'cc', k = 6),                   trend_model = 'AR1',                   trend_map = trend_map,                   family = poisson(),                   data = simdat$data_train) summary(full_mod) ## GAM observation formula: ## y ~ series - 1 ##  ## GAM process formula: ## ~s(season, bs = \"cc\", k = 6) ##  ## Family: ## poisson ##  ## Link function: ## log ##  ## Trend model: ## AR1 ##  ## N process models: ## 2  ##  ## N series: ## 3  ##  ## N timepoints: ## 75  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## GAM observation model coefficient (beta) estimates: ##                 2.5%   50% 97.5% Rhat n_eff ## seriesseries_1 -0.15 0.088  0.31 1.00  1895 ## seriesseries_2  0.92 1.100  1.20 1.00  1267 ## seriesseries_3  1.90 2.100  2.30 1.02   256 ##  ## Process model AR parameter estimates: ##         2.5%    50%  97.5% Rhat n_eff ## ar1[1] -0.72 -0.420 -0.056    1   676 ## ar1[2] -0.28 -0.011  0.280    1  1433 ##  ## Process error parameter estimates: ##          2.5%  50% 97.5% Rhat n_eff ## sigma[1] 0.33 0.49  0.67    1   487 ## sigma[2] 0.59 0.73  0.91    1   948 ##  ## GAM process model coefficient (beta) estimates: ##                    2.5%    50% 97.5% Rhat n_eff ## s(season).1_trend -0.22 -0.011  0.20    1  1612 ## s(season).2_trend -0.27 -0.045  0.18    1  1745 ## s(season).3_trend -0.15  0.074  0.29    1  1347 ## s(season).4_trend -0.15  0.067  0.28    1  1561 ##  ## Approximate significance of GAM process smooths: ##            edf   F p-value ## s(season) 1.52 0.1    0.91 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:57:59 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot(conditional_effects(full_mod, type = 'link'), ask = FALSE) plot(full_mod, type = 'trend', series = 1) plot(full_mod, type = 'trend', series = 2) plot(full_mod, type = 'trend', series = 3) plot(full_mod, type = 'forecast', series = 1) plot(full_mod, type = 'forecast', series = 2) plot(full_mod, type = 'forecast', series = 3)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"example-signal-detection","dir":"Articles","previous_headings":"","what":"Example: signal detection","title":"Shared latent states in mvgam","text":"Now explore complicated example. simulate true hidden signal trying track. signal depends nonlinearly covariate (called productivity, represents measure productive landscape ). signal also demonstrates fairly large amount temporal autocorrelation: Plot signal inspect ’s evolution time  plot relationship signal productivity covariate:  Next simulate three sensors trying track hidden signal. sensors different observation errors can depend nonlinearly second external covariate, called temperature example. makes use gamSim Plot sensor observations  now plot observed relationships three sensors temperature covariate","code":"set.seed(543210) # simulate a nonlinear relationship using the mgcv function gamSim signal_dat <- gamSim(n = 100, eg = 1, scale = 1) ## Gu & Wahba 4 term additive model # productivity is one of the variables in the simulated data productivity <- signal_dat$x2  # simulate the true signal, which already has a nonlinear relationship # with productivity; we will add in a fairly strong AR1 process to  # contribute to the signal true_signal <- as.vector(scale(signal_dat$y) +                          arima.sim(100, model = list(ar = 0.8, sd = 0.1))) plot(true_signal, type = 'l',      bty = 'l', lwd = 2,      ylab = 'True signal',      xlab = 'Time') plot(true_signal ~ productivity,      pch = 16, bty = 'l',      ylab = 'True signal',      xlab = 'Productivity') set.seed(543210) sim_series = function(n_series = 3, true_signal){   temp_effects <- gamSim(n = 100, eg = 7, scale = 0.1)   temperature <- temp_effects$y   alphas <- rnorm(n_series, sd = 2)    do.call(rbind, lapply(seq_len(n_series), function(series){     data.frame(observed = rnorm(length(true_signal),                                 mean = alphas[series] +                                        1.5*as.vector(scale(temp_effects[, series + 1])) +                                        true_signal,                                 sd = runif(1, 1, 2)),                series = paste0('sensor_', series),                time = 1:length(true_signal),                temperature = temperature,                productivity = productivity,                true_signal = true_signal)    }))   } model_dat <- sim_series(true_signal = true_signal) %>%   dplyr::mutate(series = factor(series)) ## Gu & Wahba 4 term additive model, correlated predictors plot_mvgam_series(data = model_dat, y = 'observed',                   series = 'all') plot(observed ~ temperature, data = model_dat %>%    dplyr::filter(series == 'sensor_1'),    pch = 16, bty = 'l',    ylab = 'Sensor 1',    xlab = 'Temperature') plot(observed ~ temperature, data = model_dat %>%    dplyr::filter(series == 'sensor_2'),    pch = 16, bty = 'l',    ylab = 'Sensor 2',    xlab = 'Temperature') plot(observed ~ temperature, data = model_dat %>%    dplyr::filter(series == 'sensor_3'),    pch = 16, bty = 'l',    ylab = 'Sensor 3',    xlab = 'Temperature')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"the-shared-signal-model","dir":"Articles","previous_headings":"Example: signal detection","what":"The shared signal model","title":"Shared latent states in mvgam","text":"Now can formulate fit model allows sensor’s observation error depend nonlinearly temperature allowing true signal depend nonlinearly productivity. fixing values trend column 1 trend_map, assuming observation sensors tracking latent signal. use informative priors two variance components (process error observation error), reflect prior belief observation error smaller overall true process error View reduced version model summary many spline coefficients model","code":"mod <- mvgam(formula =                # formula for observations, allowing for different                # intercepts and hierarchical smooth effects of temperature                observed ~ series +                 s(temperature, k = 10) +                s(series, temperature, bs = 'sz', k = 8),                            trend_formula =                # formula for the latent signal, which can depend                # nonlinearly on productivity                ~ s(productivity, k = 8),                            trend_model =                # in addition to productivity effects, the signal is                # assumed to exhibit temporal autocorrelation                'AR1',                            trend_map =                # trend_map forces all sensors to track the same                # latent signal                data.frame(series = unique(model_dat$series),                           trend = c(1, 1, 1)),                            # informative priors on process error              # and observation error will help with convergence              priors = c(prior(normal(2, 0.5), class = sigma),                         prior(normal(1, 0.5), class = sigma_obs)),                            # Gaussian observations              family = gaussian(),              data = model_dat) summary(mod, include_betas = FALSE) ## GAM observation formula: ## observed ~ series + s(temperature, k = 10) + s(series, temperature,  ##     bs = \"sz\", k = 8) ##  ## GAM process formula: ## ~s(productivity, k = 8) ##  ## Family: ## gaussian ##  ## Link function: ## identity ##  ## Trend model: ## AR1 ##  ## N process models: ## 1  ##  ## N series: ## 3  ##  ## N timepoints: ## 100  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1100; warmup = 600; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## Observation error parameter estimates: ##              2.5% 50% 97.5% Rhat n_eff ## sigma_obs[1]  1.6 1.9   2.2    1  1757 ## sigma_obs[2]  1.4 1.7   2.0    1  1090 ## sigma_obs[3]  1.3 1.5   1.8    1  1339 ##  ## GAM observation model coefficient (beta) estimates: ##                 2.5%   50% 97.5% Rhat n_eff ## (Intercept)     0.72  1.70  2.50 1.01   360 ## seriessensor_2 -2.10 -0.96  0.32 1.00  1068 ## seriessensor_3 -3.40 -2.00 -0.39 1.00  1154 ##  ## Approximate significance of GAM observation smooths: ##                        edf     F p-value     ## s(temperature)        1.22 12.66 < 2e-16 *** ## s(series,temperature) 1.92  0.95 6.9e-06 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Process model AR parameter estimates: ##        2.5%  50% 97.5% Rhat n_eff ## ar1[1] 0.33 0.59  0.83    1   492 ##  ## Process error parameter estimates: ##          2.5% 50% 97.5% Rhat n_eff ## sigma[1] 0.72   1   1.3 1.01   392 ##  ## Approximate significance of GAM process smooths: ##                 edf    F p-value     ## s(productivity) 3.6 8.31 5.1e-05 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhats above 1.05 found for 28 parameters ##  *Diagnose further to investigate why the chains have not mixed ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 11:59:46 AM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"inspecting-effects-on-both-process-and-observation-models","dir":"Articles","previous_headings":"Example: signal detection","what":"Inspecting effects on both process and observation models","title":"Shared latent states in mvgam","text":"Don’t pay much attention approximate p-values smooth terms. calculation values incredibly sensitive estimates smoothing parameters don’t tend find meaningful. meaningful, however, prediction-based plots smooth functions. example, estimated response underlying signal productivity:  estimated relationships sensor observations temperature covariate:  main effects can quickly plotted conditional_effects:  conditional_effects simply wrapper flexible plot_predictions function marginaleffects package. can get useful plots effects using function customisation:  successfully estimated effects, nonlinear, impact hidden process observations. single joint model. can always challenges models, particularly estimating process observation error time. example, pairs plot observation error sensor 1 hidden process error shows strong correlations might want deal using structured prior:  leave model -example","code":"plot(mod, type = 'smooths', trend_effects = TRUE) plot(mod, type = 'smooths') plot(conditional_effects(mod, type = 'link'), ask = FALSE) plot_predictions(mod,                   condition = c('temperature', 'series', 'series'),                  points = 0.5) +   theme(legend.position = 'none') pairs(mod, variable = c('sigma[1]', 'sigma_obs[1]'))"},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"recovering-the-hidden-signal","dir":"Articles","previous_headings":"Example: signal detection","what":"Recovering the hidden signal","title":"Shared latent states in mvgam","text":"final key question whether can successfully recover true hidden signal. trend slot returned model parameters estimates signal, can easily plot using mvgam S3 method plot. can also overlay true values hidden signal, shows model done good job recovering :","code":"plot(mod, type = 'trend')  # Overlay the true simulated signal points(true_signal, pch = 16, cex = 1, col = 'white') points(true_signal, pch = 16, cex = 0.8)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/shared_states.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further reading","title":"Shared latent states in mvgam","text":"following papers resources offer lot useful material types State-Space models can applied practice: Holmes, Elizabeth E., Eric J. Ward, Wills Kellie. “MARSS: multivariate autoregressive state-space models analyzing time-series data.” R Journal. 4.1 (2012): 11. Ward, Eric J., et al. “Inferring spatial structure time‐series data: using multivariate state‐space models detect metapopulation structure California sea lions Gulf California, Mexico.” Journal Applied Ecology 47.1 (2010): 47-56. Auger‐Méthé, Marie, et al. “guide state–space modeling ecological time series.” Ecological Monographs 91.4 (2021): e01470.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"time-varying-effects","dir":"Articles","previous_headings":"","what":"Time-varying effects","title":"Time-varying effects in mvgam","text":"Dynamic fixed-effect coefficients (often referred dynamic linear models) can readily incorporated GAMs / DGAMs. mvgam, dynamic() formula wrapper offers convenient interface set . plan incorporate range dynamic options (random walk, AR1 etc…) moment low-rank Gaussian Process (GP) smooths allowed (making use either gp basis mgcv Hilbert space approximate GPs). advantageous splines random walk effects several reasons. First, GPs force time-varying effect smooth. often makes sense reality, expect regression coefficient change rapidly one time point next. Second, GPs provide information ‘global’ dynamics time-varying effect length-scale parameters. means can use provide accurate forecasts effect expected change future, something couldn’t well used splines estimate effect. example illustrates.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"simulating-time-varying-effects","dir":"Articles","previous_headings":"Time-varying effects","what":"Simulating time-varying effects","title":"Time-varying effects in mvgam","text":"Simulate time-varying coefficient using squared exponential Gaussian Process function length scale \\(\\rho\\)=10. using internal function mvgam (sim_gp function): plot time-varying coefficient shows changes smoothly time:  Next need simulate values covariate, call temp (represent \\(temperature\\)). case just use standard normal distribution simulate covariate: Finally, simulate outcome variable, Gaussian observation process (observation error) time-varying effect \\(temperature\\)  Gather data data.frame fitting models, split data training testing folds. Plot series","code":"set.seed(1111) N <- 200 beta_temp <- mvgam:::sim_gp(rnorm(1),                             alpha_gp = 0.75,                             rho_gp = 10,                             h = N) + 0.5 plot(beta_temp, type = 'l', lwd = 3,       bty = 'l', xlab = 'Time', ylab = 'Coefficient',      col = 'darkred') box(bty = 'l', lwd = 2) temp <- rnorm(N, sd = 1) out <- rnorm(N, mean = 4 + beta_temp * temp,              sd = 0.25) time <- seq_along(temp) plot(out,  type = 'l', lwd = 3,       bty = 'l', xlab = 'Time', ylab = 'Outcome',      col = 'darkred') box(bty = 'l', lwd = 2) data <- data.frame(out, temp, time) data_train <- data[1:190,] data_test <- data[191:200,] plot_mvgam_series(data = data_train, newdata = data_test, y = 'out')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"the-dynamic-function","dir":"Articles","previous_headings":"Time-varying effects","what":"The dynamic() function","title":"Time-varying effects in mvgam","text":"Time-varying coefficients can fairly easily set using s() gp() wrapper functions mvgam formulae fitting nonlinear effect time using covariate interest numeric variable (see ?mgcv::s ?brms::gp details). dynamic() formula wrapper offers way automate process, eventually allow broader variety time-varying effects (random walk AR processes). Depending arguments specified dynamic, either set low-rank GP smooth function using s() bs = 'gp' fixed value length scale parameter \\(\\rho\\), set Hilbert space approximate GP using gp() function c=5/4 \\(\\rho\\) estimated (see ?dynamic details). first example use s() option, mis-specify \\(\\rho\\) parameter , practice, never known. call dynamic() set following smooth: s(time, = temp, bs = \"gp\", m = c(-2, 8, 2), k = 40) Inspect model summary, shows dynamic() wrapper used construct low-rank Gaussian Process smooth function: model used spline gp basis, ’s smooths can visualised just like gam. Plot estimated time-varying coefficient -sample training period  can also plot estimates -sample --sample periods see Gaussian Process function produces sensible smooth forecasts. supply full dataset newdata argument plot_mvgam_smooth inspect posterior forecasts time-varying smooth function. Overlay true simulated function see model adequately estimated ’s dynamics training testing data partitions  can also use plot_predictions marginaleffects package visualise time-varying coefficient effect estimated different values \\(temperature\\):  results sensible forecasts observations well  syntax similar wish estimate parameters underlying Gaussian Process, time using Hilbert space approximation. simply omit rho argument dynamic make happen. set call similar gp(time, = 'temp', c = 5/4, k = 40). model summary now contains estimates marginal deviation length scale parameters underlying Gaussian Process function: Effects gp() terms can also plotted smooths:  plot plot_predictions() call show effect case similar estimated approximate GP smooth model :  Forecasts also similar:","code":"mod <- mvgam(out ~ dynamic(temp, rho = 8, stationary = TRUE, k = 40),              family = gaussian(),              data = data_train) summary(mod, include_betas = FALSE) ## GAM formula: ## out ~ s(time, by = temp, bs = \"gp\", m = c(-2, 8, 2), k = 40) ##  ## Family: ## gaussian ##  ## Link function: ## identity ##  ## Trend model: ## None ##  ## N series: ## 1  ##  ## N timepoints: ## 190  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## Observation error parameter estimates: ##              2.5%  50% 97.5% Rhat n_eff ## sigma_obs[1] 0.23 0.25  0.28    1  2222 ##  ## GAM coefficient (beta) estimates: ##             2.5% 50% 97.5% Rhat n_eff ## (Intercept)    4   4   4.1    1  2893 ##  ## Approximate significance of GAM observation smooths: ##              edf    F p-value     ## s(time):temp  14 55.2  <2e-16 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 12:00:36 PM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot(mod, type = 'smooths') plot_mvgam_smooth(mod, smooth = 1, newdata = data) abline(v = 190, lty = 'dashed', lwd = 2) lines(beta_temp, lwd = 2.5, col = 'white') lines(beta_temp, lwd = 2) range_round = function(x){   round(range(x, na.rm = TRUE), 2) } plot_predictions(mod,                   newdata = datagrid(time = unique,                                     temp = range_round),                  by = c('time', 'temp', 'temp'),                  type = 'link') plot(mod, type = 'forecast', newdata = data_test) ## Out of sample CRPS: ## [1] 1.280347 mod <- mvgam(out ~ dynamic(temp, k = 40),              family = gaussian(),              data = data_train) summary(mod, include_betas = FALSE) ## GAM formula: ## out ~ gp(time, by = temp, c = 5/4, k = 40, scale = TRUE) ##  ## Family: ## gaussian ##  ## Link function: ## identity ##  ## Trend model: ## None ##  ## N series: ## 1  ##  ## N timepoints: ## 190  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## Observation error parameter estimates: ##              2.5%  50% 97.5% Rhat n_eff ## sigma_obs[1] 0.24 0.26  0.29    1  2151 ##  ## GAM coefficient (beta) estimates: ##             2.5% 50% 97.5% Rhat n_eff ## (Intercept)    4   4   4.1    1  2989 ##  ## GAM gp term marginal deviation (alpha) and length scale (rho) estimates: ##                      2.5%   50% 97.5% Rhat n_eff ## alpha_gp(time):temp 0.640 0.890 1.400 1.01   745 ## rho_gp(time):temp   0.028 0.053 0.069 1.00   888 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 1 of 2000 iterations ended with a divergence (0.05%) ##  *Try running with larger adapt_delta to remove the divergences ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 12:01:17 PM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot_mvgam_smooth(mod, smooth = 1, newdata = data) abline(v = 190, lty = 'dashed', lwd = 2) lines(beta_temp, lwd = 2.5, col = 'white') lines(beta_temp, lwd = 2) plot_predictions(mod,                   newdata = datagrid(time = unique,                                     temp = range_round),                  by = c('time', 'temp', 'temp'),                  type = 'link') plot(mod, type = 'forecast', newdata = data_test) ## Out of sample CRPS: ## [1] 1.667521"},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"salmon-survival-example","dir":"Articles","previous_headings":"","what":"Salmon survival example","title":"Time-varying effects in mvgam","text":"use openly available data marine survival Chinook salmon illustrate time-varying effects can used improve ecological time series models. Scheuerell Williams (2005) used dynamic linear model examine relationship marine survival Chinook salmon index ocean upwelling strength along west coast USA. authors hypothesized stronger upwelling April create better growing conditions phytoplankton, translate zooplankton provide better foraging opportunities juvenile salmon entering ocean. data survival measured proportional variable 42 years (1964–2005) available MARSS package: First need prepare data modelling. variable CUI.apr standardized make easier sampler estimate underlying GP parameters time-varying effect. also need convert survival back proportion, current form logit-transformed (time series packages handle proportional data). usual, also need create time indicator series indicator working mvgam: Inspect data Plot features outcome variable, shows proportional variable particular restrictions want model:","code":"load(url('https://github.com/atsa-es/MARSS/raw/master/data/SalmonSurvCUI.rda')) dplyr::glimpse(SalmonSurvCUI) ## Rows: 42 ## Columns: 3 ## $ year    <int> 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 19… ## $ logit.s <dbl> -3.46, -3.32, -3.58, -3.03, -3.61, -3.35, -3.93, -4.19, -4.82,… ## $ CUI.apr <int> 57, 5, 43, 11, 47, -21, 25, -2, -1, 43, 2, 35, 0, 1, -1, 6, -7… SalmonSurvCUI %>%   # create a time variable   dplyr::mutate(time = dplyr::row_number()) %>%    # create a series variable   dplyr::mutate(series = as.factor('salmon')) %>%    # z-score the covariate CUI.apr   dplyr::mutate(CUI.apr = as.vector(scale(CUI.apr))) %>%    # convert logit-transformed survival back to proportional   dplyr::mutate(survival = plogis(logit.s)) -> model_data dplyr::glimpse(model_data) ## Rows: 42 ## Columns: 6 ## $ year     <int> 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1… ## $ logit.s  <dbl> -3.46, -3.32, -3.58, -3.03, -3.61, -3.35, -3.93, -4.19, -4.82… ## $ CUI.apr  <dbl> 2.37949804, 0.03330223, 1.74782994, 0.30401713, 1.92830654, -… ## $ time     <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18… ## $ series   <fct> salmon, salmon, salmon, salmon, salmon, salmon, salmon, salmo… ## $ survival <dbl> 0.030472033, 0.034891409, 0.027119717, 0.046088827, 0.0263393… plot_mvgam_series(data = model_data, y = 'survival')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"a-state-space-beta-regression","dir":"Articles","previous_headings":"Salmon survival example","what":"A State-Space Beta regression","title":"Time-varying effects in mvgam","text":"mvgam can easily handle data bounded 0 1 Beta observation model (using mgcv function betar(), see ?mgcv::betar details). First fit simple State-Space model uses Random Walk dynamic process model predictors Beta observation model: summary model shows good behaviour Hamiltonian Monte Carlo sampler provides useful summaries Beta observation model parameters: plot underlying dynamic component shows easily handled temporal evolution time series:  Posterior hindcasts also good automatically respect observational data bounding 0 1:","code":"mod0 <- mvgam(formula = survival ~ 1,              trend_model = 'RW',              family = betar(),              data = model_data) summary(mod0) ## GAM formula: ## survival ~ 1 ##  ## Family: ## beta ##  ## Link function: ## logit ##  ## Trend model: ## RW ##  ## N series: ## 1  ##  ## N timepoints: ## 42  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## Observation precision parameter estimates: ##        2.5% 50% 97.5% Rhat n_eff ## phi[1]  160 310   580 1.01   612 ##  ## GAM coefficient (beta) estimates: ##             2.5%  50% 97.5% Rhat n_eff ## (Intercept) -4.2 -3.4  -2.4 1.02   125 ##  ## Latent trend variance estimates: ##          2.5%  50% 97.5% Rhat n_eff ## sigma[1] 0.18 0.33  0.55 1.02   276 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhat looks reasonable for all parameters ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 12:02:00 PM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot(mod0, type = 'trend') plot(mod0, type = 'forecast')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"including-time-varying-upwelling-effects","dir":"Articles","previous_headings":"Salmon survival example","what":"Including time-varying upwelling effects","title":"Time-varying effects in mvgam","text":"Now can increase complexity model constructing fitting State-Space model time-varying effect coastal upwelling index addition autoregressive dynamics. use Beta observation model capture restrictions proportional observations, time include dynamic() effect CUI.apr latent process model. specify \\(\\rho\\) parameter, instead opting estimate using Hilbert space approximate GP: summary model now includes estimates time-varying GP parameters: estimates underlying dynamic process, hindcasts, haven’t changed much:   process error parameter \\(\\sigma\\) slightly smaller model first model:  process error need flexible second model? estimates dynamic process now informed partly time-varying effect upwelling, can visualise link scale using plot() trend_effects = TRUE:  outcome scale, range possible CUI.apr values, using plot_predictions():","code":"mod1 <- mvgam(formula = survival ~ 1,               trend_formula = ~ dynamic(CUI.apr, k = 25, scale = FALSE),               trend_model = 'RW',               family = betar(),               data = model_data) summary(mod1, include_betas = FALSE) ## GAM observation formula: ## survival ~ 1 ##  ## GAM process formula: ## ~dynamic(CUI.apr, k = 25, scale = FALSE) ##  ## Family: ## beta ##  ## Link function: ## logit ##  ## Trend model: ## RW ##  ## N process models: ## 1  ##  ## N series: ## 1  ##  ## N timepoints: ## 42  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1000; warmup = 500; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## Observation precision parameter estimates: ##        2.5% 50% 97.5% Rhat n_eff ## phi[1]  190 360   670    1   858 ##  ## GAM observation model coefficient (beta) estimates: ##             2.5%  50% 97.5% Rhat n_eff ## (Intercept) -4.1 -3.2  -2.2 1.07    64 ##  ## Process error parameter estimates: ##          2.5%  50% 97.5% Rhat n_eff ## sigma[1] 0.18 0.31  0.51 1.02   274 ##  ## GAM process model gp term marginal deviation (alpha) and length scale (rho) estimates: ##                                2.5%  50% 97.5% Rhat n_eff ## alpha_gp_time_byCUI_apr_trend 0.028 0.32   1.5 1.02   205 ## rho_gp_time_byCUI_apr_trend   1.400 6.50  40.0 1.02   236 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhats above 1.05 found for 30 parameters ##  *Diagnose further to investigate why the chains have not mixed ## 89 of 2000 iterations ended with a divergence (4.45%) ##  *Try running with larger adapt_delta to remove the divergences ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 12:02:47 PM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot(mod1, type = 'trend') plot(mod1, type = 'forecast') # Extract estimates of the process error 'sigma' for each model mod0_sigma <- as.data.frame(mod0, variable = 'sigma', regex = TRUE) %>%   dplyr::mutate(model = 'Mod0') mod1_sigma <- as.data.frame(mod1, variable = 'sigma', regex = TRUE) %>%   dplyr::mutate(model = 'Mod1') sigmas <- rbind(mod0_sigma, mod1_sigma)  # Plot using ggplot2 library(ggplot2) ggplot(sigmas, aes(y = `sigma[1]`, fill = model)) +   geom_density(alpha = 0.3, colour = NA) +   coord_flip() plot(mod1, type = 'smooth', trend_effects = TRUE) plot_predictions(mod1, newdata = datagrid(CUI.apr = range_round,                                           time = unique),                  by = c('time', 'CUI.apr', 'CUI.apr'))"},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"comparing-model-predictive-performances","dir":"Articles","previous_headings":"Salmon survival example","what":"Comparing model predictive performances","title":"Time-varying effects in mvgam","text":"key question fitting multiple time series models whether one provides better predictions . several options mvgam exploring quantitatively. First, can compare models based -sample approximate leave-one-cross-validation implemented popular loo package: second model larger Expected Log Predictive Density (ELPD), meaning slightly favoured simpler model include time-varying upwelling effect. However, two models certainly differ much. metric compares -sample performance, hoping use models produce reasonable forecasts. Luckily, mvgam also routines comparing models using approximate leave-future-cross-validation. refit models reduced training set (starting time point 30) produce approximate 1-step ahead forecasts. forecasts used estimate forecast ELPD expanding training set one time point time. use Pareto-smoothed importance sampling reweight posterior predictions, acting kind particle filter don’t need refit model often (can read process works Bürkner et al. 2020). model time-varying upwelling effect tends provides better 1-step ahead forecasts, higher total forecast ELPD can also plot ELPDs model contrast. , values less zero suggest time-varying predictor model (Mod1) gives better 1-step ahead forecasts:  useful exercise expand model think kinds predictors might impact measurement error, easily implemented observation formula mvgam. now, leave model -.","code":"loo_compare(mod0, mod1) ## Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.  ## Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. ##      elpd_diff se_diff ## mod1  0.0       0.0    ## mod0 -2.3       1.6 lfo_mod0 <- lfo_cv(mod0, min_t = 30) lfo_mod1 <- lfo_cv(mod1, min_t = 30) sum(lfo_mod0$elpds) ## [1] 34.73176 sum(lfo_mod1$elpds) ## [1] 36.05325 plot(x = 1:length(lfo_mod0$elpds) + 30,      y = lfo_mod0$elpds - lfo_mod1$elpds,      ylab = 'ELPDmod0 - ELPDmod1',      xlab = 'Evaluation time point',      pch = 16,      col = 'darkred',      bty = 'l') abline(h = 0, lty = 'dashed')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/time_varying_effects.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further reading","title":"Time-varying effects in mvgam","text":"following papers resources offer lot useful material dynamic linear models can applied / evaluated practice: Bürkner, PC, Gabry, J Vehtari, Approximate leave-future-cross-validation Bayesian time series models. Journal Statistical Computation Simulation. 90:14 (2020) 2499-2523. Herrero, Asier, et al. individual landscape back: time‐varying effects climate herbivory tree sapling growth distribution limits. Journal Ecology 104.2 (2016): 430-442. Holmes, Elizabeth E., Eric J. Ward, Wills Kellie. “MARSS: multivariate autoregressive state-space models analyzing time-series data.” R Journal. 4.1 (2012): 11. Scheuerell, Mark D., John G. Williams. Forecasting climate induced changes survival Snake River Spring/Summer Chinook Salmon (Oncorhynchus Tshawytscha) Fisheries Oceanography 14 (2005): 448–57.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html","id":"state-space-models","dir":"Articles","previous_headings":"","what":"State-Space Models","title":"State-Space models in mvgam","text":"State-Space models allow us separately make inferences underlying dynamic process model interested (.e. evolution time series collection time series) observation model (.e. way survey / measure underlying process). extremely useful ecology observations always imperfect / noisy measurements thing interested measuring. also helpful often know covariates impact ability measure accurately (.e. take accurate counts rodents thunderstorm happening) covariate impact underlying process (highly unlikely rodent abundance responds one storm, instead probably responds longer-term weather climate variation). State-Space model allows us model components single unified modelling framework. major advantage mvgam can include nonlinear effects random effects model components also capturing dynamic processes.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html","id":"lake-washington-plankton-data","dir":"Articles","previous_headings":"State-Space Models","what":"Lake Washington plankton data","title":"State-Space models in mvgam","text":"data use illustrate can fit State-Space models mvgam long-term monitoring study plankton counts (cells per mL) taken Lake Washington Washington, USA. data available part MARSS package can downloaded using following: work five different groups plankton: usual, preparing data correct format mvgam modelling takes little bit wrangling dplyr: Inspect data structure Note z-scored counts example make easier specify priors (though completely necessary; often better build model respects properties actual outcome variables)  always helpful check data NAs attempting models:  missing observations, isn’t issue modelling mvgam. useful property understand counts tend highly seasonal. plots z-scored counts z-scored temperature measurements lake month:    try capture seasonality process model, easy given flexibility GAMs. Next split data training testing splits: Now time fit models. requires bit thinking can best tackle seasonal variation likely dependence structure data. algae interacting part complex system within lake, certainly expect lagged cross-dependencies underling dynamics. capture seasonal variation, multivariate dynamic model forced try capture , lead poor convergence unstable results (feasibly capture cyclic dynamics complex multi-species Lotka-Volterra model, ordinary differential equation approaches beyond scope mvgam).","code":"load(url('https://github.com/atsa-es/MARSS/raw/master/data/lakeWAplankton.rda')) outcomes <- c('Greens', 'Bluegreens', 'Diatoms', 'Unicells', 'Other.algae') # loop across each plankton group to create the long datframe plankton_data <- do.call(rbind, lapply(outcomes, function(x){      # create a group-specific dataframe with counts labelled 'y'   # and the group name in the 'series' variable   data.frame(year = lakeWAplanktonTrans[, 'Year'],              month = lakeWAplanktonTrans[, 'Month'],              y = lakeWAplanktonTrans[, x],              series = x,              temp = lakeWAplanktonTrans[, 'Temp'])})) %>%      # change the 'series' label to a factor   dplyr::mutate(series = factor(series)) %>%      # filter to only include some years in the data   dplyr::filter(year >= 1965 & year < 1975) %>%   dplyr::arrange(year, month) %>%   dplyr::group_by(series) %>%      # z-score the counts so they are approximately standard normal   dplyr::mutate(y = as.vector(scale(y))) %>%      # add the time indicator   dplyr::mutate(time = dplyr::row_number()) %>%   dplyr::ungroup() head(plankton_data) ## # A tibble: 6 × 6 ##    year month       y series       temp  time ##   <dbl> <dbl>   <dbl> <fct>       <dbl> <int> ## 1  1965     1 -0.542  Greens      -1.23     1 ## 2  1965     1 -0.344  Bluegreens  -1.23     1 ## 3  1965     1 -0.0768 Diatoms     -1.23     1 ## 4  1965     1 -1.52   Unicells    -1.23     1 ## 5  1965     1 -0.491  Other.algae -1.23     1 ## 6  1965     2 NA      Greens      -1.32     2 dplyr::glimpse(plankton_data) ## Rows: 600 ## Columns: 6 ## $ year   <dbl> 1965, 1965, 1965, 1965, 1965, 1965, 1965, 1965, 1965, 1965, 196… ## $ month  <dbl> 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, … ## $ y      <dbl> -0.54241769, -0.34410776, -0.07684901, -1.52243490, -0.49055442… ## $ series <fct> Greens, Bluegreens, Diatoms, Unicells, Other.algae, Greens, Blu… ## $ temp   <dbl> -1.2306562, -1.2306562, -1.2306562, -1.2306562, -1.2306562, -1.… ## $ time   <int> 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, … plot_mvgam_series(data = plankton_data, series = 'all') image(is.na(t(plankton_data)), axes = F,       col = c('grey80', 'darkred')) axis(3, at = seq(0,1, len = NCOL(plankton_data)),       labels = colnames(plankton_data)) plankton_data %>%   dplyr::filter(series == 'Other.algae') %>%   ggplot(aes(x = time, y = temp)) +   geom_line(size = 1.1) +   geom_line(aes(y = y), col = 'white',             size = 1.3) +   geom_line(aes(y = y), col = 'darkred',             size = 1.1) +   ylab('z-score') +   xlab('Time') +   ggtitle('Temperature (black) vs Other algae (red)') ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. plankton_data %>%   dplyr::filter(series == 'Diatoms') %>%   ggplot(aes(x = time, y = temp)) +   geom_line(size = 1.1) +   geom_line(aes(y = y), col = 'white',             size = 1.3) +   geom_line(aes(y = y), col = 'darkred',             size = 1.1) +   ylab('z-score') +   xlab('Time') +   ggtitle('Temperature (black) vs Diatoms (red)') plankton_data %>%   dplyr::filter(series == 'Greens') %>%   ggplot(aes(x = time, y = temp)) +   geom_line(size = 1.1) +   geom_line(aes(y = y), col = 'white',             size = 1.3) +   geom_line(aes(y = y), col = 'darkred',             size = 1.1) +   ylab('z-score') +   xlab('Time') +   ggtitle('Temperature (black) vs Greens (red)') plankton_train <- plankton_data %>%   dplyr::filter(time <= 112) plankton_test <- plankton_data %>%   dplyr::filter(time > 112)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html","id":"capturing-seasonality","dir":"Articles","previous_headings":"State-Space Models","what":"Capturing seasonality","title":"State-Space models in mvgam","text":"First fit model include dynamic component, just see can reproduce seasonal variation observations. model introduces hierarchical multidimensional smooths, time series share “global” tensor product month temp variables, capturing expectation algal seasonality responds temperature variation. response depend year temperatures recorded (.e. response warm temperatures Spring different response warm temperatures Autumn). model also fits series-specific deviation smooths (.e. one tensor product per series) capture algal group’s seasonality differs overall “global” seasonality. Note include series-specific intercepts model series z-scored mean 0. “global” tensor product smooth function can quickly visualized:  plot, red indicates -average linear predictors white indicates -average. can plot deviation smooths algal group see vary “global” pattern:      multidimensional smooths done good job capturing seasonal variation observations:      basic model gives us confidence can capture seasonal variation observations. model captured remaining temporal dynamics, obvious inspect Dunn-Smyth residuals series:","code":"notrend_mod <- mvgam(y ~                         # tensor of temp and month to capture                        # \"global\" seasonality                        te(temp, month, k = c(4, 4)) +                                                # series-specific deviation tensor products                        te(temp, month, k = c(4, 4), by = series),                      family = gaussian(),                      data = plankton_train,                      newdata = plankton_test,                      trend_model = 'None') plot_mvgam_smooth(notrend_mod, smooth = 1) plot_mvgam_smooth(notrend_mod, smooth = 2) plot_mvgam_smooth(notrend_mod, smooth = 3) plot_mvgam_smooth(notrend_mod, smooth = 4) plot_mvgam_smooth(notrend_mod, smooth = 5) plot_mvgam_smooth(notrend_mod, smooth = 6) plot(notrend_mod, type = 'forecast', series = 1) ## Out of sample CRPS: ## [1] 6.781425 plot(notrend_mod, type = 'forecast', series = 2) ## Out of sample CRPS: ## [1] 6.720558 plot(notrend_mod, type = 'forecast', series = 3) ## Out of sample CRPS: ## [1] 4.060107 plot(notrend_mod, type = 'forecast', series = 4) ## Out of sample CRPS: ## [1] 3.600694 plot(notrend_mod, type = 'forecast', series = 5) ## Out of sample CRPS: ## [1] 2.865938 plot(notrend_mod, type = 'residuals', series = 1) plot(notrend_mod, type = 'residuals', series = 2) plot(notrend_mod, type = 'residuals', series = 3) plot(notrend_mod, type = 'residuals', series = 4) plot(notrend_mod, type = 'residuals', series = 5)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html","id":"multiseries-dynamics","dir":"Articles","previous_headings":"State-Space Models","what":"Multiseries dynamics","title":"State-Space models in mvgam","text":"Now time get multivariate State-Space models. fit two models can incorporate lagged cross-dependencies latent process models. first model assumes process errors operate independently one another, second assumes may contemporaneous correlations process errors. models include Vector Autoregressive component process means, can model complex community dynamics. models can described mathematically follows: \\[\\begin{align*} \\boldsymbol{count}_t & \\sim \\text{Normal}(\\mu_{obs[t]}, \\sigma_{obs}) \\\\ \\mu_{obs[t]} & = process_t \\\\ process_t & \\sim \\text{MVNormal}(\\mu_{process[t]}, \\Sigma_{process}) \\\\ \\mu_{process[t]} & = VAR * process_{t-1} + f_{global}(\\boldsymbol{month},\\boldsymbol{temp})_t + f_{series}(\\boldsymbol{month},\\boldsymbol{temp})_t \\\\ f_{global}(\\boldsymbol{month},\\boldsymbol{temp}) & = \\sum_{k=1}^{K}b_{global} * \\beta_{global} \\\\ f_{series}(\\boldsymbol{month},\\boldsymbol{temp}) & = \\sum_{k=1}^{K}b_{series} * \\beta_{series} \\end{align*}\\] can see terms observation model apart underlying process model. easily add covariates observation model felt explain systematic observation errors. also assume independent observation processes (covariance structure observation errors \\(\\sigma_{obs}\\)). present, mvgam support multivariate observation models. feature added future versions. However underlying process model multivariate, lot going . component Vector Autoregressive part, process mean time \\(t\\) \\((\\mu_{process[t]})\\) vector evolves function vector-valued process model time \\(t-1\\). \\(VAR\\) matrix captures dynamics self-dependencies diagonal possibly asymmetric cross-dependencies -diagonals, also incorporating nonlinear smooth functions capture seasonality series. contemporaneous process errors modeled \\(\\Sigma_{process}\\), can constrained process errors independent (.e. setting -diagonals 0) can fully parameterized using Cholesky decomposition (using Stan’s \\(LKJcorr\\) distribution place prior strength inter-species correlations). interested inner-workings, mvgam makes use recent breakthrough Sarah Heaps enforce stationarity Bayesian VAR processes. advantageous often don’t expect forecast variance increase without bound forever future, many estimated VARs tend behave way. Ok lot take . Let’s fit models try inspect going assume. first, need update mvgam’s default priors observation process errors. default, mvgam uses fairly wide Student-T prior parameters avoid overly informative. observations z-scored expect large process observation errors. However, also expect small observation errors either know measurements perfect. let’s update priors parameters. , get see formula latent process (.e. trend) model used mvgam: Get names parameters whose priors can modified: default prior distributions: Setting priors easy mvgam can use brms routines. use informative Normal priors error components, impose lower bound 0.2 observation errors: may noticed something else unique model: intercept term observation formula. shared intercept parameter can sometimes unidentifiable respect latent VAR process, particularly series similar long-run averages (case z-scored). often get better convergence State-Space models drop parameter. mvgam accomplishes fixing coefficient intercept zero. Now can fit first model, assumes process errors contemporaneously uncorrelated","code":"priors <- get_mvgam_priors(   # observation formula, which has no terms in it   y ~ -1,      # process model formula, which includes the smooth functions   trend_formula = ~ te(temp, month, k = c(4, 4)) +     te(temp, month, k = c(4, 4), by = trend),      # VAR1 model with uncorrelated process errors   trend_model = 'VAR1',   family = gaussian(),   data = plankton_train) priors[, 3] ##  [1] \"(Intercept)\"                                                                                                                                                                                                                                                            ##  [2] \"process error sd\"                                                                                                                                                                                                                                                       ##  [3] \"diagonal autocorrelation population mean\"                                                                                                                                                                                                                               ##  [4] \"off-diagonal autocorrelation population mean\"                                                                                                                                                                                                                           ##  [5] \"diagonal autocorrelation population variance\"                                                                                                                                                                                                                           ##  [6] \"off-diagonal autocorrelation population variance\"                                                                                                                                                                                                                       ##  [7] \"shape1 for diagonal autocorrelation precision\"                                                                                                                                                                                                                          ##  [8] \"shape1 for off-diagonal autocorrelation precision\"                                                                                                                                                                                                                      ##  [9] \"shape2 for diagonal autocorrelation precision\"                                                                                                                                                                                                                          ## [10] \"shape2 for off-diagonal autocorrelation precision\"                                                                                                                                                                                                                      ## [11] \"observation error sd\"                                                                                                                                                                                                                                                   ## [12] \"te(temp,month) smooth parameters, te(temp,month):trendtrend1 smooth parameters, te(temp,month):trendtrend2 smooth parameters, te(temp,month):trendtrend3 smooth parameters, te(temp,month):trendtrend4 smooth parameters, te(temp,month):trendtrend5 smooth parameters\" priors[, 4] ##  [1] \"(Intercept) ~ student_t(3, -0.1, 2.5);\" ##  [2] \"sigma ~ student_t(3, 0, 2.5);\"          ##  [3] \"es[1] = 0;\"                             ##  [4] \"es[2] = 0;\"                             ##  [5] \"fs[1] = sqrt(0.455);\"                   ##  [6] \"fs[2] = sqrt(0.455);\"                   ##  [7] \"gs[1] = 1.365;\"                         ##  [8] \"gs[2] = 1.365;\"                         ##  [9] \"hs[1] = 0.071175;\"                      ## [10] \"hs[2] = 0.071175;\"                      ## [11] \"sigma_obs ~ student_t(3, 0, 2.5);\"      ## [12] \"lambda_trend ~ normal(5, 30);\" priors <- c(prior(normal(0.5, 0.1), class = sigma_obs, lb = 0.2),             prior(normal(0.5, 0.25), class = sigma)) var_mod <- mvgam(     # observation formula, which is empty   y ~ -1,      # process model formula, which includes the smooth functions   trend_formula = ~ te(temp, month, k = c(4, 4)) +     te(temp, month, k = c(4, 4), by = trend),      # VAR1 model with uncorrelated process errors   trend_model = 'VAR1',   family = gaussian(),   data = plankton_train,   newdata = plankton_test,      # include the updated priors   priors = priors)"},{"path":"https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html","id":"inspecting-ss-models","dir":"Articles","previous_headings":"State-Space Models","what":"Inspecting SS models","title":"State-Space models in mvgam","text":"model’s summary bit different mvgam summaries. separates parameters based whether belong observation model latent process model. may often covariates impact observations latent process, can fairly complex models component. notice parameters fully converged, particularly VAR coefficients (called output) process errors (Sigma). Note set include_betas = FALSE stop summary printing output spline coefficients, can dense hard interpret: convergence model isn’t fabulous (moment). can plot smooth functions, time operate process model. can see plot using trend_effects = TRUE plotting functions:  VAR matrix particular interest , captures lagged dependencies cross-dependencies latent process model:  Unfortunately bayesplot doesn’t know matrix parameters see actually transpose VAR matrix. little bit wrangling gives us histograms correct order:  lot happening matrix. cell captures lagged effect process column process row next timestep. example, effect cell [1,3], quite strongly negative, means increase process series 3 (Greens) time \\(t\\) expected lead subsequent decrease process series 1 (Bluegreens) time \\(t+1\\). latent process model now capturing effects smooth seasonal effects, trend plot shows best estimate true count time point:   process error \\((\\Sigma)\\) captures unmodelled variation process models. , fixed -diagonals 0, histograms look like flat boxes:  observation error estimates \\((\\sigma_{obs})\\) represent much model thinks might miss true count take imperfect measurements:  still bit hard identify overall, especially trying estimate process observation error. Often need make strong assumptions important determining unexplained variation observations.","code":"summary(var_mod, include_betas = FALSE) ## GAM observation formula: ## y ~ 1 ##  ## GAM process formula: ## ~te(temp, month, k = c(4, 4)) + te(temp, month, k = c(4, 4),  ##     by = trend) ##  ## Family: ## gaussian ##  ## Link function: ## identity ##  ## Trend model: ## VAR1 ##  ## N process models: ## 5  ##  ## N series: ## 5  ##  ## N timepoints: ## 112  ##  ## Status: ## Fitted using Stan  ## 4 chains, each with iter = 1500; warmup = 1000; thin = 1  ## Total post-warmup draws = 2000 ##  ##  ## Observation error parameter estimates: ##              2.5%  50% 97.5% Rhat n_eff ## sigma_obs[1] 0.20 0.26  0.34 1.01   436 ## sigma_obs[2] 0.26 0.41  0.55 1.00   171 ## sigma_obs[3] 0.42 0.64  0.82 1.06    69 ## sigma_obs[4] 0.25 0.37  0.49 1.01   170 ## sigma_obs[5] 0.32 0.44  0.54 1.02   209 ##  ## GAM observation model coefficient (beta) estimates: ##             2.5% 50% 97.5% Rhat n_eff ## (Intercept)    0   0     0  NaN   NaN ##  ## Process model VAR parameter estimates: ##          2.5%    50% 97.5% Rhat n_eff ## A[1,1] -0.044  0.500 0.870 1.06    58 ## A[1,2] -0.380 -0.044 0.180 1.01   341 ## A[1,3] -0.560 -0.056 0.330 1.01   308 ## A[1,4] -0.260  0.039 0.420 1.00   560 ## A[1,5] -0.097  0.140 0.580 1.02   115 ## A[2,1] -0.140  0.020 0.250 1.01   504 ## A[2,2]  0.610  0.780 0.910 1.00   258 ## A[2,3] -0.450 -0.150 0.045 1.00   249 ## A[2,4] -0.039  0.120 0.350 1.00   231 ## A[2,5] -0.060  0.064 0.220 1.00   639 ## A[3,1] -0.280  0.026 0.630 1.07    50 ## A[3,2] -0.540 -0.210 0.024 1.00   133 ## A[3,3]  0.060  0.410 0.740 1.01   205 ## A[3,4] -0.031  0.240 0.650 1.00   145 ## A[3,5] -0.070  0.130 0.410 1.02   163 ## A[4,1] -0.120  0.061 0.420 1.03   108 ## A[4,2] -0.120  0.041 0.240 1.02   298 ## A[4,3] -0.490 -0.140 0.110 1.01   216 ## A[4,4]  0.500  0.760 0.970 1.03   207 ## A[4,5] -0.200 -0.034 0.130 1.01   397 ## A[5,1] -0.180  0.078 0.810 1.07    50 ## A[5,2] -0.480 -0.140 0.069 1.01   120 ## A[5,3] -0.720 -0.220 0.100 1.01   136 ## A[5,4] -0.054  0.200 0.670 1.01   141 ## A[5,5]  0.510  0.750 0.960 1.01   300 ##  ## Process error parameter estimates: ##             2.5%  50% 97.5% Rhat n_eff ## Sigma[1,1] 0.042 0.27  0.65 1.08    51 ## Sigma[1,2] 0.000 0.00  0.00  NaN   NaN ## Sigma[1,3] 0.000 0.00  0.00  NaN   NaN ## Sigma[1,4] 0.000 0.00  0.00  NaN   NaN ## Sigma[1,5] 0.000 0.00  0.00  NaN   NaN ## Sigma[2,1] 0.000 0.00  0.00  NaN   NaN ## Sigma[2,2] 0.066 0.11  0.18 1.02   266 ## Sigma[2,3] 0.000 0.00  0.00  NaN   NaN ## Sigma[2,4] 0.000 0.00  0.00  NaN   NaN ## Sigma[2,5] 0.000 0.00  0.00  NaN   NaN ## Sigma[3,1] 0.000 0.00  0.00  NaN   NaN ## Sigma[3,2] 0.000 0.00  0.00  NaN   NaN ## Sigma[3,3] 0.044 0.14  0.28 1.00   124 ## Sigma[3,4] 0.000 0.00  0.00  NaN   NaN ## Sigma[3,5] 0.000 0.00  0.00  NaN   NaN ## Sigma[4,1] 0.000 0.00  0.00  NaN   NaN ## Sigma[4,2] 0.000 0.00  0.00  NaN   NaN ## Sigma[4,3] 0.000 0.00  0.00  NaN   NaN ## Sigma[4,4] 0.047 0.12  0.25 1.02   131 ## Sigma[4,5] 0.000 0.00  0.00  NaN   NaN ## Sigma[5,1] 0.000 0.00  0.00  NaN   NaN ## Sigma[5,2] 0.000 0.00  0.00  NaN   NaN ## Sigma[5,3] 0.000 0.00  0.00  NaN   NaN ## Sigma[5,4] 0.000 0.00  0.00  NaN   NaN ## Sigma[5,5] 0.100 0.20  0.35 1.01   161 ##  ## Approximate significance of GAM process smooths: ##                              edf    F p-value   ## te(temp,month)              4.28 0.45   0.122   ## te(temp,month):seriestrend1 2.02 0.02   1.000   ## te(temp,month):seriestrend2 1.97 0.08   0.985   ## te(temp,month):seriestrend3 4.31 1.61   0.021 * ## te(temp,month):seriestrend4 1.47 0.25   0.753   ## te(temp,month):seriestrend5 2.96 0.08   0.977   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Stan MCMC diagnostics: ## n_eff / iter looks reasonable for all parameters ## Rhats above 1.05 found for 10 parameters ##  *Diagnose further to investigate why the chains have not mixed ## 0 of 2000 iterations ended with a divergence (0%) ## 0 of 2000 iterations saturated the maximum tree depth of 12 (0%) ## E-FMI indicated no pathological behavior ##  ## Samples were drawn using NUTS(diag_e) at Fri Jan 19 12:19:14 PM 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split MCMC chains ## (at convergence, Rhat = 1) plot(var_mod, 'smooths', trend_effects = TRUE) mcmc_plot(var_mod, variable = 'A', regex = TRUE, type = 'hist') A_pars <- matrix(NA, nrow = 5, ncol = 5) for(i in 1:5){   for(j in 1:5){     A_pars[i, j] <- paste0('A[', i, ',', j, ']')   } } mcmc_plot(var_mod,            variable = as.vector(t(A_pars)),            type = 'hist') plot(var_mod, type = 'trend', series = 1) plot(var_mod, type = 'trend', series = 3) Sigma_pars <- matrix(NA, nrow = 5, ncol = 5) for(i in 1:5){   for(j in 1:5){     Sigma_pars[i, j] <- paste0('Sigma[', i, ',', j, ']')   } } mcmc_plot(var_mod,            variable = as.vector(t(Sigma_pars)),            type = 'hist') mcmc_plot(var_mod, variable = 'sigma_obs', regex = TRUE, type = 'hist')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html","id":"correlated-process-errors","dir":"Articles","previous_headings":"State-Space Models","what":"Correlated process errors","title":"State-Space models in mvgam","text":"Let’s see estimates improve allow process errors correlated. , need first update priors observation errors: now can fit correlated process error model Plot convergence diagnostics two models, shows models display similar levels convergence:   \\((\\Sigma)\\) matrix now captures evidence contemporaneously correlated process error:  symmetric matrix tells us support correlated process errors. example, series 1 3 (Bluegreens Greens) show negatively correlated process errors, series 1 4 (Bluegreens .algae) show positively correlated errors. easier interpret estimates convert covariance matrix correlation matrix. compute posterior median process error correlations: model able capture correlated errors, VAR matrix changed slightly:  still evidence lagged cross-dependence, interactions now pulled toward zero. model better? Forecasts don’t appear differ much, least qualitatively (forecasts three series, model):       can compute variogram score sample forecasts get sense model better job capturing dependence structure true evaluation set:  can also compute energy score sample forecasts get sense model provides forecasts better calibrated:  models tend provide similar forecasts, though correlated error model slightly better overall. probably need use extensive rolling forecast evaluation exercise felt like needed choose one production. mvgam offers utilities (.e. see ?lfo_cv guidance).","code":"priors <- c(prior(normal(0.5, 0.1), class = sigma_obs, lb = 0.2),             prior(normal(0.5, 0.25), class = sigma)) varcor_mod <- mvgam(     # observation formula, which remains empty   y ~ -1,      # process model formula, which includes the smooth functions   trend_formula = ~ te(temp, month, k = c(4, 4)) +     te(temp, month, k = c(4, 4), by = trend),      # VAR1 model with correlated process errors   trend_model = 'VAR1cor',   family = gaussian(),   data = plankton_train,   newdata = plankton_test,      # include the updated priors   priors = priors) mcmc_plot(varcor_mod, type = 'rhat') +   labs(title = 'VAR1cor') mcmc_plot(var_mod, type = 'rhat') +   labs(title = 'VAR1') Sigma_pars <- matrix(NA, nrow = 5, ncol = 5) for(i in 1:5){   for(j in 1:5){     Sigma_pars[i, j] <- paste0('Sigma[', i, ',', j, ']')   } } mcmc_plot(varcor_mod,            variable = as.vector(t(Sigma_pars)),            type = 'hist') Sigma_post <- as.matrix(varcor_mod, variable = 'Sigma', regex = TRUE) median_correlations <- cov2cor(matrix(apply(Sigma_post, 2, median),                                       nrow = 5, ncol = 5)) rownames(median_correlations) <- colnames(median_correlations) <- levels(plankton_train$series)  round(median_correlations, 2) ##             Bluegreens Diatoms Greens Other.algae Unicells ## Bluegreens        1.00   -0.05   0.17       -0.07     0.29 ## Diatoms          -0.05    1.00  -0.21        0.49     0.17 ## Greens            0.17   -0.21   1.00        0.18     0.46 ## Other.algae      -0.07    0.49   0.18        1.00     0.27 ## Unicells          0.29    0.17   0.46        0.27     1.00 A_pars <- matrix(NA, nrow = 5, ncol = 5) for(i in 1:5){   for(j in 1:5){     A_pars[i, j] <- paste0('A[', i, ',', j, ']')   } } mcmc_plot(varcor_mod,            variable = as.vector(t(A_pars)),            type = 'hist') plot(var_mod, type = 'forecast', series = 1, newdata = plankton_test) ## Out of sample CRPS: ## [1] 3.001476 plot(varcor_mod, type = 'forecast', series = 1, newdata = plankton_test) ## Out of sample CRPS: ## [1] 2.97764 plot(var_mod, type = 'forecast', series = 2, newdata = plankton_test) ## Out of sample CRPS: ## [1] 5.978774 plot(varcor_mod, type = 'forecast', series = 2, newdata = plankton_test) ## Out of sample CRPS: ## [1] 5.534348 plot(var_mod, type = 'forecast', series = 3, newdata = plankton_test) ## Out of sample CRPS: ## [1] 4.052797 plot(varcor_mod, type = 'forecast', series = 3, newdata = plankton_test) ## Out of sample CRPS: ## [1] 4.041621 # create forecast objects for each model fcvar <- forecast(var_mod) fcvarcor <- forecast(varcor_mod)  # plot the difference in variogram scores; a negative value means the VAR1cor model is better, while a positive value means the VAR1 model is better diff_scores <- score(fcvarcor, score = 'variogram')$all_series$score -   score(fcvar, score = 'variogram')$all_series$score plot(diff_scores, pch = 16, cex = 1.25, col = 'darkred',       ylim = c(-1*max(abs(diff_scores), na.rm = TRUE),               max(abs(diff_scores), na.rm = TRUE)),      bty = 'l',      xlab = 'Forecast horizon',      ylab = expression(variogram[VAR1cor]~-~variogram[VAR1])) abline(h = 0, lty = 'dashed') # plot the difference in energy scores; a negative value means the VAR1cor model is better, while a positive value means the VAR1 model is better diff_scores <- score(fcvarcor, score = 'energy')$all_series$score -   score(fcvar, score = 'energy')$all_series$score plot(diff_scores, pch = 16, cex = 1.25, col = 'darkred',       ylim = c(-1*max(abs(diff_scores), na.rm = TRUE),               max(abs(diff_scores), na.rm = TRUE)),      bty = 'l',      xlab = 'Forecast horizon',      ylab = expression(energy[VAR1cor]~-~energy[VAR1])) abline(h = 0, lty = 'dashed')"},{"path":"https://nicholasjclark.github.io/mvgam/articles/trend_formulas.html","id":"further-reading","dir":"Articles","previous_headings":"State-Space Models","what":"Further reading","title":"State-Space models in mvgam","text":"following papers resources offer lot useful material multivariate State-Space models can applied practice: Heaps, Sarah E. “Enforcing stationarity prior vector autoregressions.” Journal Computational Graphical Statistics 32.1 (2023): 74-83. Hannaford, Naomi E., et al. “sparse Bayesian hierarchical vector autoregressive model microbial dynamics wastewater treatment plant.” Computational Statistics & Data Analysis 179 (2023): 107659. Holmes, Elizabeth E., Eric J. Ward, Wills Kellie. “MARSS: multivariate autoregressive state-space models analyzing time-series data.” R Journal. 4.1 (2012): 11. Ward, Eric J., et al. “Inferring spatial structure time‐series data: using multivariate state‐space models detect metapopulation structure California sea lions Gulf California, Mexico.” Journal Applied Ecology 47.1 (2010): 47-56. Auger‐Méthé, Marie, et al. “guide state–space modeling ecological time series.” Ecological Monographs 91.4 (2021): e01470.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nicholas J Clark. Author, maintainer.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Nicholas J. Clark, Konstans Wells (2022). Dynamic Generalized Additive Models (DGAMs) forecasting discrete ecological time series Methods Ecology Evolution DOI: https://doi.org/10.1111/2041-210X.13974","code":"@Article{,   title = {Dynamic Generalized Additive Models (DGAMs) for forecasting discrete ecological time series},   author = {Nicholas J. Clark and Konstans Wells},   journal = {Methods in Ecology and Evolution},   year = {2022},   url = {https://doi.org/10.1111/2041-210X.13974}, }"},{"path":"https://nicholasjclark.github.io/mvgam/index.html","id":"mvgam","dir":"","previous_headings":"","what":"mvgam","title":"Multivariate (Dynamic) Generalized Additive Models","text":"MultiVariate (Dynamic) Generalized Addivite Models goal mvgam use Bayesian framework estimate parameters Dynamic Generalized Additive Models (DGAMs) time series dynamic trend components. package provides interface fit Bayesian DGAMs using either JAGS Stan backend, note users strongly encouraged opt Stan JAGS. formula syntax based package mgcv provide familiar GAM modelling interface. motivation package primary objectives described detail Clark & Wells 2022 (published Methods Ecology Evolution). introduction package worked examples also shown seminar: Ecological Forecasting Dynamic Generalized Additive Models.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Multivariate (Dynamic) Generalized Additive Models","text":"Install development version GitHub using: devtools::install_github(\"nicholasjclark/mvgam\"). Note actually condition models MCMC sampling, either JAGS software must installed (along R packages rjags runjags) Stan software must installed (along either rstan /cmdstanr). rstan listed dependency mvgam ensure installation less difficult. users wish fit models using mvgam, please refer installation links JAGS , Stan rstan , Stan cmdstandr . need fairly recent version Stan ensure model syntax recognized. see warnings variable \"array\" exist, usually sign need update version Stan. highly recommend use Cmdstan cmdstanr interface backend. Cmdstan easier install, date new features, uses less memory Rstan. See documentation Cmdstan team information.","code":""},{"path":[]},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Multivariate (Dynamic) Generalized Additive Models","text":"mvgam originally designed analyse forecast non-negative integer-valued data (counts). data traditionally challenging analyse existing time-series analysis packages. development mvgam resulted support growing number observation families extend types data. Currently, package can handle data following families: gaussian() real-valued data student_t() heavy-tailed real-valued data lognormal() non-negative real-valued data Gamma() non-negative real-valued data betar() proportional data (0,1) poisson() count data nb() overdispersed count data nmix() count data imperfect detection tweedie() overdispersed count data Note poisson(), nb(), tweedie() available using JAGS. families, apart tweedie(), supported using Stan. See ??mvgam_families information. simple example simulating modelling proportional data Beta observations set seasonal series independent Gaussian Process dynamic trends: Plot series see evolve time  Fit DGAM series uses hierarchical cyclic seasonal smooth term capture variation seasonality among series. model also includes series-specific latent Gaussian Processes squared exponential covariance functions capture temporal dynamics Plot estimated posterior hindcast forecast distributions series  Various S3 functions can used inspect parameter estimates, plot smooth functions residuals, evaluate models posterior predictive checks forecast comparisons. Please see package documentation detailed examples.","code":"data <- sim_mvgam(family = betar(),                  T = 80,                  trend_model = 'GP',                  trend_rel = 0.5,                   seasonality = 'shared') plot_mvgam_series(data = data$data_train, series = 'all') mod <- mvgam(y ~ s(season, bs = 'cc', k = 7) +                s(season, by = series, m = 1, k = 5),              trend_model = 'GP',              data = data$data_train,              newdata = data$data_test,              family = betar()) layout(matrix(1:4, nrow = 2, byrow = TRUE)) for(i in 1:3){   plot(mod, type = 'forecast', series = i) }"},{"path":"https://nicholasjclark.github.io/mvgam/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Multivariate (Dynamic) Generalized Additive Models","text":"can set build_vignettes = TRUE installing either devtools::install_github remotes::install_github, aware slow installation drastically. Instead, can always access vignette htmls online https://nicholasjclark.github.io/mvgam/articles/","code":""},{"path":"https://nicholasjclark.github.io/mvgam/index.html","id":"other-resources","dir":"","previous_headings":"","what":"Other resources","title":"Multivariate (Dynamic) Generalized Additive Models","text":"number case studies compiled highlight DGAMs can estimated using MCMC sampling: Ecological Forecasting Dynamic Generalized Additive Models mvgam case study 1: model comparison data assimilation mvgam case study 2: multivariate models mvgam case study 3: distributed lag models package can also used generate necessary data structures, initial value functions modelling code necessary fit DGAMs using Stan JAGS. can helpful users wish make changes model better suit bespoke research / analysis goals. following resources can helpful troubleshoot: Stan Discourse JAGS Discourse","code":""},{"path":"https://nicholasjclark.github.io/mvgam/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 Nicholas Clark Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/add_tweedie_lines.html","id":null,"dir":"Reference","previous_headings":"","what":"Tweedie JAGS modifications — add_tweedie_lines","title":"Tweedie JAGS modifications — add_tweedie_lines","text":"Tweedie JAGS modifications","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/add_tweedie_lines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tweedie JAGS modifications — add_tweedie_lines","text":"","code":"add_tweedie_lines(model_file, upper_bounds)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/add_tweedie_lines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tweedie JAGS modifications — add_tweedie_lines","text":"model_file template JAGS model file modified upper_bounds Optional upper bounds truncated observation likelihood","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/add_tweedie_lines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tweedie JAGS modifications — add_tweedie_lines","text":"modified JAGS model file","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/all_neon_tick_data.html","id":null,"dir":"Reference","previous_headings":"","what":"NEON Amblyomma and Ixodes tick abundance survey data — all_neon_tick_data","title":"NEON Amblyomma and Ixodes tick abundance survey data — all_neon_tick_data","text":"dataset containing timeseries Amblyomma americanum Ixodes scapularis nymph abundances NEON sites","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/all_neon_tick_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NEON Amblyomma and Ixodes tick abundance survey data — all_neon_tick_data","text":"","code":"all_neon_tick_data"},{"path":"https://nicholasjclark.github.io/mvgam/reference/all_neon_tick_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NEON Amblyomma and Ixodes tick abundance survey data — all_neon_tick_data","text":"tibble/dataframe containing covariate information alongside main fields : Year Year sampling epiWeek Epidemiological week sampling plot_ID NEON plot ID survey location siteID NEON site ID survey location amblyomma_americanum Counts . americanum nymphs ixodes_scapularis Counts . scapularis nymphs","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/all_neon_tick_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NEON Amblyomma and Ixodes tick abundance survey data — all_neon_tick_data","text":"https://www.neonscience.org/data","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/code.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the model code from an mvgam object — code","title":"Print the model code from an mvgam object — code","text":"Print model code mvgam object","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print the model code from an mvgam object — code","text":"","code":"code(object)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the model code from an mvgam object — code","text":"object list object returned mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print the model code from an mvgam object — code","text":"character string containing model code tidy format","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/conditional_effects.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Display Conditional Effects of Predictors — conditional_effects.mvgam","title":"Display Conditional Effects of Predictors — conditional_effects.mvgam","text":"Display conditional effects one numeric /categorical predictors mvgam models, including two-way interaction effects.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/conditional_effects.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display Conditional Effects of Predictors — conditional_effects.mvgam","text":"","code":"# S3 method for mvgam conditional_effects(   x,   effects = NULL,   type = \"response\",   points = TRUE,   rug = TRUE,   ... )  # S3 method for mvgam_conditional_effects plot(x, plot = TRUE, ask = FALSE, ...)  # S3 method for mvgam_conditional_effects print(x, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/conditional_effects.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display Conditional Effects of Predictors — conditional_effects.mvgam","text":"x Object class mvgam mvgam_conditional_effects effects optional character vector naming effects (main effects interactions) compute conditional plots. Interactions specified : variable names. NULL (default), plots generated main effects two-way interactions estimated model. specifying effects manually, two-way interactions (including grouping variables) may plotted even originally modeled. type character specifying scale predictions. value link (default) linear predictor calculated link scale. expected used, predictions reflect expectation response (mean) ignore uncertainty observation process. response used, predictions take uncertainty observation process account return predictions outcome scale. Two special cases also allowed: type latent_N return estimated latent abundances N-mixture distribution, type detection return estimated detection probability N-mixture distribution points Logical. Indicates original data points added, type == 'response'. Default TRUE. rug Logical. Indicates displays tick marks plotted axes mark distribution raw data, type == 'response'. Default TRUE. ... arguments pass plot_predictions plot Logical; indicates plots plotted directly active graphic device. Defaults TRUE. ask Logical. Indicates user prompted new page plotted. used plot TRUE. Default FALSE.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/conditional_effects.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display Conditional Effects of Predictors — conditional_effects.mvgam","text":"conditional_effects returns object class mvgam_conditional_effects named list one slot per effect containing ggplot object, can customized using ggplot2 package. corresponding plot method draw plots active graphic device","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/conditional_effects.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display Conditional Effects of Predictors — conditional_effects.mvgam","text":"function acts wrapper flexible plot_predictions. creating conditional_effects particular predictor (interaction two predictors), one choose values predictors condition . default, mean used continuous variables reference category used factors. Use plot_predictions change create bespoke conditional effects plots.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/conditional_effects.mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Display Conditional Effects of Predictors — conditional_effects.mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/conditional_effects.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display Conditional Effects of Predictors — conditional_effects.mvgam","text":"","code":"if (FALSE) { # Simulate some data simdat <- sim_mvgam(family = poisson(),                     seasonality = 'hierarchical')  # Fit a model mod <- mvgam(y ~ s(season, by = series) + year:series,              family = poisson(),              data = simdat$data_train)  # Plot all main effects on the response scale plot(conditional_effects(mod), ask = FALSE)  # Change the prediction interval to 70% using plot_predictions() argument # 'conf_level' plot(conditional_effects(mod, conf_level = 0.7), ask = FALSE)  # Plot all main effects on the link scale plot(conditional_effects(mod, type = 'link'), ask = FALSE)  # Works the same for smooth terms set.seed(0) dat <- mgcv::gamSim(1, n = 200, scale = 2) dat$time <- 1:NROW(dat) mod <- mvgam(y ~ s(x0) + s(x1) + s(x2) + s(x3),             data = dat,             family = gaussian()) conditional_effects(mod) conditional_effects(mod, conf_level = 0.5, type = 'link') }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/dynamic.html","id":null,"dir":"Reference","previous_headings":"","what":"Defining dynamic coefficients in mvgam formulae — dynamic","title":"Defining dynamic coefficients in mvgam formulae — dynamic","text":"Set time-varying (dynamic) coefficients use mvgam models. Currently, low-rank Gaussian Process smooths available estimating dynamics time-varying coefficient.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/dynamic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Defining dynamic coefficients in mvgam formulae — dynamic","text":"","code":"dynamic(variable, k, rho = 5, stationary = TRUE, scale = TRUE)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/dynamic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Defining dynamic coefficients in mvgam formulae — dynamic","text":"variable variable dynamic smooth function k Optional number basis functions computing approximate GPs. missing, k set large possible accurately estimate nonlinear function rho Either positive numeric stating length scale used approximating squared exponential Gaussian Process smooth (see gp.smooth details) missing, case length scale estimated setting Hilbert space approximate GP stationary Logical. TRUE (default) rho supplied, latent Gaussian Process smooth linear trend component. FALSE, linear trend covariate added Gaussian Process smooth. Leave TRUE believe coefficient evolving much trend, linear component basis functions can hard penalize zero. sometimes causes divergence issues Stan. See gp.smooth details. Ignored rho missing (case Hilbert space approximate GP used) scale Logical; TRUE (default) rho missing, predictors scaled maximum Euclidean distance two points 1. often improves sampling speed convergence. Scaling also affects estimated length-scale parameters resemble scaled predictors (original predictors) scale TRUE.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/dynamic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Defining dynamic coefficients in mvgam formulae — dynamic","text":"mvgam currently sets dynamic coefficients low-rank squared exponential Gaussian Process smooths via call s(time, = variable, bs = \"gp\", m = c(2, rho, 2)). smooths, specified reasonable values length scale parameter, give realistic sample forecasts standard splines thin plate cubic. user must set value rho, currently support estimating value mgcv. may big problem, estimating latent length scales often difficult anyway. rho parameter thought prior smoothness latent dynamic coefficient function (higher values rho lead smoother functions temporal covariance structure. Values k set automatically ensure enough basis functions used approximate expected wiggliness underlying dynamic function (k increase rho decreases)","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/dynamic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Defining dynamic coefficients in mvgam formulae — dynamic","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/dynamic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Defining dynamic coefficients in mvgam formulae — dynamic","text":"","code":"if (FALSE) { # Simulate a time-varying coefficient \\ #(as a Gaussian Process with length scale = 10) set.seed(1111) N <- 200 beta <- mvgam:::sim_gp(rnorm(1),                       alpha_gp = 0.75,                       rho_gp = 10,                       h = N) + 0.5 plot(beta, type = 'l', lwd = 3,     bty = 'l', xlab = 'Time',     ylab = 'Coefficient',     col = 'darkred')  # Simulate the predictor as a standard normal predictor <- rnorm(N, sd = 1)  # Simulate a Gaussian outcome variable out <- rnorm(N, mean = 4 + beta * predictor,             sd = 0.25) time <- seq_along(predictor) plot(out,  type = 'l', lwd = 3,     bty = 'l', xlab = 'Time', ylab = 'Outcome',     col = 'darkred')  # Gather into a data.frame and fit a dynamic coefficient mmodel data <- data.frame(out, predictor, time)  # Split into training and testing data_train <- data[1:190,] data_test <- data[191:200,]  # Fit a model using the dynamic function mod <- mvgam(out ~             # mis-specify the length scale slightly as this             # won't be known in practice             dynamic(predictor, rho = 8, stationary = TRUE),            family = gaussian(),            data = data_train)  # Inspect the summary summary(mod)  # Plot the time-varying coefficient estimates plot(mod, type = 'smooths')  # Extrapolate the coefficient forward in time plot_mvgam_smooth(mod, smooth = 1, newdata = data) abline(v = 190, lty = 'dashed', lwd = 2)  # Overlay the true simulated time-varying coefficient lines(beta, lwd = 2.5, col = 'white') lines(beta, lwd = 2) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/evaluate_mvgams.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate forecasts from fitted mvgam objects — evaluate_mvgams","title":"Evaluate forecasts from fitted mvgam objects — evaluate_mvgams","text":"Evaluate forecasts fitted mvgam objects","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/evaluate_mvgams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate forecasts from fitted mvgam objects — evaluate_mvgams","text":"","code":"eval_mvgam(   object,   n_samples = 5000,   eval_timepoint = 3,   fc_horizon = 3,   n_cores = 2,   score = \"drps\",   log = FALSE,   weights )  roll_eval_mvgam(   object,   n_evaluations = 5,   evaluation_seq,   n_samples = 5000,   fc_horizon = 3,   n_cores = 2,   score = \"drps\",   log = FALSE,   weights )  compare_mvgams(   model1,   model2,   n_samples = 1000,   fc_horizon = 3,   n_evaluations = 10,   n_cores = 2,   score = \"drps\",   log = FALSE,   weights )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/evaluate_mvgams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate forecasts from fitted mvgam objects — evaluate_mvgams","text":"object list object returned mvgam n_samples integer specifying number samples generate model's posterior distribution eval_timepoint integer indexing timepoint represents last 'observed' set outcome data fc_horizon integer specifying length forecast horizon evaluating forecasts n_cores integer specifying number cores generating particle forecasts parallel score character specifying type ranked probability score use evaluation. Options : variogram, drps crps log logical. forecasts truths logged prior scoring? often appropriate comparing performance models series vary observation ranges weights optional vector weights (length(weights) == n_series) weighting pairwise correlations evaluating variogram score multivariate forecasts. Useful -weighting series larger magnitude observations less interest forecasting. Ignored score != 'variogram' n_evaluations integer specifying total number evaluations perform evaluation_seq Optional integer sequence specifying exact set timepoints evaluating model's forecasts. sequence values <3 > max(training timepoints) - fc_horizon model1 list object returned mvgam representing first model evaluated model2 list object returned mvgam representing second model evaluated","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/evaluate_mvgams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate forecasts from fitted mvgam objects — evaluate_mvgams","text":"eval_mvgam, list object containing information specific evaluations series (using drps crps score) vector scores using variogram. roll_eval_mvgam, list object containing information specific evaluations series well total evaluation summary (taken summing forecast score series evaluation averaging coverages evaluation) compare_mvgams, series plots comparing forecast Rank Probability Scores competing model. lower score preferred. Note however possible select model ultimately perform poorly true --sample forecasting. example wiggly smooth function 'year' included model function learned prior evaluating rolling window forecasts, model generate tight predictions result. forecasting ahead timepoints model seen (.e. next year), smooth function end extrapolating, sometimes strange unexpected ways. therefore recommended use smooth functions covariates adequately measured data (.e. 'seasonality', example) reduce possible extrapolation smooths let latent trends mvgam model capture temporal dependencies data. trends time series models provide much stable forecasts","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/evaluate_mvgams.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate forecasts from fitted mvgam objects — evaluate_mvgams","text":"eval_mvgam generates set samples representing fixed parameters estimated full mvgam model latent trend states given point time. trends rolled forward total fc_horizon timesteps according estimated state space dynamics generate '--sample' forecast evaluated true observations horizon window. function therefore simulates situation model's parameters already estimated observed data evaluation timepoint like generate forecasts latent trends observed timepoint. Evaluation involves calculating appropriate Rank Probability Score binary indicator whether true value lies within forecast's 90% prediction interval roll_eval_mvgam sets sequence evaluation timepoints along rolling window iteratively calls eval_mvgam evaluate '--sample' forecasts. Evaluation involves calculating Discrete Rank Probability Score binary indicator whether true value lies within forecast's 90% prediction interval compare_mvgams automates evaluation compare two fitted models using rolling window forecast evaluation provides series summary plots facilitate model selection. essentially wrapper roll_eval_mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/evaluate_mvgams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate forecasts from fitted mvgam objects — evaluate_mvgams","text":"","code":"if (FALSE) { # Simulate from a Poisson-AR2 model with a seasonal smooth set.seed(100) dat <- sim_mvgam(T = 75,                 n_series = 1,                 prop_trend = 0.75,                  trend_model = 'AR2',                  family = poisson())  # Plot the time series plot_mvgam_series(data = dat$data_train,                  newdata = dat$data_test,                  series = 1)  # Fit an appropriate model mod_ar2 <- mvgam(y ~ s(season, bs = 'cc'),                trend_model = 'AR2',                family = poisson(),                data = dat$data_train,                newdata = dat$data_test)  # Fit a less appropriate model mod_rw <- mvgam(y ~ s(season, bs = 'cc'),               trend_model = 'RW',               family = poisson(),               data = dat$data_train,               newdata = dat$data_test)  # Compare Discrete Ranked Probability Scores for the testing period fc_ar2 <- forecast(mod_ar2) fc_rw <- forecast(mod_rw) score_ar2 <- score(fc_ar2, score = 'drps') score_rw <- score(fc_rw, score = 'drps') sum(score_ar2$series_1$score) sum(score_rw$series_1$score)  # Use rolling evaluation for approximate comparisons of 3-step ahead # forecasts across the training period compare_mvgams(mod_ar2,               mod_rw,               fc_horizon = 3,               n_samples = 1000,               n_evaluations = 5)  # Now use approximate leave-future-out CV to compare # rolling forecasts; start at time point 40 to reduce # computational time and to ensure enough data is available # for estimating model parameters lfo_ar2 <- lfo_cv(mod_ar2,                  min_t = 40,                  fc_horizon = 3) lfo_rw <- lfo_cv(mod_rw,                 min_t = 40,                 fc_horizon = 3)  # Plot Pareto-K values and ELPD estimates plot(lfo_ar2) plot(lfo_rw)  # Proportion of timepoints in which AR2 model gives # better forecasts length(which((lfo_ar2$elpds - lfo_rw$elpds) > 0)) /       length(lfo_ar2$elpds)  # A higher total ELPD is preferred lfo_ar2$sum_ELPD lfo_rw$sum_ELPD }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/fitted.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected Values of the Posterior Predictive Distribution — fitted.mvgam","title":"Expected Values of the Posterior Predictive Distribution — fitted.mvgam","text":"method extracts posterior estimates fitted values (.e. actual predictions, included estimates trend states, obtained fitting model). also includes option obtaining summaries computed draws.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/fitted.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected Values of the Posterior Predictive Distribution — fitted.mvgam","text":"","code":"# S3 method for mvgam fitted(   object,   process_error = TRUE,   scale = c(\"response\", \"linear\"),   summary = TRUE,   robust = FALSE,   probs = c(0.025, 0.975),   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/fitted.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected Values of the Posterior Predictive Distribution — fitted.mvgam","text":"object object class mvgam process_error Logical. TRUE dynamic trend model fit, expected uncertainty process model accounted using draws latent trend SD parameters. FALSE, uncertainty latent trend component ignored calculating predictions scale Either \"response\" \"linear\". \"response\", results returned scale response variable. \"linear\", results returned scale linear predictor term, without applying inverse link function transformations. summary summary statistics returned instead raw values? Default TRUE.. robust FALSE (default) mean used measure central tendency standard deviation measure variability. TRUE, median median absolute deviation (MAD) applied instead. used summary TRUE. probs percentiles computed quantile function. used summary TRUE. ... arguments passed prepare_predictions control several aspects data validation prediction.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/fitted.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected Values of the Posterior Predictive Distribution — fitted.mvgam","text":"array predicted mean response values. summary = FALSE output resembles posterior_epred.mvgam predict.mvgam. summary = TRUE output n_observations x E matrix. number summary statistics E equal 2 +   length(probs): Estimate column contains point estimates (either mean median depending argument robust), Est.Error column contains uncertainty estimates (either standard deviation median absolute deviation depending argument robust). remaining columns starting Q contain quantile estimates specified via argument probs.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/fitted.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expected Values of the Posterior Predictive Distribution — fitted.mvgam","text":"method gives actual fitted values model (.e. see generate hindcasts fitted model using hindcast.mvgam type = 'expected'). predictions can overly precise flexible dynamic trend component included model. contrast set predict functions (.e. posterior_epred.mvgam predict.mvgam), assume dynamic trend component reached stationarity returning hypothetical predictions","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/fitted.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expected Values of the Posterior Predictive Distribution — fitted.mvgam","text":"","code":"if (FALSE) { # Simulate some data and fit a model simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Extract fitted values (posterior expectations) expectations <- fitted(mod) str(expectations) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/forecast.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract or compute hindcasts and forecasts for a fitted mvgam object — forecast.mvgam","title":"Extract or compute hindcasts and forecasts for a fitted mvgam object — forecast.mvgam","text":"Extract compute hindcasts forecasts fitted mvgam object","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/forecast.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract or compute hindcasts and forecasts for a fitted mvgam object — forecast.mvgam","text":"","code":"forecast(object, ...)  # S3 method for mvgam forecast(   object,   newdata,   data_test,   series = \"all\",   n_cores = 1,   type = \"response\",   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/forecast.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract or compute hindcasts and forecasts for a fitted mvgam object — forecast.mvgam","text":"object list object returned mvgam. See mvgam() ... Ignored newdata Optional dataframe list test data containing least 'series' 'time' addition variables included linear predictor original formula. included, covariate information newdata used generate forecasts fitted model equations. newdata originally included call mvgam, forecasts already produced generative model simply extracted plotted. However newdata supplied original model call, assumption made newdata supplied comes sequentially data supplied data original model (.e. assume time gap last observation series 1 data first observation series 1 newdata) data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows series Either integer specifying series set forecast, character string '', specifying series forecast. preferable fitted model contained multivariate trends (either dynamic factor VAR process), saves recomputing full set trends series individually n_cores integer specifying number cores generating forecasts parallel type value link (default) linear predictor calculated link scale. expected used, predictions reflect expectation response (mean) ignore uncertainty observation process. response used, predictions take uncertainty observation process account return predictions outcome scale. variance used, variance response respect mean (mean-variance relationship) returned. Two special cases also allowed: type latent_N return estimated latent abundances N-mixture distribution, type detection return estimated detection probability N-mixture distribution","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/forecast.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract or compute hindcasts and forecasts for a fitted mvgam object — forecast.mvgam","text":"object class mvgam_forecast containing hindcast forecast distributions. See mvgam_forecast-class details.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/forecast.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract or compute hindcasts and forecasts for a fitted mvgam object — forecast.mvgam","text":"Posterior predictions drawn fitted mvgam used simulate forecast distribution","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/forecast.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract or compute hindcasts and forecasts for a fitted mvgam object — forecast.mvgam","text":"","code":"if (FALSE) { simdat <- sim_mvgam(n_series = 3, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Hindcasts on response scale hc <- hindcast(mod) str(hc) plot(hc, series = 1) plot(hc, series = 2) plot(hc, series = 3)  # Forecasts on response scale fc <- forecast(mod, newdata = simdat$data_test) str(fc) plot(fc, series = 1) plot(fc, series = 2) plot(fc, series = 3)  # Forecasts as expectations fc <- forecast(mod, newdata = simdat$data_test, type = 'expected') plot(fc, series = 1) plot(fc, series = 2) plot(fc, series = 3)  }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/formula.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract formulae from mvgam objects — formula.mvgam","title":"Extract formulae from mvgam objects — formula.mvgam","text":"Extract formulae mvgam objects","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/formula.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract formulae from mvgam objects — formula.mvgam","text":"","code":"# S3 method for mvgam formula(x, trend_effects = FALSE, ...)  # S3 method for mvgam_prefit formula(x, trend_effects = FALSE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/formula.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract formulae from mvgam objects — formula.mvgam","text":"x mvgam mvgam_prefit object trend_effects logical, return formula observation model (FALSE) underlying process model (ifTRUE) ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/formula.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract formulae from mvgam objects — formula.mvgam","text":"formula object","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/formula.mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract formulae from mvgam objects — formula.mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_monitor_pars.html","id":null,"dir":"Reference","previous_headings":"","what":"Return parameters to monitor during modelling — get_monitor_pars","title":"Return parameters to monitor during modelling — get_monitor_pars","text":"Return parameters monitor modelling","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_monitor_pars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return parameters to monitor during modelling — get_monitor_pars","text":"","code":"get_monitor_pars(family, smooths_included = TRUE, use_lv, trend_model, drift)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_monitor_pars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return parameters to monitor during modelling — get_monitor_pars","text":"family character smooths_included Logical. smooth terms included model formula? use_lv Logical (use latent variable trends ) trend_model type trend model used drift Logical (drift term estimated )","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_monitor_pars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return parameters to monitor during modelling — get_monitor_pars","text":"string parameters monitor","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"function lists parameters can prior distributions changed given mvgam model, well listing default distributions","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"","code":"get_mvgam_priors(   formula,   trend_formula,   data,   data_train,   family = \"poisson\",   use_lv = FALSE,   n_lv,   use_stan = TRUE,   trend_model = \"None\",   trend_map,   drift = FALSE )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"formula character string specifying GAM observation model formula. exactly like formula GLM except smooth terms, s(), te(), ti(), t2(), well time-varying dynamic() terms, can added right hand side specify linear predictor depends smooth functions predictors (linear functionals ). nmix() family models, formula used set linear predictor detection probability. Details formula syntax used mvgam can found mvgam_formulae trend_formula optional character string specifying GAM process model formula. supplied, linear predictor modelled latent trends capture process model evolution separately observation model. response variable specified left-hand side formula (.e. valid option ~ season + s(year)). Also note use identifier series formula specify effects vary across time series. Instead use trend. ensure models trend_map supplied still work consistently (.e. allowing effects vary across process models, even time series share underlying process model). feature currently available RW(), AR() VAR() trend models. nmix() family models, trend_formula used set linear predictor underlying latent abundance data dataframe list containing model response variable covariates required GAM formula optional trend_formula. include columns: series (factor index series IDs;number levels identical number unique series labels (.e. n_series = length(levels(data$series)))) time (numeric integer index time point observation). variables included linear predictor formula must also present data_train Deprecated. Still works place data users recommended use data instead seamless integration R workflows family family specifying exponential observation family series. Currently supported families : nb() count data poisson() count data gaussian() real-valued data betar() proportional data (0,1) lognormal() non-negative real-valued data student_t() real-valued data Gamma() non-negative real-valued data nmix() count data imperfect detection modeled via State-Space N-Mixture model. latent states Poisson, capturing 'true' latent abundance, observation process Binomial account imperfect detection. See mvgam_families example use family Note nb() poisson() available using JAGS backend. Default poisson(). See mvgam_families details use_lv logical. TRUE, use dynamic factors estimate series' latent trends reduced dimension format. available RW(), AR() GP() trend models. Defaults FALSE n_lv integer number latent dynamic factors use use_lv == TRUE. > n_series. Defaults arbitrarily min(2, floor(n_series / 2)) use_stan Logical. TRUE, model compiled sampled using Hamiltonian Monte Carlo call cmdstan_model call stan. Note many options using Stan vs JAGS trend_model character  function specifying time series dynamics latent trend. Options : None (latent trend component; .e. GAM component contributes linear predictor, observation process source error; similarly estimated gam) 'RW' RW() 'AR1' AR(p = 1) 'AR2' AR(p = 2) 'AR3' AR(p = 3) 'VAR1'  VAR()(available Stan) 'PWlogistic, 'PWlinear' PW() (available Stan) 'GP' GP() (Gaussian Process squared exponential kernel; available Stan) trend types apart GP() PW(), moving average /correlated process error terms can also estimated (example, RW(cor = TRUE) set multivariate Random Walk n_series > 1). See mvgam_trends details trend_map Optional data.frame specifying series depend latent trends. Useful allowing multiple series depend latent trend process, different observation processes. supplied, latent factor model set setting use_lv = TRUE using mapping set shared trends. Needs column names series trend, integer values trend column state trend series depend . series column single unique entry series data (names perfectly match factor levels series variable data). See examples details drift logical estimate drift parameter latent trend components. Useful latent trend expected broadly follow non-zero slope. available RW() AR() trend models. Note latent trend less stationary, drift parameter can become unidentifiable, especially intercept term included GAM linear predictor (default calling jagam). Drift parameters also likely unidentifiable using dynamic factor models. Therefore defaults FALSE","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"either data.frame containing prior definitions (suitable priors can altered user) NULL, indicating priors model can modified mvgam interface","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"Users can supply model formula, prior fitting model, default priors can inspected altered. make alterations, change contents prior column supplying data.frame mvgam function using argument priors. using Stan backend, users can also modify parameter bounds modifying new_lowerbound /new_upperbound columns. necessary using restrictive distributions parameters, Beta distribution trend sd parameters example (Beta support  (0,1)), upperbound 1. Another option make use prior modification functions brms (.e. prior) change prior distributions bounds (just use name parameter like change class argument; see examples )","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"prior, new_lowerbound /new_upperbound columns output altered defining user-defined priors mvgam model. Use familiar underlying probabilistic programming language. sanity checks done ensure code legal (.e. check lower bounds smaller upper bounds, example)","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/get_mvgam_priors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract information on default prior distributions for an mvgam model — get_mvgam_priors","text":"","code":"# Simulate three integer-valued time series library(mvgam) dat <- sim_mvgam(trend_rel = 0.5)  # Get a model file that uses default mvgam priors for inspection (not always necessary, # but this can be useful for testing whether your updated priors are written correctly) mod_default <- mvgam(y ~ s(series, bs = 're') +               s(season, bs = 'cc') - 1,               family = 'nb',               data = dat$data_train,               trend_model = 'AR2',               run_model = FALSE)  # Inspect the model file with default mvgam priors code(mod_default) #> // Stan model code generated by package mvgam #> functions { #>   vector rep_each(vector x, int K) { #>     int N = rows(x); #>     vector[N * K] y; #>     int pos = 1; #>     for (n in 1 : N) { #>       for (k in 1 : K) { #>         y[pos] = x[n]; #>         pos += 1; #>       } #>     } #>     return y; #>   } #> } #> data { #>   int<lower=0> total_obs; // total number of observations #>   int<lower=0> n; // number of timepoints per series #>   int<lower=0> n_sp; // number of smoothing parameters #>   int<lower=0> n_series; // number of series #>   int<lower=0> num_basis; // total number of basis coefficients #>   vector[num_basis] zero; // prior locations for basis coefficients #>   matrix[total_obs, num_basis] X; // mgcv GAM design matrix #>   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) #>   matrix[8, 8] S1; // mgcv smooth penalty matrix S1 #>   int<lower=0> n_nonmissing; // number of nonmissing observations #>   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations #>   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations #>   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations #> } #> parameters { #>   // raw basis coefficients #>   vector[num_basis] b_raw; #>    #>   // random effect variances #>   vector<lower=0>[1] sigma_raw; #>    #>   // random effect means #>   vector[1] mu_raw; #>    #>   // negative binomial overdispersion #>   vector<lower=0>[n_series] phi_inv; #>    #>   // latent trend AR1 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar1; #>    #>   // latent trend AR2 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar2; #>    #>   // latent trend variance parameters #>   vector<lower=0>[n_series] sigma; #>    #>   // latent trends #>   matrix[n, n_series] trend; #>    #>   // smoothing parameters #>   vector<lower=0>[n_sp] lambda; #> } #> transformed parameters { #>   // basis coefficients #>   vector[num_basis] b; #>   b[1 : 8] = b_raw[1 : 8]; #>   b[9 : 11] = mu_raw[1] + b_raw[9 : 11] * sigma_raw[1]; #> } #> model { #>   // prior for random effect population variances #>   sigma_raw ~ student_t(3, 0, 2.5); #>    #>   // prior for random effect population means #>   mu_raw ~ std_normal(); #>    #>   // prior for s(season)... #>   b_raw[1 : 8] ~ multi_normal_prec(zero[1 : 8], S1[1 : 8, 1 : 8] * lambda[1]); #>    #>   // prior (non-centred) for s(series)... #>   b_raw[9 : 11] ~ std_normal(); #>    #>   // priors for AR parameters #>   ar1 ~ std_normal(); #>   ar2 ~ std_normal(); #>    #>   // priors for smoothing parameters #>   lambda ~ normal(5, 30); #>    #>   // priors for overdispersion parameters #>   phi_inv ~ student_t(3, 0, 0.1); #>    #>   // priors for latent trend variance parameters #>   sigma ~ student_t(3, 0, 2.5); #>    #>   // trend estimates #>   trend[1, 1 : n_series] ~ normal(0, sigma); #>   trend[2, 1 : n_series] ~ normal(trend[1, 1 : n_series] * ar1, sigma); #>   for (s in 1 : n_series) { #>     trend[3 : n, s] ~ normal(ar1[s] * trend[2 : (n - 1), s] #>                              + ar2[s] * trend[1 : (n - 2), s], sigma[s]); #>   } #>   { #>     // likelihood functions #>     vector[n_nonmissing] flat_trends; #>     array[n_nonmissing] real flat_phis; #>     flat_trends = to_vector(trend)[obs_ind]; #>     flat_phis = to_array_1d(rep_each(phi_inv, n)[obs_ind]); #>     flat_ys ~ neg_binomial_2(exp(append_col(flat_xs, flat_trends) #>                                  * append_row(b, 1.0)), #>                              inv(flat_phis)); #>   } #> } #> generated quantities { #>   vector[total_obs] eta; #>   matrix[n, n_series] mus; #>   vector[n_sp] rho; #>   vector[n_series] tau; #>   array[n, n_series] int ypred; #>   matrix[n, n_series] phi_vec; #>   vector[n_series] phi; #>   phi = inv(phi_inv); #>   for (s in 1 : n_series) { #>     phi_vec[1 : n, s] = rep_vector(phi[s], n); #>   } #>   rho = log(lambda); #>   for (s in 1 : n_series) { #>     tau[s] = pow(sigma[s], -2.0); #>   } #>    #>   // posterior predictions #>   eta = X * b; #>   for (s in 1 : n_series) { #>     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; #>     ypred[1 : n, s] = neg_binomial_2_rng(exp(mus[1 : n, s]), phi_vec[1 : n, s]); #>   } #> } #>  #>   # Look at which priors can be updated in mvgam test_priors <- get_mvgam_priors(y ~ s(series, bs = 're') +                               s(season, bs = 'cc') - 1,                               family = 'nb',                               data = dat$data_train,                               trend_model = 'AR2') test_priors #>                                    param_name param_length #> 1               vector<lower=0>[n_sp] lambda;            2 #> 2                           vector[1] mu_raw;            1 #> 3               vector<lower=0>[1] sigma_raw;            1 #> 4 vector<lower=-1.5,upper=1.5>[n_series] ar1;            3 #> 5 vector<lower=-1.5,upper=1.5>[n_series] ar2;            3 #> 6            vector<lower=0>[n_series] sigma;            3 #> 7          vector<lower=0>[n_series] phi_inv;            3 #>                    param_info                             prior #> 1 s(season) smooth parameters           lambda ~ normal(5, 30); #> 2          s(series) pop mean            mu_raw ~ std_normal(); #> 3            s(series) pop sd sigma_raw ~ student_t(3, 0, 2.5); #> 4       trend AR1 coefficient               ar1 ~ std_normal(); #> 5       trend AR2 coefficient               ar2 ~ std_normal(); #> 6                    trend sd     sigma ~ student_t(3, 0, 2.5); #> 7   inverse of NB dispsersion   phi_inv ~ student_t(3, 0, 0.1); #>                   example_change new_lowerbound new_upperbound #> 1    lambda ~ exponential(0.25);             NA             NA #> 2   mu_raw ~ normal(0.96, 0.76);             NA             NA #> 3 sigma_raw ~ exponential(0.17);             NA             NA #> 4      ar1 ~ normal(0.58, 0.24);             NA             NA #> 5      ar2 ~ normal(0.26, 0.69);             NA             NA #> 6     sigma ~ exponential(0.26);             NA             NA #> 7  phi_inv ~ normal(0.39, 0.35);             NA             NA  # Make a few changes; first, change the population mean for the series-level # random intercepts test_priors$prior[2] <- 'mu_raw ~ normal(0.2, 0.5);'  # Now use stronger regularisation for the series-level AR2 coefficients test_priors$prior[5] <- 'ar2 ~ normal(0, 0.25);'  # Check that the changes are made to the model file without any warnings by # setting 'run_model = FALSE' mod <- mvgam(y ~ s(series, bs = 're') +             s(season, bs = 'cc') - 1,             family = 'nb',             data = dat$data_train,             trend_model = 'AR2',             priors = test_priors,             run_model = FALSE)             code(mod) #> // Stan model code generated by package mvgam #> functions { #>   vector rep_each(vector x, int K) { #>     int N = rows(x); #>     vector[N * K] y; #>     int pos = 1; #>     for (n in 1 : N) { #>       for (k in 1 : K) { #>         y[pos] = x[n]; #>         pos += 1; #>       } #>     } #>     return y; #>   } #> } #> data { #>   int<lower=0> total_obs; // total number of observations #>   int<lower=0> n; // number of timepoints per series #>   int<lower=0> n_sp; // number of smoothing parameters #>   int<lower=0> n_series; // number of series #>   int<lower=0> num_basis; // total number of basis coefficients #>   vector[num_basis] zero; // prior locations for basis coefficients #>   matrix[total_obs, num_basis] X; // mgcv GAM design matrix #>   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) #>   matrix[8, 8] S1; // mgcv smooth penalty matrix S1 #>   int<lower=0> n_nonmissing; // number of nonmissing observations #>   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations #>   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations #>   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations #> } #> parameters { #>   // raw basis coefficients #>   vector[num_basis] b_raw; #>    #>   // random effect variances #>   vector<lower=0>[1] sigma_raw; #>    #>   // random effect means #>   vector[1] mu_raw; #>    #>   // negative binomial overdispersion #>   vector<lower=0>[n_series] phi_inv; #>    #>   // latent trend AR1 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar1; #>    #>   // latent trend AR2 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar2; #>    #>   // latent trend variance parameters #>   vector<lower=0>[n_series] sigma; #>    #>   // latent trends #>   matrix[n, n_series] trend; #>    #>   // smoothing parameters #>   vector<lower=0>[n_sp] lambda; #> } #> transformed parameters { #>   // basis coefficients #>   vector[num_basis] b; #>   b[1 : 8] = b_raw[1 : 8]; #>   b[9 : 11] = mu_raw[1] + b_raw[9 : 11] * sigma_raw[1]; #> } #> model { #>   // prior for random effect population variances #>   sigma_raw ~ student_t(3, 0, 2.5); #>    #>   // prior for random effect population means #>   mu_raw ~ normal(0.2, 0.5); #>    #>   // prior for s(season)... #>   b_raw[1 : 8] ~ multi_normal_prec(zero[1 : 8], S1[1 : 8, 1 : 8] * lambda[1]); #>    #>   // prior (non-centred) for s(series)... #>   b_raw[9 : 11] ~ std_normal(); #>    #>   // priors for AR parameters #>   ar1 ~ std_normal(); #>   ar2 ~ normal(0, 0.25); #>    #>   // priors for smoothing parameters #>   lambda ~ normal(5, 30); #>    #>   // priors for overdispersion parameters #>   phi_inv ~ student_t(3, 0, 0.1); #>    #>   // priors for latent trend variance parameters #>   sigma ~ student_t(3, 0, 2.5); #>    #>   // trend estimates #>   trend[1, 1 : n_series] ~ normal(0, sigma); #>   trend[2, 1 : n_series] ~ normal(trend[1, 1 : n_series] * ar1, sigma); #>   for (s in 1 : n_series) { #>     trend[3 : n, s] ~ normal(ar1[s] * trend[2 : (n - 1), s] #>                              + ar2[s] * trend[1 : (n - 2), s], sigma[s]); #>   } #>   { #>     // likelihood functions #>     vector[n_nonmissing] flat_trends; #>     array[n_nonmissing] real flat_phis; #>     flat_trends = to_vector(trend)[obs_ind]; #>     flat_phis = to_array_1d(rep_each(phi_inv, n)[obs_ind]); #>     flat_ys ~ neg_binomial_2(exp(append_col(flat_xs, flat_trends) #>                                  * append_row(b, 1.0)), #>                              inv(flat_phis)); #>   } #> } #> generated quantities { #>   vector[total_obs] eta; #>   matrix[n, n_series] mus; #>   vector[n_sp] rho; #>   vector[n_series] tau; #>   array[n, n_series] int ypred; #>   matrix[n, n_series] phi_vec; #>   vector[n_series] phi; #>   phi = inv(phi_inv); #>   for (s in 1 : n_series) { #>     phi_vec[1 : n, s] = rep_vector(phi[s], n); #>   } #>   rho = log(lambda); #>   for (s in 1 : n_series) { #>     tau[s] = pow(sigma[s], -2.0); #>   } #>    #>   // posterior predictions #>   eta = X * b; #>   for (s in 1 : n_series) { #>     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; #>     ypred[1 : n, s] = neg_binomial_2_rng(exp(mus[1 : n, s]), phi_vec[1 : n, s]); #>   } #> } #>  #>   # No warnings, the model is ready for fitting now in the usual way with the addition # of the 'priors' argument  # The same can be done using brms functions; here we will also change the ar1 prior # and put some bounds on the ar coefficients to enforce stationarity; we set the # prior using the 'class' argument in all brms prior functions brmsprior <- c(prior(normal(0.2, 0.5), class = mu_raw),               prior(normal(0, 0.25), class = ar1, lb = -1, ub = 1),               prior(normal(0, 0.25), class = ar2, lb = -1, ub = 1)) brmsprior #>             prior  class coef group resp dpar nlpar   lb   ub source #>  normal(0.2, 0.5) mu_raw                            <NA> <NA>   user #>   normal(0, 0.25)    ar1                              -1    1   user #>   normal(0, 0.25)    ar2                              -1    1   user  mod <- mvgam(y ~ s(series, bs = 're') +             s(season, bs = 'cc') - 1,           family = 'nb',           data = dat$data_train,           trend_model = 'AR2',           priors = brmsprior,           run_model = FALSE) code(mod) #> // Stan model code generated by package mvgam #> functions { #>   vector rep_each(vector x, int K) { #>     int N = rows(x); #>     vector[N * K] y; #>     int pos = 1; #>     for (n in 1 : N) { #>       for (k in 1 : K) { #>         y[pos] = x[n]; #>         pos += 1; #>       } #>     } #>     return y; #>   } #> } #> data { #>   int<lower=0> total_obs; // total number of observations #>   int<lower=0> n; // number of timepoints per series #>   int<lower=0> n_sp; // number of smoothing parameters #>   int<lower=0> n_series; // number of series #>   int<lower=0> num_basis; // total number of basis coefficients #>   vector[num_basis] zero; // prior locations for basis coefficients #>   matrix[total_obs, num_basis] X; // mgcv GAM design matrix #>   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) #>   matrix[8, 8] S1; // mgcv smooth penalty matrix S1 #>   int<lower=0> n_nonmissing; // number of nonmissing observations #>   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations #>   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations #>   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations #> } #> parameters { #>   // raw basis coefficients #>   vector[num_basis] b_raw; #>    #>   // random effect variances #>   vector<lower=0>[1] sigma_raw; #>    #>   // random effect means #>   vector[1] mu_raw; #>    #>   // negative binomial overdispersion #>   vector<lower=0>[n_series] phi_inv; #>    #>   // latent trend AR1 terms #>   vector<lower=-1, upper=1>[n_series] ar1; #>    #>   // latent trend AR2 terms #>   vector<lower=-1, upper=1>[n_series] ar2; #>    #>   // latent trend variance parameters #>   vector<lower=0>[n_series] sigma; #>    #>   // latent trends #>   matrix[n, n_series] trend; #>    #>   // smoothing parameters #>   vector<lower=0>[n_sp] lambda; #> } #> transformed parameters { #>   // basis coefficients #>   vector[num_basis] b; #>   b[1 : 8] = b_raw[1 : 8]; #>   b[9 : 11] = mu_raw[1] + b_raw[9 : 11] * sigma_raw[1]; #> } #> model { #>   // prior for random effect population variances #>   sigma_raw ~ student_t(3, 0, 2.5); #>    #>   // prior for random effect population means #>   mu_raw ~ normal(0.2, 0.5); #>    #>   // prior for s(season)... #>   b_raw[1 : 8] ~ multi_normal_prec(zero[1 : 8], S1[1 : 8, 1 : 8] * lambda[1]); #>    #>   // prior (non-centred) for s(series)... #>   b_raw[9 : 11] ~ std_normal(); #>    #>   // priors for AR parameters #>   ar1 ~ normal(0, 0.25); #>   ar2 ~ normal(0, 0.25); #>    #>   // priors for smoothing parameters #>   lambda ~ normal(5, 30); #>    #>   // priors for overdispersion parameters #>   phi_inv ~ student_t(3, 0, 0.1); #>    #>   // priors for latent trend variance parameters #>   sigma ~ student_t(3, 0, 2.5); #>    #>   // trend estimates #>   trend[1, 1 : n_series] ~ normal(0, sigma); #>   trend[2, 1 : n_series] ~ normal(trend[1, 1 : n_series] * ar1, sigma); #>   for (s in 1 : n_series) { #>     trend[3 : n, s] ~ normal(ar1[s] * trend[2 : (n - 1), s] #>                              + ar2[s] * trend[1 : (n - 2), s], sigma[s]); #>   } #>   { #>     // likelihood functions #>     vector[n_nonmissing] flat_trends; #>     array[n_nonmissing] real flat_phis; #>     flat_trends = to_vector(trend)[obs_ind]; #>     flat_phis = to_array_1d(rep_each(phi_inv, n)[obs_ind]); #>     flat_ys ~ neg_binomial_2(exp(append_col(flat_xs, flat_trends) #>                                  * append_row(b, 1.0)), #>                              inv(flat_phis)); #>   } #> } #> generated quantities { #>   vector[total_obs] eta; #>   matrix[n, n_series] mus; #>   vector[n_sp] rho; #>   vector[n_series] tau; #>   array[n, n_series] int ypred; #>   matrix[n, n_series] phi_vec; #>   vector[n_series] phi; #>   phi = inv(phi_inv); #>   for (s in 1 : n_series) { #>     phi_vec[1 : n, s] = rep_vector(phi[s], n); #>   } #>   rho = log(lambda); #>   for (s in 1 : n_series) { #>     tau[s] = pow(sigma[s], -2.0); #>   } #>    #>   // posterior predictions #>   eta = X * b; #>   for (s in 1 : n_series) { #>     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; #>     ypred[1 : n, s] = neg_binomial_2_rng(exp(mus[1 : n, s]), phi_vec[1 : n, s]); #>   } #> } #>  #>   # Look at what is returned when an incorrect spelling is used test_priors$prior[5] <- 'ar2_bananas ~ normal(0, 0.25);' mod <- mvgam(y ~ s(series, bs = 're') +             s(season, bs = 'cc') - 1,             family = 'nb',             data = dat$data_train,             trend_model = 'AR2',             priors = test_priors,             run_model = FALSE) #> Warning: no match found in model_file for parameter: ar2_bananas code(mod) #> // Stan model code generated by package mvgam #> functions { #>   vector rep_each(vector x, int K) { #>     int N = rows(x); #>     vector[N * K] y; #>     int pos = 1; #>     for (n in 1 : N) { #>       for (k in 1 : K) { #>         y[pos] = x[n]; #>         pos += 1; #>       } #>     } #>     return y; #>   } #> } #> data { #>   int<lower=0> total_obs; // total number of observations #>   int<lower=0> n; // number of timepoints per series #>   int<lower=0> n_sp; // number of smoothing parameters #>   int<lower=0> n_series; // number of series #>   int<lower=0> num_basis; // total number of basis coefficients #>   vector[num_basis] zero; // prior locations for basis coefficients #>   matrix[total_obs, num_basis] X; // mgcv GAM design matrix #>   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) #>   matrix[8, 8] S1; // mgcv smooth penalty matrix S1 #>   int<lower=0> n_nonmissing; // number of nonmissing observations #>   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations #>   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations #>   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations #> } #> parameters { #>   // raw basis coefficients #>   vector[num_basis] b_raw; #>    #>   // random effect variances #>   vector<lower=0>[1] sigma_raw; #>    #>   // random effect means #>   vector[1] mu_raw; #>    #>   // negative binomial overdispersion #>   vector<lower=0>[n_series] phi_inv; #>    #>   // latent trend AR1 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar1; #>    #>   // latent trend AR2 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar2; #>    #>   // latent trend variance parameters #>   vector<lower=0>[n_series] sigma; #>    #>   // latent trends #>   matrix[n, n_series] trend; #>    #>   // smoothing parameters #>   vector<lower=0>[n_sp] lambda; #> } #> transformed parameters { #>   // basis coefficients #>   vector[num_basis] b; #>   b[1 : 8] = b_raw[1 : 8]; #>   b[9 : 11] = mu_raw[1] + b_raw[9 : 11] * sigma_raw[1]; #> } #> model { #>   // prior for random effect population variances #>   sigma_raw ~ student_t(3, 0, 2.5); #>    #>   // prior for random effect population means #>   mu_raw ~ normal(0.2, 0.5); #>    #>   // prior for s(season)... #>   b_raw[1 : 8] ~ multi_normal_prec(zero[1 : 8], S1[1 : 8, 1 : 8] * lambda[1]); #>    #>   // prior (non-centred) for s(series)... #>   b_raw[9 : 11] ~ std_normal(); #>    #>   // priors for AR parameters #>   ar1 ~ std_normal(); #>   ar2 ~ std_normal(); #>    #>   // priors for smoothing parameters #>   lambda ~ normal(5, 30); #>    #>   // priors for overdispersion parameters #>   phi_inv ~ student_t(3, 0, 0.1); #>    #>   // priors for latent trend variance parameters #>   sigma ~ student_t(3, 0, 2.5); #>    #>   // trend estimates #>   trend[1, 1 : n_series] ~ normal(0, sigma); #>   trend[2, 1 : n_series] ~ normal(trend[1, 1 : n_series] * ar1, sigma); #>   for (s in 1 : n_series) { #>     trend[3 : n, s] ~ normal(ar1[s] * trend[2 : (n - 1), s] #>                              + ar2[s] * trend[1 : (n - 2), s], sigma[s]); #>   } #>   { #>     // likelihood functions #>     vector[n_nonmissing] flat_trends; #>     array[n_nonmissing] real flat_phis; #>     flat_trends = to_vector(trend)[obs_ind]; #>     flat_phis = to_array_1d(rep_each(phi_inv, n)[obs_ind]); #>     flat_ys ~ neg_binomial_2(exp(append_col(flat_xs, flat_trends) #>                                  * append_row(b, 1.0)), #>                              inv(flat_phis)); #>   } #> } #> generated quantities { #>   vector[total_obs] eta; #>   matrix[n, n_series] mus; #>   vector[n_sp] rho; #>   vector[n_series] tau; #>   array[n, n_series] int ypred; #>   matrix[n, n_series] phi_vec; #>   vector[n_series] phi; #>   phi = inv(phi_inv); #>   for (s in 1 : n_series) { #>     phi_vec[1 : n, s] = rep_vector(phi[s], n); #>   } #>   rho = log(lambda); #>   for (s in 1 : n_series) { #>     tau[s] = pow(sigma[s], -2.0); #>   } #>    #>   // posterior predictions #>   eta = X * b; #>   for (s in 1 : n_series) { #>     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; #>     ypred[1 : n, s] = neg_binomial_2_rng(exp(mus[1 : n, s]), phi_vec[1 : n, s]); #>   } #> } #>  #>   # Example of changing parametric (fixed effect) priors simdat <- sim_mvgam()  # Add a fake covariate simdat$data_train$cov <- rnorm(NROW(simdat$data_train))  priors <- get_mvgam_priors(y ~ cov + s(season),                           data = simdat$data_train,                           family = poisson(),                           trend_model = 'AR1')  # Change priors for the intercept and fake covariate effects priors$prior[1] <- '(Intercept) ~ normal(0, 1);' priors$prior[2] <- 'cov ~ normal(0, 0.1);'  mod2 <- mvgam(y ~ cov + s(season),              data = simdat$data_train,              trend_model = 'AR1',              family = poisson(),              priors = priors,              run_model = FALSE) code(mod2) #> // Stan model code generated by package mvgam #> data { #>   int<lower=0> total_obs; // total number of observations #>   int<lower=0> n; // number of timepoints per series #>   int<lower=0> n_sp; // number of smoothing parameters #>   int<lower=0> n_series; // number of series #>   int<lower=0> num_basis; // total number of basis coefficients #>   vector[num_basis] zero; // prior locations for basis coefficients #>   matrix[total_obs, num_basis] X; // mgcv GAM design matrix #>   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) #>   matrix[9, 18] S1; // mgcv smooth penalty matrix S1 #>   int<lower=0> n_nonmissing; // number of nonmissing observations #>   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations #>   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations #>   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations #> } #> parameters { #>   // raw basis coefficients #>   vector[num_basis] b_raw; #>    #>   // latent trend AR1 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar1; #>    #>   // latent trend variance parameters #>   vector<lower=0>[n_series] sigma; #>    #>   // latent trends #>   matrix[n, n_series] trend; #>    #>   // smoothing parameters #>   vector<lower=0>[n_sp] lambda; #> } #> transformed parameters { #>   // basis coefficients #>   vector[num_basis] b; #>   b[1 : num_basis] = b_raw[1 : num_basis]; #> } #> model { #>   // prior for (Intercept)... #>   b_raw[1] ~ normal(0, 1); #>    #>   // prior for cov... #>   b_raw[2] ~ normal(0, 0.1); #>    #>   // prior for s(season)... #>   b_raw[3 : 11] ~ multi_normal_prec(zero[3 : 11], #>                                     S1[1 : 9, 1 : 9] * lambda[1] #>                                     + S1[1 : 9, 10 : 18] * lambda[2]); #>    #>   // priors for AR parameters #>   ar1 ~ std_normal(); #>    #>   // priors for smoothing parameters #>   lambda ~ normal(5, 30); #>    #>   // priors for latent trend variance parameters #>   sigma ~ student_t(3, 0, 2.5); #>    #>   // trend estimates #>   trend[1, 1 : n_series] ~ normal(0, sigma); #>   for (s in 1 : n_series) { #>     trend[2 : n, s] ~ normal(ar1[s] * trend[1 : (n - 1), s], sigma[s]); #>   } #>   { #>     // likelihood functions #>     vector[n_nonmissing] flat_trends; #>     flat_trends = to_vector(trend)[obs_ind]; #>     flat_ys ~ poisson_log_glm(append_col(flat_xs, flat_trends), 0.0, #>                               append_row(b, 1.0)); #>   } #> } #> generated quantities { #>   vector[total_obs] eta; #>   matrix[n, n_series] mus; #>   vector[n_sp] rho; #>   vector[n_series] tau; #>   array[n, n_series] int ypred; #>   rho = log(lambda); #>   for (s in 1 : n_series) { #>     tau[s] = pow(sigma[s], -2.0); #>   } #>    #>   // posterior predictions #>   eta = X * b; #>   for (s in 1 : n_series) { #>     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; #>     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]); #>   } #> } #>  #>   # Likewise using brms utilities (note that you can use # Intercept rather than `(Intercept)`) to change priors on the intercept brmsprior <- c(prior(normal(0.2, 0.5), class = cov),               prior(normal(0, 0.25), class = Intercept)) brmsprior #>             prior     class coef group resp dpar nlpar   lb   ub source #>  normal(0.2, 0.5)       cov                            <NA> <NA>   user #>   normal(0, 0.25) Intercept                            <NA> <NA>   user  mod2 <- mvgam(y ~ cov + s(season),              data = simdat$data_train,              trend_model = 'AR1',              family = poisson(),              priors = brmsprior,              run_model = FALSE) code(mod2) #> // Stan model code generated by package mvgam #> data { #>   int<lower=0> total_obs; // total number of observations #>   int<lower=0> n; // number of timepoints per series #>   int<lower=0> n_sp; // number of smoothing parameters #>   int<lower=0> n_series; // number of series #>   int<lower=0> num_basis; // total number of basis coefficients #>   vector[num_basis] zero; // prior locations for basis coefficients #>   matrix[total_obs, num_basis] X; // mgcv GAM design matrix #>   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) #>   matrix[9, 18] S1; // mgcv smooth penalty matrix S1 #>   int<lower=0> n_nonmissing; // number of nonmissing observations #>   array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations #>   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations #>   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations #> } #> parameters { #>   // raw basis coefficients #>   vector[num_basis] b_raw; #>    #>   // latent trend AR1 terms #>   vector<lower=-1.5, upper=1.5>[n_series] ar1; #>    #>   // latent trend variance parameters #>   vector<lower=0>[n_series] sigma; #>    #>   // latent trends #>   matrix[n, n_series] trend; #>    #>   // smoothing parameters #>   vector<lower=0>[n_sp] lambda; #> } #> transformed parameters { #>   // basis coefficients #>   vector[num_basis] b; #>   b[1 : num_basis] = b_raw[1 : num_basis]; #> } #> model { #>   // prior for (Intercept)... #>   b_raw[1] ~ normal(0, 0.25); #>    #>   // prior for cov... #>   b_raw[2] ~ normal(0.2, 0.5); #>    #>   // prior for s(season)... #>   b_raw[3 : 11] ~ multi_normal_prec(zero[3 : 11], #>                                     S1[1 : 9, 1 : 9] * lambda[1] #>                                     + S1[1 : 9, 10 : 18] * lambda[2]); #>    #>   // priors for AR parameters #>   ar1 ~ std_normal(); #>    #>   // priors for smoothing parameters #>   lambda ~ normal(5, 30); #>    #>   // priors for latent trend variance parameters #>   sigma ~ student_t(3, 0, 2.5); #>    #>   // trend estimates #>   trend[1, 1 : n_series] ~ normal(0, sigma); #>   for (s in 1 : n_series) { #>     trend[2 : n, s] ~ normal(ar1[s] * trend[1 : (n - 1), s], sigma[s]); #>   } #>   { #>     // likelihood functions #>     vector[n_nonmissing] flat_trends; #>     flat_trends = to_vector(trend)[obs_ind]; #>     flat_ys ~ poisson_log_glm(append_col(flat_xs, flat_trends), 0.0, #>                               append_row(b, 1.0)); #>   } #> } #> generated quantities { #>   vector[total_obs] eta; #>   matrix[n, n_series] mus; #>   vector[n_sp] rho; #>   vector[n_series] tau; #>   array[n, n_series] int ypred; #>   rho = log(lambda); #>   for (s in 1 : n_series) { #>     tau[s] = pow(sigma[s], -2.0); #>   } #>    #>   // posterior predictions #>   eta = X * b; #>   for (s in 1 : n_series) { #>     mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s]; #>     ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]); #>   } #> } #>  #>   # The \"class = 'b'\" shortcut can be used to put the same prior on all # 'fixed' effect coefficients (apart from any intercepts) set.seed(0) dat <- mgcv::gamSim(1, n = 200, scale = 2) #> Gu & Wahba 4 term additive model dat$time <- 1:NROW(dat) mod <- mvgam(y ~ x0 + x1 + s(x2) + s(x3),             priors = prior(normal(0, 0.75), class = 'b'),             data = dat,             family = gaussian(),             run_model = FALSE) code(mod) #> // Stan model code generated by package mvgam #> functions { #>   vector rep_each(vector x, int K) { #>     int N = rows(x); #>     vector[N * K] y; #>     int pos = 1; #>     for (n in 1 : N) { #>       for (k in 1 : K) { #>         y[pos] = x[n]; #>         pos += 1; #>       } #>     } #>     return y; #>   } #> } #> data { #>   int<lower=0> total_obs; // total number of observations #>   int<lower=0> n; // number of timepoints per series #>   int<lower=0> n_sp; // number of smoothing parameters #>   int<lower=0> n_series; // number of series #>   int<lower=0> num_basis; // total number of basis coefficients #>   vector[num_basis] zero; // prior locations for basis coefficients #>   matrix[total_obs, num_basis] X; // mgcv GAM design matrix #>   array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?) #>   matrix[9, 18] S1; // mgcv smooth penalty matrix S1 #>   matrix[9, 18] S2; // mgcv smooth penalty matrix S2 #>   int<lower=0> n_nonmissing; // number of nonmissing observations #>   vector[n_nonmissing] flat_ys; // flattened nonmissing observations #>   matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations #>   array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations #> } #> parameters { #>   // raw basis coefficients #>   vector[num_basis] b_raw; #>    #>   // gaussian observation error #>   vector<lower=0>[n_series] sigma_obs; #>    #>   // smoothing parameters #>   vector<lower=0>[n_sp] lambda; #> } #> transformed parameters { #>   // basis coefficients #>   vector[num_basis] b; #>   b[1 : num_basis] = b_raw[1 : num_basis]; #> } #> model { #>   // prior for (Intercept)... #>   b_raw[1] ~ student_t(3, 7.4, 3.7); #>    #>   // prior for x0... #>   b_raw[2] ~ normal(0, 0.75); #>    #>   // prior for x1... #>   b_raw[3] ~ normal(0, 0.75); #>    #>   // prior for s(x2)... #>   b_raw[4 : 12] ~ multi_normal_prec(zero[4 : 12], #>                                     S1[1 : 9, 1 : 9] * lambda[1] #>                                     + S1[1 : 9, 10 : 18] * lambda[2]); #>    #>   // prior for s(x3)... #>   b_raw[13 : 21] ~ multi_normal_prec(zero[13 : 21], #>                                      S2[1 : 9, 1 : 9] * lambda[3] #>                                      + S2[1 : 9, 10 : 18] * lambda[4]); #>    #>   // priors for smoothing parameters #>   lambda ~ normal(5, 30); #>    #>   // priors for observation error parameters #>   sigma_obs ~ student_t(3, 0, 3.7); #>   { #>     // likelihood functions #>     vector[n_nonmissing] flat_sigma_obs; #>     flat_sigma_obs = rep_each(sigma_obs, n)[obs_ind]; #>     flat_ys ~ normal_id_glm(flat_xs, 0.0, b, flat_sigma_obs); #>   } #> } #> generated quantities { #>   vector[total_obs] eta; #>   matrix[n, n_series] sigma_obs_vec; #>   matrix[n, n_series] mus; #>   vector[n_sp] rho; #>   array[n, n_series] real ypred; #>   rho = log(lambda); #>    #>   // posterior predictions #>   eta = X * b; #>   for (s in 1 : n_series) { #>     sigma_obs_vec[1 : n, s] = rep_vector(sigma_obs[s], n); #>   } #>   for (s in 1 : n_series) { #>     mus[1 : n, s] = eta[ytimes[1 : n, s]]; #>     ypred[1 : n, s] = normal_rng(mus[1 : n, s], sigma_obs_vec[1 : n, s]); #>   } #> } #>  #>"},{"path":"https://nicholasjclark.github.io/mvgam/reference/GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify dynamic Gaussian processes — GP","title":"Specify dynamic Gaussian processes — GP","text":"Set low-rank approximate Gaussian Process trend models using Hilbert basis expansions mvgam. function evaluate arguments – exists purely help set model particular GP trend models.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify dynamic Gaussian processes — GP","text":"","code":"GP()"},{"path":"https://nicholasjclark.github.io/mvgam/reference/GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify dynamic Gaussian processes — GP","text":"object class mvgam_trend, contains list arguments interpreted parsing functions mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/GP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify dynamic Gaussian processes — GP","text":"GP trend estimated series using Hilbert space approximate Gaussian Processes. mvgam, latent squared exponential GP trends approximated using default 20 basis functions using multiplicative factor c = 5/4, saves computational costs compared fitting full GPs adequately estimating GP alpha rho parameters.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/hindcast.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract hindcasts for a fitted mvgam object — hindcast.mvgam","title":"Extract hindcasts for a fitted mvgam object — hindcast.mvgam","text":"Extract hindcasts fitted mvgam object","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/hindcast.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract hindcasts for a fitted mvgam object — hindcast.mvgam","text":"","code":"hindcast(object, ...)  # S3 method for mvgam hindcast(object, series = \"all\", type = \"response\", ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/hindcast.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract hindcasts for a fitted mvgam object — hindcast.mvgam","text":"object list object returned mvgam. See mvgam() ... Ignored series Either integer specifying series set forecast, character string '', specifying series forecast. preferable fitted model contained multivariate trends (either dynamic factor VAR process), saves recomputing full set trends series individually type value link (default) linear predictor calculated link scale. expected used, predictions reflect expectation response (mean) ignore uncertainty observation process. response used, predictions take uncertainty observation process account return predictions outcome scale. variance used, variance response respect mean (mean-variance relationship) returned. Two special cases also allowed: type latent_N return estimated latent abundances N-mixture distribution, type detection return estimated detection probability N-mixture distribution","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/hindcast.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract hindcasts for a fitted mvgam object — hindcast.mvgam","text":"object class mvgam_forecast containing hindcast distributions. See mvgam_forecast-class details. #'@seealso forecast.mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/hindcast.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract hindcasts for a fitted mvgam object — hindcast.mvgam","text":"Posterior retrodictions drawn fitted mvgam organized convenient format","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/hindcast.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract hindcasts for a fitted mvgam object — hindcast.mvgam","text":"","code":"if (FALSE) { simdat <- sim_mvgam(n_series = 3, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Hindcasts on response scale hc <- hindcast(mod) str(hc) plot(hc, series = 1) plot(hc, series = 2) plot(hc, series = 3)  # Hindcasts as expectations hc <- hindcast(mod, type = 'expected') str(hc) plot(hc, series = 1) plot(hc, series = 2) plot(hc, series = 3)  # Estimated latent trends hc <- hindcast(mod, type = 'trend') str(hc) plot(hc, series = 1) plot(hc, series = 2) plot(hc, series = 3) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/index-mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Index mvgam objects — index-mvgam","title":"Index mvgam objects — index-mvgam","text":"Index mvgam objects","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/index-mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Index mvgam objects — index-mvgam","text":"","code":"# S3 method for mvgam variables(x, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/index-mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Index mvgam objects — index-mvgam","text":"x list object returned mvgam. See mvgam() ... Arguments passed individual methods (applicable).","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"Approximate leave-future-cross-validation fitted mvgam objects","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"","code":"lfo_cv(object, ...)  # S3 method for mvgam lfo_cv(object, data, min_t, fc_horizon = 1, pareto_k_threshold = 0.7, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"object list object returned mvgam. See mvgam() ... Ignored data dataframe list containing model response variable covariates required GAM formula. include columns: 'series' (character factor index series IDs) 'time' (numeric index time point observation). variables included linear predictor formula must also present min_t Integer specifying minimum training time required making predictions data. Default either 30, whatever training time allows least 10 lfo-cv calculations (.e. pmin(max(data$time) - 10, 30)) fc_horizon Integer specifying number time steps ahead evaluating forecasts pareto_k_threshold Proportion specifying threshold Pareto shape parameter considered unstable, triggering model refit. Default 0.7","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"list class mvgam_lfo containing approximate ELPD scores, Pareto-k shape values 'specified pareto_k_threshold","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"Approximate leave-future-cross-validation uses expanding training window scheme evaluate model forecasting ability. steps used function mirror laid lfo vignette loo package, written Paul Bürkner, Jonah Gabry, Aki Vehtari. First, refit model using first min_t observations perform single exact fc_horizon-ahead forecast step. forecast evaluated min_t + fc_horizon sample observations using Expected Log Predictive Density (ELPD). Next, approximate successive round expanding window forecasts moving forward one step time 1:N_evaluations re-weighting draws model's posterior predictive distribution using Pareto Smoothed Importance Sampling (PSIS). iteration , PSIS weights obtained next observation included model re-fit (.e. last observation training data, min_t + ). importance ratios stable, consider approximation adequate use re-weighted posterior's forecast evaluating next holdout set testing observations ((min_t + + 1):(min_t + + fc_horizon)). point importance ratio variability become large importance sampling fail. indicated estimated shape parameter k generalized Pareto distribution crossing certain threshold pareto_k_threshold. refit model using observations time failure. restart process iterate forward next refit triggered (Bürkner et al. 2020).","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"Paul-Christian Bürkner, Jonah Gabry & Aki Vehtari (2020). Approximate leave-future-cross-validation Bayesian time series models Journal Statistical Computation Simulation. 90:14, 2499-2523.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lfo_cv.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Approximate leave-future-out cross-validation of fitted mvgam objects — lfo_cv.mvgam","text":"","code":"if (FALSE) { # Simulate from a Poisson-AR2 model with a seasonal smooth set.seed(100) dat <- sim_mvgam(T = 75,                 n_series = 1,                 prop_trend = 0.75,                 trend_model = 'AR2',                 family = poisson())  # Plot the time series plot_mvgam_series(data = dat$data_train,                  newdata = dat$data_test,                  series = 1)  # Fit an appropriate model mod_ar2 <- mvgam(y ~ s(season, bs = 'cc'),                trend_model = 'AR2',                family = poisson(),                data = dat$data_train,                newdata = dat$data_test)  # Fit a less appropriate model mod_rw <- mvgam(y ~ s(season, bs = 'cc'),               trend_model = 'RW',               family = poisson(),               data = dat$data_train,               newdata = dat$data_test)  # Compare Discrete Ranked Probability Scores for the testing period fc_ar2 <- forecast(mod_ar2) fc_rw <- forecast(mod_rw) score_ar2 <- score(fc_ar2, score = 'drps') score_rw <- score(fc_rw, score = 'drps') sum(score_ar2$series_1$score) sum(score_rw$series_1$score)  # Now use approximate leave-future-out CV to compare # rolling forecasts; start at time point 40 to reduce # computational time and to ensure enough data is available # for estimating model parameters lfo_ar2 <- lfo_cv(mod_ar2,                  min_t = 40,                  fc_horizon = 3) lfo_rw <- lfo_cv(mod_rw,                 min_t = 40,                 fc_horizon = 3)  # Plot Pareto-K values and ELPD estimates plot(lfo_ar2) plot(lfo_rw)  # Proportion of timepoints in which AR2 model gives # better forecasts length(which((lfo_ar2$elpds - lfo_rw$elpds) > 0)) /       length(lfo_ar2$elpds)  # A higher total ELPD is preferred lfo_ar2$sum_ELPD lfo_rw$sum_ELPD }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/logLik.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute pointwise Log-Likelihoods from fitted mvgam objects — logLik.mvgam","title":"Compute pointwise Log-Likelihoods from fitted mvgam objects — logLik.mvgam","text":"Compute pointwise Log-Likelihoods fitted mvgam objects","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/logLik.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute pointwise Log-Likelihoods from fitted mvgam objects — logLik.mvgam","text":"","code":"# S3 method for mvgam logLik(object, linpreds, newdata, family_pars, include_forecast = TRUE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/logLik.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute pointwise Log-Likelihoods from fitted mvgam objects — logLik.mvgam","text":"object list object returned mvgam linpreds Optional matrix linear predictor draws use calculating poitwise log-likelihoods newdata Optional data.frame list object specifying series column linpreds belongs . linpreds supplied, newdata must also supplied family_pars Optional list containing posterior draws family-specific parameters (.e. shape, scale overdispersion parameters). Required linpreds newdata supplied include_forecast Logical. newdata fed model compute forecasts, log-likelihood draws observations also returned. Defaults TRUE ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/logLik.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute pointwise Log-Likelihoods from fitted mvgam objects — logLik.mvgam","text":"matrix dimension n_samples x n_observations containing pointwise log-likelihood draws observations newdata. newdata supplied, log-likelihood draws returned observations originally fed model (training observations , supplied original model via newdata argument mvgam, testing observations)","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/logLik.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute pointwise Log-Likelihoods from fitted mvgam objects — logLik.mvgam","text":"","code":"if (FALSE) { # Simulate some data and fit a model simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Extract logLikelihood values lls <- logLik(mod) str(lls) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/loo.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"LOO information criteria for mvgam models — loo.mvgam","title":"LOO information criteria for mvgam models — loo.mvgam","text":"Extract LOOIC (leave-one-information criterion) using loo::loo()","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/loo.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LOO information criteria for mvgam models — loo.mvgam","text":"","code":"# S3 method for mvgam loo(x, ...)  # S3 method for mvgam loo_compare(x, ..., model_names = NULL)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/loo.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LOO information criteria for mvgam models — loo.mvgam","text":"x Object class mvgam ... mvgam objects. model_names NULL (default) use model names derived deparsing call. Otherwise use passed values model names.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/loo.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LOO information criteria for mvgam models — loo.mvgam","text":"","code":"if (FALSE) { # Simulate 4 time series with hierarchical seasonality # and independent AR1 dynamic processes set.seed(111) simdat <- sim_mvgam(seasonality = 'hierarchical',                    trend_model = 'AR1',                    family = gaussian())  # Fit a model with shared seasonality mod1 <- mvgam(y ~ s(season, bs = 'cc', k = 6),              data = rbind(simdat$data_train,              simdat$data_test),              family = gaussian()) plot(mod1, type = 'smooths') loo(mod1)  # Now fit a model with hierarchical seasonality mod2 <- update(mod1,               formula = y ~ s(season, bs = 'cc', k = 6) +               s(season, series, bs = 'fs',               xt = list(bs = 'cc'), k = 4)) plot(mod2, type = 'smooths') loo(mod2)  # Now add a AR1 dynamic errors to mod2 mod3 <- update(mod2, trend_model = 'AR1') plot(mod3, type = 'smooths') plot(mod3, type = 'trend') loo(mod3)  # Compare models using LOO loo_compare(mod1, mod2, mod3) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/lv_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate trend correlations based on mvgam latent factor loadings — lv_correlations","title":"Calculate trend correlations based on mvgam latent factor loadings — lv_correlations","text":"function uses samples latent trends series fitted mvgam model calculates correlations among series' trends","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lv_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate trend correlations based on mvgam latent factor loadings — lv_correlations","text":"","code":"lv_correlations(object)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/lv_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate trend correlations based on mvgam latent factor loadings — lv_correlations","text":"object list object returned mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/lv_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate trend correlations based on mvgam latent factor loadings — lv_correlations","text":"list object containing mean posterior correlations full array posterior correlations","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mcmc_plot.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC plots as implemented in bayesplot — mcmc_plot.mvgam","title":"MCMC plots as implemented in bayesplot — mcmc_plot.mvgam","text":"Convenient way call MCMC plotting functions implemented bayesplot package","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mcmc_plot.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC plots as implemented in bayesplot — mcmc_plot.mvgam","text":"","code":"# S3 method for mvgam mcmc_plot(   object,   type = \"intervals\",   variable = NULL,   regex = FALSE,   use_alias = TRUE,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mcmc_plot.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC plots as implemented in bayesplot — mcmc_plot.mvgam","text":"object R object typically class brmsfit type type plot. Supported types (names) hist, dens, hist_by_chain, dens_overlay, violin, intervals, areas, areas_ridges, combo, acf, acf_bar, trace, trace_highlight, scatter, hex, pairs, violin, rhat, rhat_hist, neff, neff_hist nuts_energy. overview various plot types see MCMC-overview. variable Names variables (parameters) plot, given character vector regular expression (regex = TRUE). default, hopefully large selection variables plotted. regex Logical; Indicates whether variable treated regular expressions. Defaults FALSE. use_alias Logical. informative names parameters available (.e. beta coefficients b smoothing parameters rho), replace uninformative names informative alias. Defaults TRUE ... Additional arguments passed plotting functions. See MCMC-overview details.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mcmc_plot.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC plots as implemented in bayesplot — mcmc_plot.mvgam","text":"ggplot object can customized using ggplot2 package.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/mcmc_plot.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC plots as implemented in bayesplot — mcmc_plot.mvgam","text":"","code":"if (FALSE) { simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train) mcmc_plot(mod) mcmc_plot(mod, type = 'neff_hist') mcmc_plot(mod, variable = 'betas', type = 'areas') mcmc_plot(mod, variable = 'trend_params', type = 'combo') }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/model.frame.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract model.frame from a fitted mvgam object — model.frame.mvgam","title":"Extract model.frame from a fitted mvgam object — model.frame.mvgam","text":"Extract model.frame fitted mvgam object","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/model.frame.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract model.frame from a fitted mvgam object — model.frame.mvgam","text":"","code":"# S3 method for mvgam model.frame(formula, trend_effects = FALSE, ...)  # S3 method for mvgam_prefit model.frame(formula, trend_effects = FALSE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/model.frame.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract model.frame from a fitted mvgam object — model.frame.mvgam","text":"formula model formula terms     object R object. trend_effects logical, return model.frame observation model (FALSE) underlying process model (ifTRUE) ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/model.frame.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract model.frame from a fitted mvgam object — model.frame.mvgam","text":"matrix containing fitted model frame","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/model.frame.mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract model.frame from a fitted mvgam object — model.frame.mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":null,"dir":"Reference","previous_headings":"","what":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"Uses constructors package splines2 build monotonically increasing decreasing splines. Details also Wang & Yan (2021).","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"","code":"# S3 method for moi.smooth.spec smooth.construct(object, data, knots)  # S3 method for mod.smooth.spec smooth.construct(object, data, knots)  # S3 method for moi.smooth Predict.matrix(object, data)  # S3 method for mod.smooth Predict.matrix(object, data)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"object smooth specification object, usually generated term s(x, bs = \"moi\", ...) s(x, bs = \"mod\", ...) data list containing just data (including variable) required term,              names corresponding object$term (object$). variable              last element. knots list containing knots supplied basis setup --- order names data.               Can NULL. See details information.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"object class \"moi.smooth\" \"mod.smooth\". addition usual elements smooth class documented smooth.construct, object contain slot called boundary defines endpoints beyond spline begin extrapolating (extrapolation flat due first order penalty placed smooth function)","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"constructor normally called directly, rather used internally mvgam. supplied knots spline placed evenly throughout covariate values term refers: example, fitting 101 data 11 knot spline x knot every 10th (ordered) x value. spline implementation closed-form -spline basis based recursion formula given Ramsay (1988), basis coefficients must constrained either non-negative (monotonically increasing functions) non-positive (monotonically decreasing)  Take note using either monotonic basis, number basis functions k must supplied even integer due manner monotonic basis functions constructed","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"constructor result valid smooth using call gam bam, however resulting functions guaranteed monotonic constraints basis coefficients enforced","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"Wang, Wenjie, Jun Yan. \"Shape-Restricted Regression Splines R Package splines2.\" Journal Data Science 19.3 (2021).  Ramsay, J. O. (1988). Monotone regression splines action. Statistical Science, 3(4), 425--441.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/monotonic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monotonic splines in mvgam — smooth.construct.moi.smooth.spec","text":"","code":"if (FALSE) { # Simulate data from a monotonically increasing function set.seed(123123) x <- runif(80) * 4 - 1 x <- sort(x) f <- exp(4 * x) / (1 + exp(4 * x)) y <- f + rnorm(80) * 0.1 plot(x, y)  # A standard TRPS smooth doesn't capture monotonicity mod_data <- data.frame(y = y, x = x) mod <- gam(y ~ s(x, k = 16),            data = mod_data,            family = gaussian())  library(marginaleffects) plot_predictions(mod,                  by = 'x',                  newdata = data.frame(x = seq(min(x) - 0.5,                                               max(x) + 0.5,                                               length.out = 100)),                  points = 0.5)  # Using the 'moi' basis in mvgam rectifies this mod_data$time <- 1:NROW(mod_data) mod2 <- mvgam(y ~ s(x, bs = 'moi', k = 18),              data = mod_data,              family = gaussian())  plot_predictions(mod2,                  by = 'x',                  newdata = data.frame(x = seq(min(x) - 0.5,                                               max(x) + 0.5,                                               length.out = 100)),                  points = 0.5)  plot(mod2, type = 'smooth', realisations = TRUE)  # 'by' terms that produce a different smooth for each level of the 'by' # factor are also allowed set.seed(123123) x <- runif(80) * 4 - 1 x <- sort(x)  # Two different monotonic smooths, one for each factor level f <- exp(4 * x) / (1 + exp(4 * x)) f2 <- exp(3.5 * x) / (1 + exp(3 * x)) fac <- c(rep('a', 80), rep('b', 80)) y <- c(f + rnorm(80) * 0.1,        f2 + rnorm(80) * 0.2) plot(x, y[1:80]) plot(x, y[81:160])  # Gather all data into a data.frame, including the factor 'by' variable mod_data <- data.frame(y, x, fac = as.factor(fac)) mod_data$time <- 1:NROW(mod_data)  # Fit a model with different smooths per factor level mod <- mvgam(y ~ s(x, bs = 'moi', by = fac, k = 8),              data = mod_data,              family = gaussian())  # Visualise the different monotonic functions plot_predictions(mod, condition = c('x', 'fac', 'fac'),                  points = 0.5) plot(mod, type = 'smooth', realisations = TRUE) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted mvgam object description — mvgam-class","title":"Fitted mvgam object description — mvgam-class","text":"fitted mvgam object returned function mvgam. Run methods(class = \"mvgam\") see overview available methods.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitted mvgam object description — mvgam-class","text":"mvgam object contains following elements: call original observation model formula trend_call trend_formula supplied, original trend model formula returned. Otherwise NULL family character description observation distribution trend_model character description latent trend model trend_map data.frame describing mapping trend states observations, supplied original model. Otherwise NULL drift Logical specifying whether drift term used trend model priors model priors updated defaults, prior dataframe returned. Otherwise NULL model_output MCMC object returned fitting engine. model fitted using Stan, object class stanfit (see stanfit-class details). JAGS used backend, object class runjags (see runjags-class details) model_file character string model file used describe model either Stan JAGS syntax model_data return_model_data set TRUE fitting model, list object containing data objects needed condition model returned. item list described detail top model_file. Otherwise NULL inits return_model_data set TRUE fitting model, initial value functions used initialise MCMC chains returned. Otherwise NULL monitor_pars parameters monitored MCMC sampling returned character vector sp_names character vector specifying names smoothing parameter mgcv_model object class gam containing mgcv version observation model. object used generating linear predictor matrix making predictions new data. coefficients model object contain posterior median coefficients GAM linear predictor, used generating plots smooth functions mvgam currently handle (plots three-dimensional smooths). model therefore used inference. See gamObject details trend_mgcv_model trend_formula supplied, object class gam containing mgcv version trend model. Otherwise NULL ytimes matrix object used model fitting indexing series timepoints observed row supplied data. Used internally downstream plotting prediction functions resids named list object containing posterior draws Dunn-Smyth randomized quantile residuals use_lv Logical flag indicating whether latent dynamic factors used model n_lv use_lv == TRUE, number latent dynamic factors used model upper_bounds bounds supplied original model fit, returned. Otherwise NULL obs_data original data object (either list dataframe) supplied model fitting. test_data test data supplied (argument newdata original model), returned. Othwerise NULL fit_engine Character describing fit engine, either stan jags backend Character describing backend used modelling, either rstan, cmdstanr rjags algorithm Character describing algorithm used finding posterior, either sampling, laplace, pathfinder, meanfield fullrank max_treedepth model fitted using Stan, value supplied maximum treedepth tuning parameter returned (see stan details). Otherwise NULL adapt_delta model fitted using Stan, value supplied adapt_delta tuning parameter returned (see stan details). Otherwise NULL","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitted mvgam object description — mvgam-class","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"function estimates posterior distribution Generalised Additive Models (GAMs) can include smooth spline functions, specified GAM formula, well latent temporal processes, specified trend_model. modelling options include State-Space representations allow covariates dynamic processes occur latent 'State' level also capturing observation-level effects. Prior specifications flexible explicitly encourage users apply prior distributions actually reflect beliefs. addition, model fits can easily assessed compared posterior predictive checks, forecast comparisons leave-one-/ leave-future-cross-validation.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"","code":"mvgam(   formula,   trend_formula,   knots,   trend_knots,   data,   data_train,   newdata,   data_test,   run_model = TRUE,   prior_simulation = FALSE,   return_model_data = FALSE,   family = \"poisson\",   use_lv = FALSE,   n_lv,   trend_map,   trend_model = \"None\",   drift = FALSE,   chains = 4,   burnin = 500,   samples = 500,   thin = 1,   parallel = TRUE,   threads = 1,   priors,   refit = FALSE,   lfo = FALSE,   use_stan = TRUE,   backend = getOption(\"brms.backend\", \"cmdstanr\"),   algorithm = getOption(\"brms.algorithm\", \"sampling\"),   autoformat = TRUE,   save_all_pars = FALSE,   max_treedepth,   adapt_delta,   jags_path,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"formula character string specifying GAM observation model formula. exactly like formula GLM except smooth terms, s(), te(), ti(), t2(), well time-varying dynamic() terms, can added right hand side specify linear predictor depends smooth functions predictors (linear functionals ). nmix() family models, formula used set linear predictor detection probability. Details formula syntax used mvgam can found mvgam_formulae trend_formula optional character string specifying GAM process model formula. supplied, linear predictor modelled latent trends capture process model evolution separately observation model. response variable specified left-hand side formula (.e. valid option ~ season + s(year)). Also note use identifier series formula specify effects vary across time series. Instead use trend. ensure models trend_map supplied still work consistently (.e. allowing effects vary across process models, even time series share underlying process model). feature currently available RW(), AR() VAR() trend models. nmix() family models, trend_formula used set linear predictor underlying latent abundance knots optional list containing user specified knot values used basis construction. bases user simply supplies knots used, must match k value supplied (note number knots always just k). Different terms can use different numbers knots, unless share covariate trend_knots knots , optional list knot values smooth functions within trend_formula data dataframe list containing model response variable covariates required GAM formula optional trend_formula. include columns: series (factor index series IDs;number levels identical number unique series labels (.e. n_series = length(levels(data$series)))) time (numeric integer index time point observation). variables included linear predictor formula must also present data_train Deprecated. Still works place data users recommended use data instead seamless integration R workflows newdata Optional dataframe list test data containing least series time addition variables included linear predictor formula. included, observations variable y set NA fitting model posterior simulations can obtained data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows run_model logical. FALSE, model fitted instead function return model file data / initial values needed fit model outside mvgam prior_simulation logical. TRUE, observations fed model, instead simulations prior distributions returned return_model_data logical. TRUE, list data needed fit model returned, along initial values smooth AR parameters, model fitted. helpful users wish modify model file add stochastic elements currently avaiable mvgam. Default FALSE reduce size returned object, unless run_model == FALSE family family specifying exponential observation family series. Currently supported families : nb() count data poisson() count data gaussian() real-valued data betar() proportional data (0,1) lognormal() non-negative real-valued data student_t() real-valued data Gamma() non-negative real-valued data nmix() count data imperfect detection modeled via State-Space N-Mixture model. latent states Poisson, capturing 'true' latent abundance, observation process Binomial account imperfect detection. See mvgam_families example use family Note nb() poisson() available using JAGS backend. Default poisson(). See mvgam_families details use_lv logical. TRUE, use dynamic factors estimate series' latent trends reduced dimension format. available RW(), AR() GP() trend models. Defaults FALSE n_lv integer number latent dynamic factors use use_lv == TRUE. > n_series. Defaults arbitrarily min(2, floor(n_series / 2)) trend_map Optional data.frame specifying series depend latent trends. Useful allowing multiple series depend latent trend process, different observation processes. supplied, latent factor model set setting use_lv = TRUE using mapping set shared trends. Needs column names series trend, integer values trend column state trend series depend . series column single unique entry series data (names perfectly match factor levels series variable data). See examples details trend_model character  function specifying time series dynamics latent trend. Options : None (latent trend component; .e. GAM component contributes linear predictor, observation process source error; similarly estimated gam) 'RW' RW() 'AR1' AR(p = 1) 'AR2' AR(p = 2) 'AR3' AR(p = 3) 'VAR1'  VAR()(available Stan) 'PWlogistic, 'PWlinear' PW() (available Stan) 'GP' GP() (Gaussian Process squared exponential kernel; available Stan) trend types apart GP() PW(), moving average /correlated process error terms can also estimated (example, RW(cor = TRUE) set multivariate Random Walk n_series > 1). See mvgam_trends details drift logical estimate drift parameter latent trend components. Useful latent trend expected broadly follow non-zero slope. available RW() AR() trend models. Note latent trend less stationary, drift parameter can become unidentifiable, especially intercept term included GAM linear predictor (default calling jagam). Drift parameters also likely unidentifiable using dynamic factor models. Therefore defaults FALSE chains integer specifying number parallel chains model. Ignored algorithm %% c('meanfield', 'fullrank', 'pathfinder', 'laplace') burnin integer specifying number warmup iterations Markov chain run tune sampling algorithms. Ignored algorithm %% c('meanfield', 'fullrank', 'pathfinder', 'laplace') samples integer specifying number post-warmup iterations Markov chain run sampling posterior distribution thin Thinning interval monitors.  Ignored algorithm %% c('meanfield', 'fullrank', 'pathfinder', 'laplace') parallel logical specifying whether multiple cores used generating MCMC simulations parallel. TRUE, number cores use min(c(chains, parallel::detectCores() - 1)) threads integer Experimental option use multithreading within-chain parallelisation Stan. recommend use experienced Stan's reduce_sum function slow running model sped means. available using Cmdstan backend priors optional data.frame prior definitions (JAGS Stan syntax). using Stan, can also object class brmsprior (see. prior details). See get_mvgam_priors 'Details' information changing default prior distributions refit Logical indicating whether refit, called using update.mvgam. Users leave FALSE lfo Logical indicating whether part call lfo_cv.mvgam. Returns lighter version model residuals fewer monitored parameters speed post-processing. downstream functions work properly, users always leave set FALSE use_stan Logical. TRUE, model compiled sampled using Hamiltonian Monte Carlo call cmdstan_model call stan. Note many options using Stan vs JAGS backend Character string naming package use backend fitting Stan model (use_stan = TRUE). Options \"cmdstanr\" (default) \"rstan\". Can set globally current R session via \"brms.backend\" option (see options). Details rstan cmdstanr packages available https://mc-stan.org/rstan/ https://mc-stan.org/cmdstanr/, respectively algorithm Character string naming estimation approach use. Options \"sampling\" MCMC (default), \"meanfield\" variational inference factorized normal distributions, \"fullrank\" variational inference multivariate normal distribution, \"laplace\" Laplace approximation (available using cmdstanr backend) \"pathfinder\" pathfinder algorithm (currently available using cmdstanr backend). Can set globally current R session via \"brms.algorithm\" option (see options). Limited testing suggests \"meanfield\" performs best non-MCMC approximations dynamic GAMs, possibly difficulties estimating covariances among many spline parameters latent trend parameters. rigorous testing carried autoformat Logical. Use stanc parser automatically format Stan code check deprecations. Defaults TRUE save_all_pars Logical flag indicate draws variables defined Stan's parameters block saved (default FALSE). max_treedepth positive integer placing cap number simulation steps evaluated iteration use_stan == TRUE. Default 12. Increasing value can sometimes help exploration complex posterior geometries, rarely fruitful go max_treedepth 14 adapt_delta positive numeric 0 1 defining target average proposal acceptance probability Stan's adaptation period, use_stan == TRUE. Default 0.8. general need change adapt_delta unless see warning message divergent transitions, case can increase adapt_delta default value closer 1 (e.g. 0.95 0.99, 0.99 0.999, etc). step size used numerical integrator function adapt_delta increasing adapt_delta result smaller step size fewer divergences. Increasing adapt_delta typically result slower sampler, always lead robust sampler jags_path Optional character vector specifying path location JAGS executable (.exe) use modelling use_stan == FALSE. missing, path recovered call findjags ... arguments passed Stan. backend = \"rstan\" arguments passed sampling vb. backend = \"cmdstanr\" arguments passed cmdstanr::sample, cmdstanr::variational, cmdstanr::laplace cmdstanr::pathfinder method","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"list object class mvgam containing model output, text representation model file, mgcv model output (easily generating simulations unsampled covariate values), Dunn-Smyth residuals series key information needed functions package. See mvgam-class details. Use methods(class = \"mvgam\") overview available methods.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"Dynamic GAMs useful wish predict future values time series show temporal dependence want rely extrapolating smooth term (can sometimes lead unpredictable unrealistic behaviours). addition, smooths can often try wiggle excessively capture autocorrelation present time series, exacerbates problem forecasting ahead. GAMs naturally viewed Bayesian lens, often must model time series show complex distributional features missing data, parameters mvgam models estimated Bayesian framework using Markov Chain Monte Carlo default. general overview provided primary vignettes: vignette(\"mvgam_overview\") vignette(\"data_in_mvgam\"). full list available vignettes see vignette(package = \"mvgam\") Formula syntax: Details formula syntax used mvgam can found mvgam_formulae. Note possible supply empty formula predictors intercepts observation model (.e. y ~ 0 y ~ -1). case, intercept-observation model set intercept coefficient fixed zero. can handy wish fit pure State-Space models variation dynamic trend controls average expectation, /intercepts non-identifiable (piecewise trends, see examples ) Families link functions: Details families supported mvgam can found mvgam_families. Trend models: Details latent trend models supported mvgam can found mvgam_trends. Priors: jagam model file generated formula modified include latent temporal processes. Default priors intercepts scale parameters generated using practice brms. Prior distributions important model parameters can altered user inspect model sensitivities given priors (see get_mvgam_priors details). Note latent trends estimated link scale choose priors accordingly. However control model specification can accomplished first using mvgam baseline, editing returned model accordingly. model file can edited run outside mvgam setting run_model = FALSE encouraged complex modelling tasks. Note, priors formally checked ensure right syntax respective probabilistic modelling framework, user ensure correct (.e. use dnorm normal densities JAGS, mean precision parameterisation; use normal normal densities Stan, mean standard deviation parameterisation) Random effects: smooth terms using random effect basis (smooth.construct.re.smooth.spec), non-centred parameterisation automatically employed avoid degeneracies common hierarchical models. Note however centred versions may perform better series particularly informative, foray Bayesian modelling, worth building understanding model's assumptions limitations following principled workflow. Also note models parameterised using drop.unused.levels = FALSE jagam ensure predictions can made levels supplied factor variable Observation level parameters: one series included data observation family contains one parameter used, additional observation family parameters (.e. phi nb() sigma gaussian()) estimated independently series. Factor regularisation: using dynamic factor model trends JAGS factor precisions given regularized penalty priors theoretically allow factors dropped model squeezing increasing factors' variances zero. done help protect selecting many latent factors needed capture dependencies data, can often advantageous set n_lv slightly larger number. However larger numbers factors come additional computational costs balanced well. using Stan, factors parameterised fixed variance parameters Residuals: series, randomized quantile (.e. Dunn-Smyth) residuals calculated inspecting model diagnostics fitted model appropriate Dunn-Smyth residuals standard normal distribution autocorrelation evident. particular observation missing, residual calculated comparing independent draws model's posterior distribution Using Stan: mvgam primarily designed use Hamiltonian Monte Carlo parameter estimation via software Stan (using either cmdstanr rstan interface). great advantages using Stan Gibbs / Metropolis Hastings samplers, includes option estimate smooth latent trends via Hilbert space approximate Gaussian Processes. often makes sense ecological series, expect change smoothly. mvgam, latent squared exponential GP trends approximated using default 20 basis functions, saves computational costs compared fitting full GPs adequately estimating GP alpha rho parameters. many advantages Stan JAGS, development package applied Stan. includes planned addition response distributions, plans handle zero-inflation, plans incorporate greater variety trend models. Users strongly encouraged opt Stan JAGS proceeding workflows","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"Nicholas J Clark & Konstans Wells (2020). Dynamic generalised additive models (DGAMs) forecasting discrete ecological time series. Methods Ecology Evolution. 14:3, 771-784.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Bayesian dynamic GAM to a univariate or multivariate set of time series — mvgam","text":"","code":"if (FALSE) { # Simulate a collection of three time series that have shared seasonal dynamics dat <- sim_mvgam(T = 80, n_series = 3, prop_missing = 0.1,                 prop_trend = 0.6)  # Plot key summary statistics for a single series plot_mvgam_series(data = dat$data_train, series = 1)  # Plot all series together plot_mvgam_series(data = dat$data_train, series = 'all')  # Formulate a model using Stan where series share a cyclic smooth for # seasonality and each series has an independent random walk temporal process; # Set run_model = FALSE to inspect the returned objects mod1 <- mvgam(formula = y ~ s(season, bs = 'cc'),              data = dat$data_train,              trend_model = 'RW',              family = 'poisson',              use_stan = TRUE,              run_model = FALSE)  # View the model code in Stan language code(mod1)  # Inspect the data objects needed to condition the model str(mod1$model_data)  # The following code can be used to run the model outside of mvgam; first using rstan model_data <- mod1$model_data library(rstan) fit <- stan(model_code = mod1$model_file,            data = model_data)  # Now using cmdstanr library(cmdstanr) model_data <- mod1$model_data cmd_mod <- cmdstan_model(write_stan_file(mod1$model_file),                         stanc_options = list('canonicalize=deprecations,braces,parentheses')) cmd_mod$print() fit <- cmd_mod$sample(data = model_data,                      chains = 4,                      parallel_chains = 4,                      refresh = 100)  # Now fit the model using mvgam with the Stan backend mod1 <- mvgam(formula = y ~ s(season, bs = 'cc'),               data = dat$data_train,               trend_model = 'RW',               family = poisson(),               use_stan = TRUE)  # Extract the model summary summary(mod1)  # Plot the estimated historical trend and forecast for one series plot(mod1, type = 'trend', series = 1) plot(mod1, type = 'forecast', series = 1)  # Residual diagnostics plot(mod1, type = 'residuals', series = 1) resids <- residuals(mod1) str(resids)  # Compute the forecast using covariate information in data_test fc <- forecast(mod1, newdata = dat$data_test) str(fc) plot(fc)  # Plot the estimated seasonal smooth function plot(mod1, type = 'smooths')  # Plot estimated first derivatives of the smooth plot(mod1, type = 'smooths', derivatives = TRUE)  # Plot partial residuals of the smooth plot(mod1, type = 'smooths', residuals = TRUE)  # Plot posterior realisations for the smooth plot(mod1, type = 'smooths', realisations = TRUE)  # Plot conditional response predictions using marginaleffects plot(conditional_effects(mod1), ask = FALSE) plot_predictions(mod1, condition = 'season', points = 0.5)  # Extract observation model beta coefficient draws as a data.frame beta_draws_df <- as.data.frame(mod1, variable = 'betas') head(beta_draws_df) str(beta_draws_df)  # Investigate model fit loo(mod1)   # Example of supplying a trend_map so that some series can share # latent trend processes sim <- sim_mvgam(n_series = 3) mod_data <- sim$data_train  # Here, we specify only two latent trends; series 1 and 2 share a trend, # while series 3 has it's own unique latent trend trend_map <- data.frame(series = unique(mod_data$series),                        trend = c(1,1,2))  # Fit the model using AR1 trends mod <- mvgam(y ~ s(season, bs = 'cc'),               trend_map = trend_map,               trend_model = 'AR1',               data = mod_data,               return_model_data = TRUE)  # The mapping matrix is now supplied as data to the model in the 'Z' element mod1$model_data$Z code(mod)  # The first two series share an identical latent trend; the third is different plot(mod, type = 'trend', series = 1) plot(mod, type = 'trend', series = 2) plot(mod, type = 'trend', series = 3)  # Example of how to use dynamic coefficients # Simulate a time-varying coefficient for the effect of temperature set.seed(3) N = 200 beta_temp <- vector(length = N) beta_temp[1] <- 0.4 for(i in 2:N){   beta_temp[i] <- rnorm(1, mean = beta_temp[i - 1], sd = 0.025) }  # Simulate a covariate called 'temp' temp <- rnorm(N, sd = 1)  # Simulate the Gaussian observation process out <- rnorm(N, mean = 4 + beta_temp * temp,              sd = 0.5)  # Gather necessary data into a data.frame; split into training / testing data = data.frame(out, temp, time = seq_along(temp)) data_train <- data[1:180,] data_test <- data[181:200,]  # Fit the model using the dynamic() formula helper mod <- mvgam(formula = out ~ dynamic(temp, rho = 8),              family = gaussian(),              data = data_train,              newdata = data_test)  # Inspect the model summary, forecast and time-varying coefficient distribution summary(mod) plot(mod, type = 'smooths') plot(mod, type = 'forecast', newdata = data_test)  # Propagating the smooth term shows how the coefficient is expected to evolve plot_mvgam_smooth(mod, smooth = 1, newdata = data) abline(v = 180, lty = 'dashed', lwd = 2)   # Example showing how to incorporate an offset; simulate some count data # with different means per series set.seed(100) dat <- sim_mvgam(prop_trend = 0, mu = c(0, 2, 2), seasonality = 'hierarchical')  # Add offset terms to the training and testing data dat$data_train$offset <- 0.5 * as.numeric(dat$data_train$series) dat$data_test$offset <- 0.5 * as.numeric(dat$data_test$series)  # Fit a model that includes the offset in the linear predictor as well as # hierarchical seasonal smooths mod <- mvgam(formula = y ~ offset(offset) +               s(series, bs = 're') +               s(season, bs = 'cc') +               s(season, by = series, m = 1, k = 5),              data = dat$data_train,              trend_model = 'None',              use_stan = TRUE)  # Inspect the model file to see the modification to the linear predictor # (eta) mod$model_file  # Forecasts for the first two series will differ in magnitude layout(matrix(1:2, ncol = 2)) plot(mod, type = 'forecast', series = 1, newdata = dat$data_test,      ylim = c(0, 75)) plot(mod, type = 'forecast', series = 2, newdata = dat$data_test,      ylim = c(0, 75)) layout(1)  # Changing the offset for the testing data should lead to changes in # the forecast dat$data_test$offset <- dat$data_test$offset - 2 plot(mod, 'forecast', newdata = dat$data_test)  # Relative Risks can be computed by fixing the offset to the same value # for each series dat$data_test$offset <- rep(1, NROW(dat$data_test)) preds_rr <- predict(mod, type = 'link', newdata = dat$data_test) series1_inds <- which(dat$data_test$series == 'series_1') series2_inds <- which(dat$data_test$series == 'series_2')  # Relative Risks are now more comparable among series layout(matrix(1:2, ncol = 2)) plot(preds_rr[1, series1_inds], type = 'l', col = 'grey75',      ylim = range(preds_rr),      ylab = 'Series1 Relative Risk', xlab = 'Time') for(i in 2:50){  lines(preds_rr[i, series1_inds], col = 'grey75') }  plot(preds_rr[1, series2_inds], type = 'l', col = 'darkred',      ylim = range(preds_rr),      ylab = 'Series2 Relative Risk', xlab = 'Time') for(i in 2:50){  lines(preds_rr[i, series2_inds], col = 'darkred')  } layout(1)  # Example of logistic growth with possible changepoints # Simple logistic growth model dNt = function(r, N, k){    r * N * (k - N) }  # Iterate growth through time Nt = function(r, N, t, k) { for (i in 1:(t - 1)) {   # population at next time step is current population + growth,  # but we introduce several 'shocks' as changepoints  if(i %in% c(5, 15, 25, 41, 45, 60, 80)){    N[i + 1] <- max(1, N[i] + dNt(r + runif(1, -0.1, 0.1),                                  N[i], k))    } else {    N[i + 1] <- max(1, N[i] + dNt(r, N[i], k))    }   }  N }  # Simulate expected values set.seed(11) expected <- Nt(0.004, 2, 100, 30) plot(expected, xlab = 'Time')  # Take Poisson draws y <- rpois(100, expected) plot(y, xlab = 'Time')  # Assemble data into dataframe and model. We set a # fixed carrying capacity of 35 for this example, but note that # this value is not required to be fixed at each timepoint mod_data <- data.frame(y = y,                        time = 1:100,                        cap = 35,                        series = as.factor('series_1')) plot_mvgam_series(data = mod_data)  # The intercept is nonidentifiable when using piecewise # trends because the trend functions have their own offset # parameters 'm'; it is recommended to always drop intercepts # when using these trend models mod <- mvgam(y ~ 0,              trend_model = PW(growth = 'logistic'),              family = poisson(),              data = mod_data) summary(mod)  # Plot the posterior hindcast plot(mod, type = 'forecast')  # View the changepoints with ggplot2 utilities library(ggplot2) mcmc_plot(mod, variable = 'delta_trend',           regex = TRUE) + scale_y_discrete(labels = mod$trend_model$changepoints) + labs(y = 'Potential changepoint',      x = 'Rate change') }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract diagnostic quantities of mvgam models — mvgam_diagnostics","title":"Extract diagnostic quantities of mvgam models — mvgam_diagnostics","text":"Extract quantities can used diagnose sampling behavior algorithms applied Stan back-end mvgam.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract diagnostic quantities of mvgam models — mvgam_diagnostics","text":"","code":"# S3 method for mvgam nuts_params(object, pars = NULL, ...)  # S3 method for mvgam log_posterior(object, ...)  # S3 method for mvgam rhat(x, pars = NULL, ...)  # S3 method for mvgam neff_ratio(object, pars = NULL, ...)  # S3 method for mvgam neff_ratio(object, pars = NULL, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract diagnostic quantities of mvgam models — mvgam_diagnostics","text":"object, x mvgam object. pars optional character vector parameter names. nuts_params NUTS sampler parameter names rather model parameters. pars omitted parameters included. ... Arguments passed individual methods.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract diagnostic quantities of mvgam models — mvgam_diagnostics","text":"exact form output depends method.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract diagnostic quantities of mvgam models — mvgam_diagnostics","text":"details see bayesplot-extractors.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract diagnostic quantities of mvgam models — mvgam_diagnostics","text":"","code":"if (FALSE) { simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train) np <- nuts_params(mod) head(np)  # extract the number of divergence transitions sum(subset(np, Parameter == \"divergent__\")$Value)  head(neff_ratio(mod)) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior draws from fitted mvgam objects — mvgam_draws","title":"Extract posterior draws from fitted mvgam objects — mvgam_draws","text":"Extract posterior draws conventional formats data.frames, matrices, arrays.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior draws from fitted mvgam objects — mvgam_draws","text":"","code":"# S3 method for mvgam as.data.frame(   x,   row.names = NULL,   optional = TRUE,   variable = \"betas\",   use_alias = TRUE,   regex = FALSE,   ... )  # S3 method for mvgam as.matrix(x, variable = \"betas\", regex = FALSE, use_alias = TRUE, ...)  # S3 method for mvgam as.array(x, variable = \"betas\", regex = FALSE, use_alias = TRUE, ...)  # S3 method for mvgam as_draws(   x,   variable = NULL,   regex = FALSE,   inc_warmup = FALSE,   use_alias = TRUE,   ... )  # S3 method for mvgam as_draws_matrix(   x,   variable = NULL,   regex = FALSE,   inc_warmup = FALSE,   use_alias = TRUE,   ... )  # S3 method for mvgam as_draws_df(   x,   variable = NULL,   regex = FALSE,   inc_warmup = FALSE,   use_alias = TRUE,   ... )  # S3 method for mvgam as_draws_array(   x,   variable = NULL,   regex = FALSE,   inc_warmup = FALSE,   use_alias = TRUE,   ... )  # S3 method for mvgam as_draws_list(   x,   variable = NULL,   regex = FALSE,   inc_warmup = FALSE,   use_alias = TRUE,   ... )  # S3 method for mvgam as_draws_rvars(x, variable = NULL, regex = FALSE, inc_warmup = FALSE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior draws from fitted mvgam objects — mvgam_draws","text":"x list object class mvgam row.names Ignored optional Ignored variable character specifying parameters extract. Can either one following options: obs_params (parameters specific observation model, overdispsersions negative binomial models observation error SD gaussian / student-t models) betas (beta coefficients GAM observation model linear predictor; default) smooth_params (smoothing parameters GAM observation model) linpreds (estimated linear predictors whatever link scale used model) trend_params (parameters governing trend dynamics, AR parameters, trend SD parameters Gaussian Process parameters) trend_betas (beta coefficients GAM latent process model linear predictor; available trend_formula supplied original model) trend_smooth_params (process model GAM smoothing parameters; available trend_formula supplied original model) trend_linpreds (process model linear predictors identity scale; available trend_formula supplied original model) can character vector providing variables extract use_alias Logical. informative names parameters available (.e. beta coefficients b smoothing parameters rho), replace uninformative names informative alias. Defaults TRUE regex Logical. using one prespecified options extractions, variable treated (vector ) regular expressions? variable x matching least one regular expressions selected. Defaults FALSE. ... Ignored inc_warmup warmup draws included? Defaults FALSE.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract posterior draws from fitted mvgam objects — mvgam_draws","text":"data.frame, matrix, array containing posterior draws.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract posterior draws from fitted mvgam objects — mvgam_draws","text":"","code":"if (FALSE) { sim <- sim_mvgam(family = Gamma()) mod1 <- mvgam(y ~ s(season, bs = 'cc'),              trend_model = 'AR1',              data = sim$data_train,              family = Gamma()) beta_draws_df <- as.data.frame(mod1, variable = 'betas') head(beta_draws_df) str(beta_draws_df)  beta_draws_mat <- as.matrix(mod1, variable = 'betas') head(beta_draws_mat) str(beta_draws_mat)  shape_pars <- as.matrix(mod1, variable = 'shape', regex = TRUE) head(shape_pars)}"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_families.html","id":null,"dir":"Reference","previous_headings":"","what":"Supported mvgam families — mvgam_families","title":"Supported mvgam families — mvgam_families","text":"Supported mvgam families","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_families.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Supported mvgam families — mvgam_families","text":"","code":"tweedie(link = \"log\")  student_t(link = \"identity\")  nmix(link = \"log\")"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_families.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Supported mvgam families — mvgam_families","text":"link specification family link function. present changed","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_families.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Supported mvgam families — mvgam_families","text":"mvgam currently supports following standard observation families: gaussian identity link, real-valued data poisson log-link, count data Gamma log-link, non-negative real-valued data addition, following extended families mgcv brms packages supported: betar logit-link, proportional data (0,1) nb log-link, count data lognormal identity-link, non-negative real-valued data Finally, mvgam supports three extended families described : tweedie log-link, count data (power parameter p fixed 1.5) student_t() (student) identity-link, real-valued data nmix count data imperfect detection modeled via State-Space N-Mixture model. latent states Poisson (log link), capturing 'true' latent abundance, observation process Binomial account imperfect detection. observation formula models used set linear predictor detection probability (logit link). See example detailed worked explanation nmix() family poisson(), nb(), tweedie() available using JAGS. families, apart tweedie(), supported using Stan. Note currently possible change default link functions mvgam, call change silently ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_families.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Supported mvgam families — mvgam_families","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_families.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Supported mvgam families — mvgam_families","text":"","code":"if (FALSE) { # An N-mixture example using family nmix() # Simulate data from a Poisson-Binomial N-Mixture model # True abundance is predicted by a single nonlinear function of temperature # as well as a nonlinear long-term trend (as a Gaussian Process function) set.seed(123) gamdat <- gamSim(n = 80); N <- NROW(gamdat) abund_linpred <- gamdat$y; temperature <- gamdat$x2 trend <- mvgam:::sim_gp(rnorm(3, 0, 0.1), alpha_gp = 3,                         rho_gp = 16, h = N) true_abund <- floor(10 + abund_linpred + trend)  # Detection probability increases linearly with decreasing rainfall rainfall <- rnorm(N) detect_linpred <- 0.4 + -0.55 * rainfall detect_prob <- plogis(detect_linpred)  # Simulate observed counts obs_abund <- rbinom(N, size = true_abund, prob = detect_prob)  # Plot true and observed time series plot(true_abund,      type = 'l',      ylab = 'Abundance',      xlab = 'Time',      ylim = c(0, max(true_abund)),      bty = 'l',      lwd = 2) lines(obs_abund, col = 'darkred', lwd = 2) title(main = 'True = black; observed = red')  # Gather data into a dataframe suitable for mvgam modelling; # This will require a 'cap' variable specifying the maximum K to marginalise # over when estimating latent abundance (it does NOT have to be a fixed value) model_dat <- data.frame(obs_abund,                         temperature,                         rainfall,                         cap = max(obs_abund) + 20,                         time = 1:N,                         series = as.factor('series1'))  # Training and testing folds data_train <- model_dat %>% dplyr::filter(time <= 74) data_test <- model_dat %>% dplyr::filter(time > 74)  # Fit a model with informative priors on the two intercept parameters # and on the length scale of the GP temporal trend parameter # Note that the 'trend_formula' applies to the latent count process # (a Poisson process with log-link), while the 'formula' applies to the # detection probability (logit link) mod <- mvgam(formula = obs_abund ~ rainfall,              trend_formula = ~ s(temperature, k = 5) +                gp(time, k = 10, c = 5/4, scale = FALSE),              family = nmix(),              data = data_train,              newdata = data_test,              priors = c(prior(std_normal(), class = '(Intercept)'),                         prior(normal(2, 2), class = '(Intercept)_trend'),                         prior(normal(15, 5), class = 'rho_gp_trend(time)')))  # Model summary and diagnostics summary(mod) plot(mod, type = 'residuals')  # Intercept parameters mcmc_plot(mod,           variable = \"Intercept\",           regex = TRUE,           type = 'hist')  # Hindcasts and forecasts of latent abundance (with truth overlain) fc <- forecast(mod, type = 'latent_N') plot(fc); points(true_abund, pch = 16, cex = 0.8)  # Latent abundance predictions are restricted based on 'cap' max(model_dat$cap); range(fc$forecasts[[1]])  # Hindcasts and forecasts of detection probability (with truth overlain) fc <- forecast(mod, type = 'detection') plot(fc); points(detect_prob, pch = 16, cex = 0.8)  # Hindcasts and forecasts of observations # (after accounting for detection error) fc <- forecast(mod, type = 'response') plot(fc)  # Hindcasts and forecasts of response expectations # (with truth overlain) fc <- forecast(object = mod, type = 'expected') plot(fc); points(detect_prob * true_abund, pch = 16, cex = 0.8)  # Plot conditional effects library(ggplot2)  # Effects on true abundance can be visualised using type = 'link' abund_plots <- plot(conditional_effects(mod,                                         type = 'link',                                         effects = c('temperature', 'time')),                     plot = FALSE)  # Effect of temperature on abundance abund_plots[[1]] +   ylab('Latent abundance')  # Long-term trend in abundance abund_plots[[2]] +   ylab('Latent abundance')  # Effect of rainfall on detection probability det_plot <- plot(conditional_effects(mod,                                      type = 'detection',                                      effects = 'rainfall'),                  plot = FALSE) det_plot[[1]] +   ylab('Pr(detection)')  # More targeted plots can use marginaleffects capabilities; # Here visualise how response predictions might change # if we considered different possible 'cap' limits on latent # abundance and different rainfall measurements plot_predictions(mod, condition = list('temperature',                                        cap = c(15, 20, 40),                                        rainfall = c(-1, 1)),                 type = 'response',                 conf_level = 0.5) +  ylab('Observed abundance') +  theme_classic() }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_forecast-class.html","id":null,"dir":"Reference","previous_headings":"","what":"mvgam_forecast object description — mvgam_forecast-class","title":"mvgam_forecast object description — mvgam_forecast-class","text":"mvgam_forecast object returned function hindcast forecast. Run methods(class = \"mvgam_forecast\") see overview available methods.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_forecast-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"mvgam_forecast object description — mvgam_forecast-class","text":"mvgam_forecast object contains following elements: call original observation model formula trend_call trend_formula supplied, original trend model formula returned. Otherwise NULL family character description observation distribution family_pars list containing draws family-specific parameters (.e. shape, scale overdispersion parameters). returned type = link. Otherwise NULL trend_model character description latent trend model drift Logical specifying whether drift term used trend model use_lv Logical flag indicating whether latent dynamic factors used model fit_engine Character describing fit engine, either stan jags type type predictions included (either link, response trend) series_names Names time series, taken levels(data$series) original model fit train_observations list training observation vectors length n_series train_times vector unique training times test_observations forecast function used, list test observation vectors length n_series. Otherwise NULL test_times forecast function used, vector unique validation (testing) times. Otherwise NULL hindcasts list posterior hindcast distributions length n_series. forecasts forecast function used, list posterior forecast distributions length n_series. Otherwise NULL","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_forecast-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"mvgam_forecast object description — mvgam_forecast-class","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_formulae.html","id":null,"dir":"Reference","previous_headings":"","what":"Details of formula specifications in mvgam — mvgam_formulae","title":"Details of formula specifications in mvgam — mvgam_formulae","text":"Details formula specifications mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_formulae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Details of formula specifications in mvgam — mvgam_formulae","text":"mvgam accept observation model formula optional process model formula (via argument trend_formula). Neither formulae can specified lists, contrary accepted behaviour mgcv brms models.  Note possible supply empty formula predictors intercepts observation model (.e. y ~ 0 y ~ -1). case, intercept-observation model set intercept coefficient fixed zero. can handy wish fit pure State-Space models variation dynamic trend controls average expectation, /intercepts non-identifiable.  formulae supplied mvgam exactly like supplied glm except smooth terms, s, te, ti t2, time-varying effects using dynamic, monotonically increasing (using s(x, bs = 'moi')) decreasing splines (using s(x, bs = 'mod'); see smooth.construct.moi.smooth.spec details), well Gaussian Process functions using gp, can added right hand side (. supported mvgam formulae).  details specifying different kinds smooth functions, control behaviours modifying potential complexities / penalties behave, can found extensive documentation mgcv package.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_formulae.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Details of formula specifications in mvgam — mvgam_formulae","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions for mvgam marginaleffects calculations — mvgam_marginaleffects","title":"Helper functions for mvgam marginaleffects calculations — mvgam_marginaleffects","text":"Helper functions mvgam marginaleffects calculations Functions needed working marginaleffects Functions needed getting data / objects insight","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions for mvgam marginaleffects calculations — mvgam_marginaleffects","text":"","code":"# S3 method for mvgam get_coef(model, trend_effects = FALSE, ...)  # S3 method for mvgam set_coef(model, coefs, trend_effects = FALSE, ...)  # S3 method for mvgam get_vcov(model, vcov = NULL, ...)  # S3 method for mvgam get_predict(model, newdata, type = \"response\", process_error = FALSE, ...)  # S3 method for mvgam get_data(x, source = \"environment\", verbose = TRUE, ...)  # S3 method for mvgam_prefit get_data(x, source = \"environment\", verbose = TRUE, ...)  # S3 method for mvgam find_predictors(   x,   effects = c(\"fixed\", \"random\", \"all\"),   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\", \"dispersion\", \"instruments\",     \"correlation\", \"smooth_terms\"),   flatten = FALSE,   verbose = TRUE,   ... )  # S3 method for mvgam_prefit find_predictors(   x,   effects = c(\"fixed\", \"random\", \"all\"),   component = c(\"all\", \"conditional\", \"zi\", \"zero_inflated\", \"dispersion\", \"instruments\",     \"correlation\", \"smooth_terms\"),   flatten = FALSE,   verbose = TRUE,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions for mvgam marginaleffects calculations — mvgam_marginaleffects","text":"model Model object trend_effects logical, extract process model component (applicable trend_formula specified model) ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?slopes documentation non-exhaustive list available arguments. coefs vector coefficients insert model object vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) newdata Grid predictor values evaluate slopes. Warning: Please avoid modifying dataset fitting model calling marginaleffects function. can sometimes lead unexpected results. NULL (default): Unit-level slopes observed value dataset (empirical distribution). dataset retrieved using insight::get_data(), tries extract data environment. may produce unexpected results original data frame altered since fitting model. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, first entry error message used default. process_error logical. TRUE, uncertainty latent process (trend) model incorporated predictions x fitted model. source String, indicating data recovered. source = \"environment\" (default), data recovered environment (e.g. data workspace). option usually fastest way getting data ensures original variables used model fitting returned. Note always current data recovered environment. Hence, data modified model fitting (e.g., variables recoded rows filtered), returned data may longer equal model data. source = \"frame\" (\"mf\"), data taken model frame. transformed variables back-transformed, possible. option returns data even available environment, however, certain edge cases back-transforming original data may fail. source = \"environment\" fails recover data, tries extract data model frame; source = \"frame\" data extracted model frame, data recovered environment. ways returns observations missing data variables used model fitting. verbose Toggle messages warnings. effects model data fixed effects (\"fixed\"), random effects (\"random\") (\"\") returned? applies mixed gee models. component predictor variables, predictor variables conditional model, zero-inflated part model, dispersion term instrumental variables returned? Applies models zero-inflated /dispersion formula, models instrumental variable (called fixed-effects regressions). May abbreviated. Note conditional component also called count mean component, depending model. flatten Logical, TRUE, values returned character vector, list. Duplicated values removed.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_marginaleffects.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper functions for mvgam marginaleffects calculations — mvgam_marginaleffects","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_trends.html","id":null,"dir":"Reference","previous_headings":"","what":"Supported mvgam trend models — mvgam_trends","title":"Supported mvgam trend models — mvgam_trends","text":"Supported mvgam trend models","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_trends.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Supported mvgam trend models — mvgam_trends","text":"mvgam currently supports following dynamic trend models: None (latent trend component; .e. GAM component contributes linear predictor, observation process source error; similarly estimated gam) RW() AR(p = 1, 2, 3) VAR()(available Stan) PW() (piecewise linear logistic trends; available Stan) GP() (Gaussian Process squared exponential kernel; available Stan) types apart GP() PW(), moving average /correlated process error terms can also estimated (example, RW(cor = TRUE) set multivariate Random Walk data contains >1 series). Character strings can also supplied instead various trend functions. full list possible models currently supported : 'RW' 'RWMA' 'RWcor' 'RWMAcor' 'AR1' 'AR1MA' 'AR1cor' 'AR1MAcor' 'AR2' 'AR2MA' 'AR2cor' 'AR2MAcor' 'AR3' 'AR3MA' 'AR3cor' 'AR3MAcor' 'VAR' 'VARcor' 'VAR1' ('VAR') 'VAR1cor' ('VARcor') 'VARMA' 'VARMAcor' 'VARMA1,1cor' 'PWlinear' 'PWlogistic' 'GP' 'None' Note RW, AR1, AR2 AR3 available using JAGS. trend models supported using Stan. Dynamic factor models can used latent factors evolve either RW, AR1-3 GP. VAR models (.e. VAR VARcor models), users can either fix trend error covariances 0 (using VAR) estimate potentially allow contemporaneously correlated errors using VARcor. VAR models, stationarity latent process enforced prior using parameterisation given Heaps (2022). Stationarity enforced using AR1, AR2 AR3 models, though can changed user specifying lower upper bounds autoregressive parameters using functionality get_mvgam_priors priors argument mvgam. Piecewise trends follow formulation popular prophet package produced Facebook, users can allow changepoints control potential flexibility trend. See Taylor Letham (2018) details","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/mvgam_trends.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Supported mvgam trend models — mvgam_trends","text":"Sarah E. Heaps (2022) Enforcing stationarity prior Vector Autoregressions. Journal Computational Graphical Statistics. 32:1, 1-10. Sean J. Taylor Benjamin Letham (2018) Forecasting scale. American Statistician 72.1, 37-45.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/pairs.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a matrix of output plots from a mvgam object — pairs.mvgam","title":"Create a matrix of output plots from a mvgam object — pairs.mvgam","text":"pairs method customized MCMC output.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pairs.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a matrix of output plots from a mvgam object — pairs.mvgam","text":"","code":"# S3 method for mvgam pairs(x, variable = NULL, regex = FALSE, use_alias = TRUE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/pairs.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a matrix of output plots from a mvgam object — pairs.mvgam","text":"x object class mvgam variable Names variables (parameters) plot, given character vector regular expression (regex = TRUE). default, hopefully large selection variables plotted. regex Logical; Indicates whether variable treated regular expressions. Defaults FALSE. use_alias Logical. informative names parameters available (.e. beta coefficients b smoothing parameters rho), replace uninformative names informative alias. Defaults TRUE ... arguments passed mcmc_pairs.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pairs.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a matrix of output plots from a mvgam object — pairs.mvgam","text":"detailed description see mcmc_pairs.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pairs.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a matrix of output plots from a mvgam object — pairs.mvgam","text":"","code":"if (FALSE) { simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train) pairs(mod) pairs(mod, variable = c('ar1', 'sigma'), regex = TRUE) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_fc.html","id":null,"dir":"Reference","previous_headings":"","what":"Forecast from a particle filtered mvgam object — pfilter_mvgam_fc","title":"Forecast from a particle filtered mvgam object — pfilter_mvgam_fc","text":"function generates forecast set particles capture unique proposal current state system modelled mvgam object. covariate timepoint information data_test used generate GAM component forecast, trends run forward time according state space dynamics. forecast weighted ensemble, weights determined particle's proposal likelihood prior recent assimilation step","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_fc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forecast from a particle filtered mvgam object — pfilter_mvgam_fc","text":"","code":"pfilter_mvgam_fc(   file_path = \"pfilter\",   n_cores = 2,   newdata,   data_test,   plot_legend = TRUE,   legend_position = \"topleft\",   ylim,   return_forecasts = FALSE )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_fc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forecast from a particle filtered mvgam object — pfilter_mvgam_fc","text":"file_path character string specifying file path particles saved n_cores integer specifying number cores generating particle forecasts parallel newdata dataframe list test data containing least 'series' time', addition variables included linear predictor formula data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows plot_legend logical stating whether include legend highlight observations used calibration assimilated particle filter legend_position legend location may specified setting x single keyword list \"bottomright\", \"bottom\", \"bottomleft\", \"left\", \"topleft\", \"top\", \"topright\", \"right\" \"center\". places legend inside plot frame given location. ylim Optional vector y-axis limits (min, max). limits used plots return_forecasts logical. TRUE, returned list object contain plots forecasts well forecast objects (matrix dimension n_particles x horizon)","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_fc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forecast from a particle filtered mvgam object — pfilter_mvgam_fc","text":"named list containing functions call base R plots series' forecast. Optionally actual forecasts returned within list separate list matrices","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_init.html","id":null,"dir":"Reference","previous_headings":"","what":"Initiate particles for online filtering from a fitted mvgam object — pfilter_mvgam_init","title":"Initiate particles for online filtering from a fitted mvgam object — pfilter_mvgam_init","text":"function generates set particles captures unique proposal current state system. next observation data_assim assimilated particles weighted proposal's multivariate composite likelihood update model's forecast distribution","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_init.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initiate particles for online filtering from a fitted mvgam object — pfilter_mvgam_init","text":"","code":"pfilter_mvgam_init(   object,   newdata,   data_assim,   n_particles = 1000,   file_path = \"pfilter\",   n_cores = 2 )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_init.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initiate particles for online filtering from a fitted mvgam object — pfilter_mvgam_init","text":"object list object returned mvgam newdata dataframe list test data containing least one observation per series (beyond last observation seen model object) assimilated particle filter. least contain 'series' 'time' one-step ahead horizon, addition variables included linear predictor object data_assim Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows n_particles integer specifying number unique particles generate tracking latent system state file_path character string specifying file path saving initiated particles n_cores integer specifying number cores generating particle forecasts parallel","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_init.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initiate particles for online filtering from a fitted mvgam object — pfilter_mvgam_init","text":"list object length = n_particles containing information parameters current state estimates particle generated saved, along important information original model, .rda object file_path","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_online.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic online particle filtering for assimilating new observations into a fitted mvgam model — pfilter_mvgam_online","title":"Automatic online particle filtering for assimilating new observations into a fitted mvgam model — pfilter_mvgam_online","text":"function operates sequentially new observations data_assim update posterior forecast distribution. wrapper calls pfilter_mvgam_smooth. iteration, next observation assimilated particles weighted proposal's multivariate composite likelihood","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_online.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic online particle filtering for assimilating new observations into a fitted mvgam model — pfilter_mvgam_online","text":"","code":"pfilter_mvgam_online(   newdata,   data_assim,   file_path = \"pfilter\",   threshold = 0.5,   use_resampling = FALSE,   kernel_lambda = 0.25,   n_cores = 1 )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_online.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic online particle filtering for assimilating new observations into a fitted mvgam model — pfilter_mvgam_online","text":"newdata dataframe list test data containing least one observation per series (beyond last observation seen model initialising particles pfilter_mvgam_init previous calls pfilter_mvgam_online. least contain 'series' 'time' one-step ahead horizon, addition variables included linear predictor object data_assim Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows file_path character string specifying file path locating particles threshold proportional numeric specifying Effective Sample Size limit resampling particles triggered (calculated ESS / n_particles) use_resampling == TRUE. 0 1 use_resampling logical specifying whether resampling used ESS falls specified threshold. Default option FALSE, relying instead kernel smoothing maintain particle diversity kernel_lambda proportional numeric specifying strength kernel smoothing use pulling low weight particles toward high likelihood state space. 0 1 n_cores integer specifying number cores generating particle forecasts parallel","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_online.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic online particle filtering for assimilating new observations into a fitted mvgam model — pfilter_mvgam_online","text":"list object length = n_particles containing information parameters current state estimates particle generated saved, along important information original model, .rda object file_path","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_smooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Assimilate new observations into a fitted mvgam model using resampling and kernel smoothing — pfilter_mvgam_smooth","title":"Assimilate new observations into a fitted mvgam model using resampling and kernel smoothing — pfilter_mvgam_smooth","text":"function operates new observation next_assim update posterior forecast distribution. next observation assimilated particle weights updated light recent multivariate composite likelihood. Low weight particles smoothed towards high weight state space using importance sampling, options given using resampling high weight particles Effective Sample Size falls user-specified threshold","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_smooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assimilate new observations into a fitted mvgam model using resampling and kernel smoothing — pfilter_mvgam_smooth","text":"","code":"pfilter_mvgam_smooth(   particles,   mgcv_model,   next_assim,   threshold = 0.25,   n_cores = 1,   use_resampling = FALSE,   kernel_lambda = 0.5 )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_smooth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assimilate new observations into a fitted mvgam model using resampling and kernel smoothing — pfilter_mvgam_smooth","text":"particles list particles run one observation prior observation next_assim mgcv_model gam model returned call link{mvgam} next_assim dataframe test data containing one observation per series (beyond last observation seen model initialising particles pfilter_mvgam_init previous calls pfilter_mvgam_online. least contain 'series' 'time' one-step ahead horizon, addition variables included linear predictor object threshold proportional numeric specifying Effective Sample Size limit resampling particles triggered (calculated ESS / n_particles) use_resampling == TRUE. 0 1 n_cores integer specifying number cores generating particle forecasts parallel use_resampling logical specifying whether resampling used ESS falls specified threshold. Note resampling can result loss original model's diversity GAM beta coefficients, may undesirable consequences forecast distribution. use_resampling TRUE, effort made remedy assigning randomly sampled draws GAM beta coefficients original model's distribution particle. however guarantee loss diversity, especially successive resampling take place. Default option therefore FALSE kernel_lambda proportional numeric specifying strength smoothing use pulling low weight particles toward high likelihood state space. 0 1","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pfilter_mvgam_smooth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assimilate new observations into a fitted mvgam model using resampling and kernel smoothing — pfilter_mvgam_smooth","text":"list object length = n_particles containing information parameters current state estimates particle","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/piecewise_trends.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify piecewise linear or logistic trends — PW","title":"Specify piecewise linear or logistic trends — PW","text":"Set piecewise linear logistic trend models mvgam. functions evaluate arguments – exist purely help set model particular piecewise trend models.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/piecewise_trends.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify piecewise linear or logistic trends — PW","text":"","code":"PW(   n_changepoints = 10,   changepoint_range = 0.8,   changepoint_scale = 0.05,   growth = \"linear\" )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/piecewise_trends.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify piecewise linear or logistic trends — PW","text":"n_changepoints non-negative integer specifying number potential changepoints. Potential changepoints selected uniformly first changepoint_range proportion timepoints data. Default 10 changepoint_range Proportion history data trend changepoints estimated. Defaults 0.8 first 80%. changepoint_scale Parameter modulating flexibility automatic changepoint selection altering scale parameter Laplace distribution. resulting prior double_exponential(0, changepoint_scale). Large values allow many changepoints flexible trend, small values allow changepoints. Default 0.05. growth Character string specifying either 'linear' 'logistic' growth trend. 'logistic', variable labelled cap MUST data specify maximum saturation point trend (see details examples mvgam information). Default 'linear'.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/piecewise_trends.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify piecewise linear or logistic trends — PW","text":"object class mvgam_trend, contains list arguments interpreted parsing functions mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/piecewise_trends.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specify piecewise linear or logistic trends — PW","text":"Offsets intercepts: trend models, offset parameter included trend estimation process. parameter incredibly difficult identify also include intercept observation formula. reason, highly recommended drop intercept formula (.e. y ~ x + 0 y ~ x - 1, x optional predictor terms). Logistic growth cap variable: forecasting growth, often maximum achievable point time series can reach. example, total market size, total population size carrying capacity population dynamics. can advantageous forecast saturate near point predictions sensible. function allows make forecasts using logistic growth trend model, specified carrying capacity. Note capacity need static time, can vary series x timepoint combination necessary. must supply cap value observation data using growth = 'logistic'. observation families use non-identity link function, cap value internally transformed link scale (.e. specified cap log transformed using poisson() nb() family). therefore important specify cap values scale outcome. Note also missing values allowed cap.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/piecewise_trends.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Specify piecewise linear or logistic trends — PW","text":"Taylor, Sean J., Benjamin Letham. \"Forecasting scale.\" American Statistician 72.1 (2018): 37-45.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://nicholasjclark.github.io/mvgam/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Default mvgam plots — plot.mvgam","title":"Default mvgam plots — plot.mvgam","text":"function takes fitted mvgam object produces plots smooth functions, forecasts, trends uncertainty components","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default mvgam plots — plot.mvgam","text":"","code":"# S3 method for mvgam plot(   x,   type = \"residuals\",   series = 1,   residuals = FALSE,   newdata,   data_test,   trend_effects = FALSE,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default mvgam plots — plot.mvgam","text":"x list object returned mvgam. See mvgam() type character specifying type plot return. Options : series, residuals, smooths, re (random effect smooths), pterms (parametric effects), forecast, trend, uncertainty, factors series integer specifying series set plotted. ignored type == 're' residuals logical. TRUE type = 'smooths', posterior quantiles partial residuals added plots 1-D smooths series ribbon rectangles. Partial residuals smooth term median Dunn-Smyth residuals obtained dropping term concerned model, leaving estimates fixed (.e. estimates term plus original median Dunn-Smyth residuals). Note mvgam works Dunn-Smyth residuals working residuals, used mgcv, magnitudes partial residuals different expect plot.gam. Interpretation similar though, partial residuals evenly scattered around smooth function function well estimated newdata Optional dataframe list test data containing least 'series' 'time' addition variables included linear predictor original formula. argument optional plotting sample forecast period observations (type = forecast) required plotting uncertainty components (type = uncertainty). data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows trend_effects logical. TRUE trend_formula used model fitting, terms trend (.e. process) model plotted ... Additional arguments individual plotting function.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default mvgam plots — plot.mvgam","text":"base R plot set plots","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Default mvgam plots — plot.mvgam","text":"plots useful getting overview fitted model estimated random effects smooth functions, individual plotting functions functions marginaleffects package offer far customisation.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Default mvgam plots — plot.mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default mvgam plots — plot.mvgam","text":"","code":"if (FALSE) { # Simulate some time series dat <- sim_mvgam(T = 80, n_series = 3)  # Fit a basic model mod <- mvgam(y ~ s(season, bs = 'cc') + s(series, bs = 're'),             data = dat$data_train,             trend_model = 'RW')  # Plot predictions and residuals for each series plot(mod, type = 'forecast', series = 1) plot(mod, type = 'forecast', series = 2) plot(mod, type = 'forecast', series = 3) plot(mod, type = 'residuals', series = 1) plot(mod, type = 'residuals', series = 2) plot(mod, type = 'residuals', series = 3)  # Plot model effects plot(mod, type = 'smooths') plot(mod, type = 're')  # More flexible plots with marginaleffects utilities plot_predictions(mod, condition = 'season', type = 'link') plot_predictions(mod,                 condition = c('season', 'series', 'series'),                 type = 'link') plot_predictions(mod, condition = 'series', type = 'link')  # When using a State-Space model with predictors on the process # model, set trend_effects = TRUE to visualise process effects mod <- mvgam(y ~ -1,             trend_formula = ~ s(season, bs = 'cc'),             data = dat$data_train,             trend_model = 'RW') plot(mod, type = 'smooths', trend_effects = TRUE)  # But marginaleffects functions work without any modification plot_predictions(mod, condition = 'season', type = 'link')  }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam_lfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Pareto-k and ELPD values from a leave-future-out object — plot.mvgam_lfo","title":"Plot Pareto-k and ELPD values from a leave-future-out object — plot.mvgam_lfo","text":"function takes object class mvgam_lfo create several informative diagnostic plots","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam_lfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Pareto-k and ELPD values from a leave-future-out object — plot.mvgam_lfo","text":"","code":"# S3 method for mvgam_lfo plot(x, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam_lfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Pareto-k and ELPD values from a leave-future-out object — plot.mvgam_lfo","text":"x object class mvgam_lfo ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot.mvgam_lfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Pareto-k and ELPD values from a leave-future-out object — plot.mvgam_lfo","text":"base R plot Pareto-k ELPD values evaluation timepoints. Pareto-k plot, dashed red line indicates specified threshold chosen triggering model refits. ELPD plot, dashed red line indicated bottom 10% quantile ELPD values. Points threshold may represent outliers difficult forecast","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_effects.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Effect plot as implemented in marginaleffects — plot_effects.mvgam","title":"Effect plot as implemented in marginaleffects — plot_effects.mvgam","text":"Convenient way call marginal conditional effect plotting functions implemented marginaleffects package","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_effects.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Effect plot as implemented in marginaleffects — plot_effects.mvgam","text":"","code":"plot_effects(object, ...)  # S3 method for mvgam plot_effects(   object,   condition = NULL,   by = NULL,   newdata = NULL,   type = NULL,   conf_level = 0.95,   wts = NULL,   transform = NULL,   points = 0,   rug = FALSE,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_effects.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Effect plot as implemented in marginaleffects — plot_effects.mvgam","text":"... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. condition Conditional predictions Character vector (max length 3): Names predictors display. Named list (max length 3): List names correspond predictors. List elements can : Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" 1: x-axis. 2: color/shape. 3: facets. Numeric variables positions 2 3 summarized Tukey's five numbers ?stats::fivenum Marginal predictions Character vector (max length 3): Names categorical predictors marginalize across. 1: x-axis. 2: color. 3: facets. newdata newdata NULL, grid determined condition argument. newdata NULL, argument behaves way predictions() function. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. conf_level numeric value 0 1. Confidence level use build confidence interval. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). transform function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. points Number 0 1 controls transparency raw data points. 0 (default) display points. rug TRUE displays tick marks axes mark distribution raw data.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_effects.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Effect plot as implemented in marginaleffects — plot_effects.mvgam","text":"ggplot object can customized using ggplot2 package","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_factors.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent factor summaries for a fitted mvgam object — plot_mvgam_factors","title":"Latent factor summaries for a fitted mvgam object — plot_mvgam_factors","text":"function takes fitted mvgam object returns plots summary statistics latent dynamic factors","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_factors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent factor summaries for a fitted mvgam object — plot_mvgam_factors","text":"","code":"plot_mvgam_factors(object, plot = TRUE)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_factors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent factor summaries for a fitted mvgam object — plot_mvgam_factors","text":"object list object returned mvgam. See mvgam() plot logical specifying whether factors plotted","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_factors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent factor summaries for a fitted mvgam object — plot_mvgam_factors","text":"dataframe factor contributions , optionally, series base R plots","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_factors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent factor summaries for a fitted mvgam object — plot_mvgam_factors","text":"model object estimated using dynamic factors, possible factors contributed estimated trends. due regularisation penalty acts independently factor's Gaussian precision, squeeze un-needed factors white noise process (effectively dropping factor model). function, factor tested null hypothesis white noise calculating sum factor's 2nd derivatives. factor larger contribution larger sum due weaker penalty factor's precision. plot == TRUE, factors also plotted.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_factors.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Latent factor summaries for a fitted mvgam object — plot_mvgam_factors","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_forecasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mvgam posterior predictions for a specified series — plot_mvgam_forecasts","title":"Plot mvgam posterior predictions for a specified series — plot_mvgam_forecasts","text":"Plot mvgam posterior predictions specified series","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_forecasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mvgam posterior predictions for a specified series — plot_mvgam_forecasts","text":"","code":"plot_mvgam_fc(   object,   series = 1,   newdata,   data_test,   realisations = FALSE,   n_realisations = 15,   hide_xlabels = FALSE,   xlab,   ylab,   ylim,   n_cores = 1,   return_forecasts = FALSE,   return_score = FALSE,   ... )  # S3 method for mvgam_forecast plot(   x,   series = 1,   realisations = FALSE,   n_realisations = 15,   hide_xlabels = FALSE,   xlab,   ylab,   ylim,   return_score = FALSE,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_forecasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mvgam posterior predictions for a specified series — plot_mvgam_forecasts","text":"object list object returned mvgam. See mvgam() series integer specifying series set plotted newdata Optional dataframe list test data containing least 'series' 'time' addition variables included linear predictor original formula. included, covariate information newdata used generate forecasts fitted model equations. newdata originally included call mvgam, forecasts already produced generative model simply extracted plotted. However newdata supplied original model call, assumption made newdata supplied comes sequentially data supplied data original model (.e. assume time gap last observation series 1 data first observation series 1 newdata). newdata contains observations column y, observations used compute Discrete Rank Probability Score forecast distribution data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows realisations logical. TRUE, forecast realisations shown spaghetti plot, making easier visualise diversity possible forecasts. FALSE, default, empirical quantiles forecast distribution shown n_realisations integer specifying number posterior realisations plot, realisations = TRUE. Ignored otherwise hide_xlabels logical. TRUE, xlabels printed allow user add custom labels using axis base R xlab label x axis. ylab label y axis. ylim Optional vector y-axis limits (min, max) n_cores integer specifying number cores generating forecasts parallel return_forecasts logical. TRUE, function plot forecast well returning forecast object (matrix dimension n_samples x horizon) return_score logical. TRUE sample test data provided newdata, probabilistic score calculated returned. score used depend observation family fitted model. Discrete families (poisson, negative binomial, tweedie) use Discrete Rank Probability Score. families use Continuous Rank Probability Score. value returned sum scores within sample forecast horizon ... par graphical parameters. x Object class mvgam_forecast","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_forecasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot mvgam posterior predictions for a specified series — plot_mvgam_forecasts","text":"base R graphics plot optional list containing forecast distribution sample probabilistic forecast score","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_forecasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot mvgam posterior predictions for a specified series — plot_mvgam_forecasts","text":"plot_mvgam_fc draws posterior predictions object class mvgam calculates posterior empirical quantiles. plot.mvgam_forecast takes object class mvgam_forecast, forecasts already computed, plots resulting forecast distribution. realisations = FALSE, posterior quantiles plotted along true observed data used train model. Otherwise, spaghetti plot returned show possible forecast paths.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_pterms.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mvgam parametric term partial effects — plot_mvgam_pterms","title":"Plot mvgam parametric term partial effects — plot_mvgam_pterms","text":"function plots posterior empirical quantiles partial effects parametric terms","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_pterms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mvgam parametric term partial effects — plot_mvgam_pterms","text":"","code":"plot_mvgam_pterms(object, trend_effects = FALSE)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_pterms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mvgam parametric term partial effects — plot_mvgam_pterms","text":"object list object returned mvgam. See mvgam() trend_effects logical. TRUE trend_formula used model fitting, terms trend (.e. process) model plotted","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_pterms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot mvgam parametric term partial effects — plot_mvgam_pterms","text":"base R graphics plot","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_pterms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot mvgam parametric term partial effects — plot_mvgam_pterms","text":"Posterior empirical quantiles parametric term's partial effect estimates (link scale) calculated visualised ribbon plots. effects can interpreted partial effect parametric term contributes terms model set 0","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_randomeffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mvgam random effect terms — plot_mvgam_randomeffects","title":"Plot mvgam random effect terms — plot_mvgam_randomeffects","text":"function plots posterior empirical quantiles random effect smooths (bs = re)","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_randomeffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mvgam random effect terms — plot_mvgam_randomeffects","text":"","code":"plot_mvgam_randomeffects(object, trend_effects = FALSE)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_randomeffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mvgam random effect terms — plot_mvgam_randomeffects","text":"object list object returned mvgam. See mvgam() trend_effects logical. TRUE trend_formula used model fitting, terms trend (.e. process) model plotted","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_randomeffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot mvgam random effect terms — plot_mvgam_randomeffects","text":"base R graphics plot","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_randomeffects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot mvgam random effect terms — plot_mvgam_randomeffects","text":"Posterior empirical quantiles random effect coefficient estimates (link scale) calculated visualised ribbon plots. Labels coefficients taken levels original factor variable used specify smooth model's formula","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_resids.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual diagnostics for a fitted mvgam object — plot_mvgam_resids","title":"Residual diagnostics for a fitted mvgam object — plot_mvgam_resids","text":"function takes fitted mvgam object returns various residual diagnostic plots","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_resids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual diagnostics for a fitted mvgam object — plot_mvgam_resids","text":"","code":"plot_mvgam_resids(object, series = 1, newdata, data_test)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_resids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual diagnostics for a fitted mvgam object — plot_mvgam_resids","text":"object list object returned mvgam. See mvgam() series integer specifying series set plotted newdata Optional dataframe list test data containing least 'series', 'y', 'time' addition variables included linear predictor formula. included, covariate information newdata used generate forecasts fitted model equations. newdata originally included call mvgam, forecasts already produced generative model simply extracted used calculate residuals. However newdata supplied original model call, assumption made newdata supplied comes sequentially data supplied data original model (.e. assume time gap last observation series 1 data_train first observation series 1 newdata). data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_resids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual diagnostics for a fitted mvgam object — plot_mvgam_resids","text":"series base R plots","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_resids.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Residual diagnostics for a fitted mvgam object — plot_mvgam_resids","text":"total four base R plots generated examine Dunn-Smyth residuals specified series. Plots include residuals vs fitted values plot, Q-Q plot, two plots check remaining temporal autocorrelation residuals. Note, plots use posterior medians fitted values / residuals, uncertainty represented.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_resids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Residual diagnostics for a fitted mvgam object — plot_mvgam_resids","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_series.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot observed time series used for mvgam modelling — plot_mvgam_series","title":"Plot observed time series used for mvgam modelling — plot_mvgam_series","text":"function takes either fitted mvgam object data_train object produces plots observed time series, ACF, CDF histograms exploratory data analysis","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_series.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot observed time series used for mvgam modelling — plot_mvgam_series","text":"","code":"plot_mvgam_series(   object,   data,   data_train,   newdata,   data_test,   y = \"y\",   lines = TRUE,   series = 1,   n_bins,   log_scale = FALSE )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_series.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot observed time series used for mvgam modelling — plot_mvgam_series","text":"object Optional list object returned mvgam. Either object data_train must supplied. data Optional dataframe list training data containing least 'series' 'time'. Use argument training data gathered correct format mvgam modelling model yet fitted. data_train Deprecated. Still works place data users recommended use data instead seamless integration R workflows newdata Optional dataframe list test data containing least 'series' 'time' forecast horizon, addition variables included linear predictor formula. included, observed values test data compared model's forecast distribution exploring biases model predictions. data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows y Character. name outcome variable supplied data? Defaults 'y' lines Logical. TRUE, line plots used visualising time series. FALSE, points used. series Either integer specifying series set plotted string '', plots series available supplied data n_bins integer specifying number bins use binning observed values plotting histogram. Default use number bins returned call hist base R log_scale logical. series == '', flag used control whether time series plot shown log scale (using log(Y + 1)). can useful visualising many series may different observed ranges. Default FALSE","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_series.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot observed time series used for mvgam modelling — plot_mvgam_series","text":"set base R graphics plots. series integer, plots show observed time series, autocorrelation cumulative distribution functions, histogram series. series == '', set observed time series plots returned series shown plot single focal series highlighted, remaining series shown faint gray lines.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_series.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot observed time series used for mvgam modelling — plot_mvgam_series","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_smooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mvgam smooth terms — plot_mvgam_smooth","title":"Plot mvgam smooth terms — plot_mvgam_smooth","text":"function plots posterior empirical quantiles series-specific smooth term","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_smooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mvgam smooth terms — plot_mvgam_smooth","text":"","code":"plot_mvgam_smooth(   object,   trend_effects = FALSE,   series = 1,   smooth,   residuals = FALSE,   n_resid_bins = 25,   realisations = FALSE,   n_realisations = 15,   derivatives = FALSE,   newdata )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_smooth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mvgam smooth terms — plot_mvgam_smooth","text":"object list object returned mvgam. See mvgam() trend_effects logical. TRUE trend_formula used model fitting, terms trend (.e. process) model plotted series integer specifying series set plotted smooth either character integer specifying smooth term plotted residuals logical. TRUE posterior quantiles partial residuals added plots 1-D smooths series ribbon rectangles. Partial residuals smooth term median Dunn-Smyth residuals obtained dropping term concerned model, leaving estimates fixed (.e. estimates term plus original median Dunn-Smyth residuals). Note mvgam works Dunn-Smyth residuals working residuals, used mgcv, magnitudes partial residuals different expect plot.gam. Interpretation similar though, partial residuals evenly scattered around smooth function function well estimated n_resid_bins integer specifying number bins group covariate plotting partial residuals. Setting argument high can make messy plots difficult interpret, setting low likely mask potentially useful patterns partial residuals. Default 25 realisations logical. TRUE, posterior realisations shown spaghetti plot, making easier visualise diversity possible functions. FALSE, default, empirical quantiles posterior distribution shown n_realisations integer specifying number posterior realisations plot, realisations = TRUE. Ignored otherwise derivatives logical. TRUE, additional plot returned show estimated 1st derivative specified smooth (Note, works univariate smooths) newdata Optional dataframe predicting smooth, containing least 'series' addition variables included linear predictor original model's formula. Note currently supported plotting univariate smooths","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_smooth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot mvgam smooth terms — plot_mvgam_smooth","text":"base R graphics plot","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_smooth.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot mvgam smooth terms — plot_mvgam_smooth","text":"Smooth functions shown empirical quantiles (spaghetti plots) posterior partial expectations across sequence 500 values variable's min max, zeroing effects variables. present, univariate bivariate smooth plots allowed, though note bivariate smooths rely default behaviour plot.gam. nuanced visualisation, supply newdata just predicting gam model","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_trend.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mvgam latent trend for a specified series — plot_mvgam_trend","title":"Plot mvgam latent trend for a specified series — plot_mvgam_trend","text":"Plot mvgam latent trend specified series","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_trend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mvgam latent trend for a specified series — plot_mvgam_trend","text":"","code":"plot_mvgam_trend(   object,   series = 1,   newdata,   data_test,   realisations = FALSE,   n_realisations = 15,   n_cores = 1,   derivatives = FALSE,   hide_xlabels = FALSE,   xlab,   ylab,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_trend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mvgam latent trend for a specified series — plot_mvgam_trend","text":"object list object returned mvgam. See mvgam() series integer specifying series set plotted newdata Optional dataframe list test data containing least 'series' 'time' addition variables included linear predictor original formula. data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows realisations logical. TRUE, posterior trend realisations shown spaghetti plot, making easier visualise diversity possible trend paths. FALSE, default, empirical quantiles posterior distribution shown n_realisations integer specifying number posterior realisations plot, realisations = TRUE. Ignored otherwise n_cores integer specifying number cores generating trend forecasts parallel derivatives logical. TRUE, additional plot returned show estimated 1st derivative estimated trend hide_xlabels logical. TRUE, xlabels printed allow user add custom labels using axis base R. Ignored derivatives = TRUE xlab label x axis. ylab label y axis. ... par graphical parameters.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_uncertainty.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mvgam forecast uncertainty contributions for a specified series — plot_mvgam_uncertainty","title":"Plot mvgam forecast uncertainty contributions for a specified series — plot_mvgam_uncertainty","text":"Plot mvgam forecast uncertainty contributions specified series","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_uncertainty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mvgam forecast uncertainty contributions for a specified series — plot_mvgam_uncertainty","text":"","code":"plot_mvgam_uncertainty(   object,   series = 1,   newdata,   data_test,   legend_position = \"topleft\",   hide_xlabels = FALSE )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/plot_mvgam_uncertainty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mvgam forecast uncertainty contributions for a specified series — plot_mvgam_uncertainty","text":"object list object returned mvgam. See mvgam() series integer specifying series set plotted newdata dataframe list containing least 'series' 'time' forecast horizon, addition variables included linear predictor formula data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows legend_position location may also specified setting x single keyword list: \"none\", \"bottomright\", \"bottom\", \"bottomleft\", \"left\", \"topleft\", \"top\", \"topright\", \"right\" \"center\". places legend inside plot frame given location (\"none\"). hide_xlabels logical. TRUE, xlabels printed allow user add custom labels using axis base R","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/portal_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Portal Project rodent capture survey data — portal_data","title":"Portal Project rodent capture survey data — portal_data","text":"dataset containing timeseries total captures (across control plots) select rodent species Portal Project","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/portal_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Portal Project rodent capture survey data — portal_data","text":"","code":"portal_data"},{"path":"https://nicholasjclark.github.io/mvgam/reference/portal_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Portal Project rodent capture survey data — portal_data","text":"dataframe containing following fields: moon time sampling lunar cycles DM Total captures species Dipodomys merriami Total captures species Dipodomys ordii PP Total captures species Chaetodipus penicillatus OT Total captures species Onychomys torridus year Sampling year month Sampling month mintemp Monthly mean minimum temperature precipitation Monthly mean precipitation ndvi Monthly mean Normalised Difference Vegetation Index","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/portal_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Portal Project rodent capture survey data — portal_data","text":"https://github.com/weecology/PortalData/blob/main/SiteandMethods/Methods.md","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_epred.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Draws from the Expected Value of the Posterior Predictive Distribution — posterior_epred.mvgam","title":"Draws from the Expected Value of the Posterior Predictive Distribution — posterior_epred.mvgam","text":"Compute posterior draws expected value posterior predictive distribution (.e. conditional expectation). Can performed data used fit model (posterior predictive checks) new data. definition, predictions smaller variance posterior predictions performed posterior_predict.mvgam method. uncertainty expected value posterior predictive distribution incorporated draws computed posterior_epred residual error ignored . However, estimated means methods averaged across draws similar.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_epred.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draws from the Expected Value of the Posterior Predictive Distribution — posterior_epred.mvgam","text":"","code":"# S3 method for mvgam posterior_epred(object, newdata, data_test, process_error = TRUE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_epred.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draws from the Expected Value of the Posterior Predictive Distribution — posterior_epred.mvgam","text":"object list object returned mvgam. See mvgam() newdata Optional dataframe list test data containing variables included linear predictor formula. supplied, predictions generated original observations used model fit. data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows process_error Logical. TRUE newdata supplied, expected uncertainty process model accounted using draws latent trend SD parameters. FALSE, uncertainty latent trend component ignored calculating predictions. newdata supplied, draws fitted model's posterior predictive distribution used (always include uncertainty latent trend components) ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_epred.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draws from the Expected Value of the Posterior Predictive Distribution — posterior_epred.mvgam","text":"matrix dimension n_samples x new_obs, n_samples number posterior samples fitted object n_obs number observations newdata","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_epred.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draws from the Expected Value of the Posterior Predictive Distribution — posterior_epred.mvgam","text":"Note types predictions models include trend_formula, uncertainty dynamic trend component can ignored setting process_error = FALSE. However, trend_formula supplied model, predictions component ignored. process_error = TRUE, trend predictions ignore autocorrelation coefficients GP length scale coefficients, ultimately assuming process stationary. method similar types posterior predictions returned brms models using autocorrelated error predictions newdata. function therefore suited posterior simulation GAM components mvgam model, forecasting functions plot_mvgam_fc forecast.mvgam better suited generate h-step ahead forecasts respect temporal dynamics estimated latent trends.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_epred.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draws from the Expected Value of the Posterior Predictive Distribution — posterior_epred.mvgam","text":"","code":"if (FALSE) { # Simulate some data and fit a model simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Compute posterior expectations expectations <- posterior_epred(mod) str(expectations) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_linpred.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior Draws of the Linear Predictor — posterior_linpred.mvgam","title":"Posterior Draws of the Linear Predictor — posterior_linpred.mvgam","text":"Compute posterior draws linear predictor, draws applying link functions transformations. Can performed data used fit model (posterior predictive checks) new data.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_linpred.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior Draws of the Linear Predictor — posterior_linpred.mvgam","text":"","code":"# S3 method for mvgam posterior_linpred(   object,   transform = FALSE,   newdata,   data_test,   process_error = TRUE,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_linpred.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior Draws of the Linear Predictor — posterior_linpred.mvgam","text":"object list object returned mvgam. See mvgam() transform Logical; FALSE (default), draws linear predictor returned. TRUE, draws transformed linear predictor, .e. conditional expectation, returned. newdata Optional dataframe list test data containing variables included linear predictor formula. supplied, predictions generated original observations used model fit. data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows process_error Logical. TRUE newdata supplied, expected uncertainty process model accounted using draws latent trend SD parameters. FALSE, uncertainty latent trend component ignored calculating predictions. newdata supplied, draws fitted model's posterior predictive distribution used (always include uncertainty latent trend components) ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_linpred.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior Draws of the Linear Predictor — posterior_linpred.mvgam","text":"matrix dimension n_samples x new_obs, n_samples number posterior samples fitted object n_obs number observations newdata","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_linpred.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior Draws of the Linear Predictor — posterior_linpred.mvgam","text":"Note types predictions models include trend_formula, uncertainty dynamic trend component can ignored setting process_error = FALSE. However, trend_formula supplied model, predictions component ignored. process_error = TRUE, trend predictions ignore autocorrelation coefficients GP length scale coefficients, ultimately assuming process stationary. method similar types posterior predictions returned brms models using autocorrelated error predictions newdata. function therefore suited posterior simulation GAM components mvgam model, forecasting functions plot_mvgam_fc forecast.mvgam better suited generate h-step ahead forecasts respect temporal dynamics estimated latent trends.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_linpred.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior Draws of the Linear Predictor — posterior_linpred.mvgam","text":"","code":"if (FALSE) { # Simulate some data and fit a model simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Extract linear predictor values linpreds <- posterior_linpred(mod) str(linpreds) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_predict.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Draws from the Posterior Predictive Distribution — posterior_predict.mvgam","title":"Draws from the Posterior Predictive Distribution — posterior_predict.mvgam","text":"Compute posterior draws posterior predictive distribution. Can performed data used fit model (posterior predictive checks) new data. definition, draws higher variance draws expected value posterior predictive distribution computed posterior_epred.mvgam. residual error incorporated posterior_predict. However, estimated means methods averaged across draws similar.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_predict.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draws from the Posterior Predictive Distribution — posterior_predict.mvgam","text":"","code":"# S3 method for mvgam posterior_predict(object, newdata, data_test, process_error = TRUE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_predict.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draws from the Posterior Predictive Distribution — posterior_predict.mvgam","text":"object list object returned mvgam. See mvgam() newdata Optional dataframe list test data containing variables included linear predictor formula. supplied, predictions generated original observations used model fit. data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows process_error Logical. TRUE newdata supplied, expected uncertainty process model accounted using draws latent trend SD parameters. FALSE, uncertainty latent trend component ignored calculating predictions. newdata supplied, draws fitted model's posterior predictive distribution used (always include uncertainty latent trend components) ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_predict.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draws from the Posterior Predictive Distribution — posterior_predict.mvgam","text":"matrix dimension n_samples x new_obs, n_samples number posterior samples fitted object n_obs number observations newdata","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_predict.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draws from the Posterior Predictive Distribution — posterior_predict.mvgam","text":"Note types predictions models include trend_formula, uncertainty dynamic trend component can ignored setting process_error = FALSE. However, trend_formula supplied model, predictions component ignored. process_error = TRUE, trend predictions ignore autocorrelation coefficients GP length scale coefficients, ultimately assuming process stationary. method similar types posterior predictions returned brms models using autocorrelated error predictions newdata. function therefore suited posterior simulation GAM components mvgam model, forecasting functions plot_mvgam_fc forecast.mvgam better suited generate h-step ahead forecasts respect temporal dynamics estimated latent trends.","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/posterior_predict.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draws from the Posterior Predictive Distribution — posterior_predict.mvgam","text":"","code":"if (FALSE) { # Simulate some data and fit a model simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Compute posterior predictions predictions <- posterior_predict(mod) str(predictions) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/ppc.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mvgam posterior predictive checks for a specified series — ppc.mvgam","title":"Plot mvgam posterior predictive checks for a specified series — ppc.mvgam","text":"Plot mvgam posterior predictive checks specified series","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/ppc.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mvgam posterior predictive checks for a specified series — ppc.mvgam","text":"","code":"ppc(object, ...)  # S3 method for mvgam ppc(   object,   newdata,   data_test,   series = 1,   type = \"hist\",   n_bins,   legend_position,   xlab,   ylab,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/ppc.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mvgam posterior predictive checks for a specified series — ppc.mvgam","text":"object list object returned mvgam. See mvgam() ... par graphical parameters. newdata Optional dataframe list test data containing least 'series' 'time' forecast horizon, addition variables included linear predictor formula. included, observed values test data compared model's forecast distribution exploring biases model predictions. Note useful newdata also included fitting original model. data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows series integer specifying series set plotted type character specifying type posterior predictive check calculate plot. Valid options : 'rootogram', 'mean', 'hist', 'density', 'prop_zero', 'pit' 'cdf' n_bins integer specifying number bins use binning observed values plotting rootogram histogram. Default 50 bins rootogram, means >50 unique observed values, bins used prevent overplotting facilitate interpretation. Default histogram use number bins returned call hist base R legend_position location may also specified setting x single keyword list \"bottomright\", \"bottom\", \"bottomleft\", \"left\", \"topleft\", \"top\", \"topright\", \"right\" \"center\". places legend inside plot frame given location. alternatively, use \"none\" hide legend. xlab label x axis. ylab label y axis.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/ppc.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot mvgam posterior predictive checks for a specified series — ppc.mvgam","text":"base R graphics plot showing either posterior rootogram (type == 'rootogram'), predicted vs observed mean series (type == 'mean'), predicted vs observed proportion zeroes series (type == 'prop_zero'),predicted vs observed histogram series (type == 'hist'), kernel density empirical CDF estimates posterior predictions (type == 'density' type == 'cdf') Probability Integral Transform histogram (type == 'pit').","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/ppc.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot mvgam posterior predictive checks for a specified series — ppc.mvgam","text":"Posterior predictions drawn fitted mvgam compared empirical distribution observed data specified series help evaluate model's ability generate unbiased predictions. plots apart 'rootogram', posterior predictions can also compared sample observations long observations included 'data_test' original model fit supplied . Rootograms currently plotted using 'hanging' style","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/ppc.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot mvgam posterior predictive checks for a specified series — ppc.mvgam","text":"","code":"if (FALSE) { # Simulate some smooth effects and fit a model set.seed(0) dat <- mgcv::gamSim(1, n = 200, scale = 2) dat$time <- 1:NROW(dat) mod <- mvgam(y ~ s(x0) + s(x1) + s(x2) + s(x3),             data = dat,             family = gaussian())  # Posterior checks ppc(mod, type = 'hist') ppc(mod, type = 'density') ppc(mod, type = 'cdf') }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/predict.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict from the GAM component of an mvgam model — predict.mvgam","title":"Predict from the GAM component of an mvgam model — predict.mvgam","text":"Predict GAM component mvgam model","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/predict.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict from the GAM component of an mvgam model — predict.mvgam","text":"","code":"# S3 method for mvgam predict(object, newdata, data_test, type = \"link\", process_error = TRUE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/predict.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict from the GAM component of an mvgam model — predict.mvgam","text":"object list object returned mvgam. See mvgam() newdata Optional dataframe list test data containing variables included linear predictor formula. supplied, predictions generated original observations used model fit. data_test Deprecated. Still works place newdata users recommended use newdata instead seamless integration R workflows type value link (default) linear predictor calculated link scale. expected used, predictions reflect expectation response (mean) ignore uncertainty observation process. response used, predictions take uncertainty observation process account return predictions outcome scale. variance used, variance response respect mean (mean-variance relationship) returned. Two special cases also allowed: type latent_N return estimated latent abundances N-mixture distribution, type detection return estimated detection probability N-mixture distribution process_error Logical. TRUE dynamic trend model fit, expected uncertainty process model accounted using draws latent trend SD parameters. FALSE, uncertainty latent trend component ignored calculating predictions ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/predict.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict from the GAM component of an mvgam model — predict.mvgam","text":"matrix dimension n_samples x new_obs, n_samples number posterior samples fitted object n_obs number test observations newdata","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/predict.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict from the GAM component of an mvgam model — predict.mvgam","text":"Note types predictions models include trend_formula, uncertainty dynamic trend component can ignored setting process_error = FALSE. However, trend_formula supplied model, predictions component ignored. process_error = TRUE, trend predictions ignore autocorrelation coefficients GP length scale coefficients, ultimately assuming process stationary. method similar types posterior predictions returned brms models using autocorrelated error predictions newdata. function therefore suited posterior simulation GAM components mvgam model, forecasting functions plot_mvgam_fc forecast.mvgam better suited generate h-step ahead forecasts respect temporal dynamics estimated latent trends.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/print.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for a fitted mvgam object — print.mvgam","title":"Summary for a fitted mvgam object — print.mvgam","text":"function takes fitted mvgam object prints quick summary","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/print.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for a fitted mvgam object — print.mvgam","text":"","code":"# S3 method for mvgam print(x, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/print.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for a fitted mvgam object — print.mvgam","text":"x list object returned mvgam ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/print.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary for a fitted mvgam object — print.mvgam","text":"list printed -screen","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/print.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary for a fitted mvgam object — print.mvgam","text":"brief summary model's call printed","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/print.mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary for a fitted mvgam object — print.mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/residuals.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior draws of mvgam residuals — residuals.mvgam","title":"Posterior draws of mvgam residuals — residuals.mvgam","text":"method extracts posterior draws Dunn-Smyth (randomized quantile) residuals order data supplied model. included additional arguments obtaining summaries computed residuals","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/residuals.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior draws of mvgam residuals — residuals.mvgam","text":"","code":"# S3 method for mvgam residuals(object, summary = TRUE, robust = FALSE, probs = c(0.025, 0.975), ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/residuals.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior draws of mvgam residuals — residuals.mvgam","text":"object object class mvgam summary summary statistics returned instead raw values? Default TRUE.. robust FALSE (default) mean used measure central tendency standard deviation measure variability. TRUE, median median absolute deviation (MAD) applied instead. used summary TRUE. probs percentiles computed quantile function. used summary TRUE. ... arguments passed prepare_predictions control several aspects data validation prediction.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/residuals.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior draws of mvgam residuals — residuals.mvgam","text":"array randomized quantile residual values. summary = FALSE output resembles posterior_epred.mvgam predict.mvgam. summary = TRUE output n_observations x E matrix. number summary statistics E equal 2 +   length(probs): Estimate column contains point estimates (either mean median depending argument robust), Est.Error column contains uncertainty estimates (either standard deviation median absolute deviation depending argument robust). remaining columns starting Q contain quantile estimates specified via argument probs.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/residuals.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior draws of mvgam residuals — residuals.mvgam","text":"method gives residuals Dunn-Smyth (randomized quantile) residuals. observations missing (.e. NA) original data missing values residuals","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/residuals.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior draws of mvgam residuals — residuals.mvgam","text":"","code":"if (FALSE) { # Simulate some data and fit a model simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train)  # Extract posterior residuals resids <- residuals(mod) str(resids) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/RW.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify autoregressive dynamic processes — RW","title":"Specify autoregressive dynamic processes — RW","text":"Set autoregressive autoregressive moving average trend models mvgam. functions evaluate arguments – exist purely help set model particular autoregressive trend models.","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/RW.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify autoregressive dynamic processes — RW","text":"","code":"RW(ma = FALSE, cor = FALSE)  AR(p = 1, ma = FALSE, cor = FALSE)  VAR(ma = FALSE, cor = FALSE)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/RW.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify autoregressive dynamic processes — RW","text":"ma Logical Include moving average terms order 1? Default FALSE. cor Logical Include correlated process errors part multivariate normal process model? TRUE n_series > 1 supplied data, fully structured covariance matrix estimated process errors. Default FALSE. p non-negative integer specifying autoregressive (AR) order. Default 1. currently larger 3","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/RW.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify autoregressive dynamic processes — RW","text":"object class mvgam_trend, contains list arguments interpreted parsing functions mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/score.mvgam_forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute probabilistic forecast scores for mvgam objects — score.mvgam_forecast","title":"Compute probabilistic forecast scores for mvgam objects — score.mvgam_forecast","text":"Compute probabilistic forecast scores mvgam objects","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/score.mvgam_forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute probabilistic forecast scores for mvgam objects — score.mvgam_forecast","text":"","code":"# S3 method for mvgam_forecast score(   object,   score = \"crps\",   log = FALSE,   weights,   interval_width = 0.9,   n_cores = 1,   ... )  score(object, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/score.mvgam_forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute probabilistic forecast scores for mvgam objects — score.mvgam_forecast","text":"object mvgam_forecast object. See forecast.mvgam(). score character specifying type proper scoring rule use evaluation. Options : sis (.e. Scaled Interval Score), energy, variogram, elpd (.e. Expected log pointwise Predictive Density), drps (.e. Discrete Rank Probability Score) crps (Continuous Rank Probability Score). Note choosing elpd, supplied object must forecasts link scale expectations can calculated prior scoring. scores, forecasts supplied response scale (.e. posterior predictions) log logical. forecasts truths logged prior scoring? often appropriate comparing performance models series vary observation ranges weights optional vector weights (length(weights) == n_series) weighting pairwise correlations evaluating variogram score multivariate forecasts. Useful -weighting series larger magnitude observations less interest forecasting. Ignored score != 'variogram' interval_width proportional value [0.05,0.95] defining forecast interval calculating coverage , score = 'sis', calculating interval score n_cores integer specifying number cores calculating scores parallel ... Ignored","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/score.mvgam_forecast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute probabilistic forecast scores for mvgam objects — score.mvgam_forecast","text":"list containing scores interval coverages per forecast horizon. score %% c('drps', 'crps', 'elpd'), list also contain return sum series-level scores per horizon. score %% c('energy','variogram'), series-level scores computed score returned series. scores apart elpd, in_interval column series-level slot binary indicator whether true value within forecast's corresponding posterior empirical quantiles. Intervals calculated using elpd forecasts contain linear predictors","code":""},{"path":[]},{"path":"https://nicholasjclark.github.io/mvgam/reference/score.mvgam_forecast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute probabilistic forecast scores for mvgam objects — score.mvgam_forecast","text":"","code":"if (FALSE) { # Simulate observations for three count-valued time series data <- sim_mvgam() # Fit a dynamic model using 'newdata' to automatically produce forecasts mod <- mvgam(y ~ 1,             trend_model = 'RW',             data = data$data_train,             newdata = data$data_test)  # Extract forecasts into a 'mvgam_forecast' object fc <- forecast(mod)  # Compute Discrete Rank Probability Scores and 0.90 interval coverages fc_scores <- score(fc, score = 'drps') str(fc_scores) }"},{"path":"https://nicholasjclark.github.io/mvgam/reference/series_to_mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"This function converts univariate or multivariate time series (xts or ts objects)\r\nto the format necessary for mvgam — series_to_mvgam","title":"This function converts univariate or multivariate time series (xts or ts objects)\r\nto the format necessary for mvgam — series_to_mvgam","text":"function converts univariate multivariate time series (xts ts objects) format necessary mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/series_to_mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function converts univariate or multivariate time series (xts or ts objects)\r\nto the format necessary for mvgam — series_to_mvgam","text":"","code":"series_to_mvgam(series, freq, train_prop = 0.85)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/series_to_mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function converts univariate or multivariate time series (xts or ts objects)\r\nto the format necessary for mvgam — series_to_mvgam","text":"series xts ts object converted mvgam format freq integer. seasonal frequency series train_prop numeric stating proportion data use training. 0.25 0.95","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/series_to_mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function converts univariate or multivariate time series (xts or ts objects)\r\nto the format necessary for mvgam — series_to_mvgam","text":"list object containing outputs needed mvgam, including 'data_train' 'data_test'","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/series_to_mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function converts univariate or multivariate time series (xts or ts objects)\r\nto the format necessary for mvgam — series_to_mvgam","text":"","code":"# A ts object example data(\"sunspots\") series <- cbind(sunspots, sunspots) colnames(series) <- c('blood', 'bone') head(series) #>      blood bone #> [1,]  58.0 58.0 #> [2,]  62.6 62.6 #> [3,]  70.0 70.0 #> [4,]  55.7 55.7 #> [5,]  85.0 85.0 #> [6,]  83.5 83.5 series_to_mvgam(series, frequency(series), 0.85) #> $data_train #>         y season year                date series time #> 1    58.0      1 1749 1749-01-01 00:00:00  blood    1 #> 2    58.0      1 1749 1749-01-01 00:00:00   bone    1 #> 3    62.6      2 1749 1749-01-31 10:00:00  blood    2 #> 4    62.6      2 1749 1749-01-31 10:00:00   bone    2 #> 5    70.0      3 1749 1749-03-02 20:00:01  blood    3 #> 6    70.0      3 1749 1749-03-02 20:00:01   bone    3 #> 7    55.7      4 1749 1749-04-02 06:00:00  blood    4 #> 8    55.7      4 1749 1749-04-02 06:00:00   bone    4 #> 9    85.0      5 1749 1749-05-02 16:00:00  blood    5 #> 10   85.0      5 1749 1749-05-02 16:00:00   bone    5 #> 11   83.5      6 1749 1749-06-02 02:00:01  blood    6 #> 12   83.5      6 1749 1749-06-02 02:00:01   bone    6 #> 13   94.8      7 1749 1749-07-02 12:00:00  blood    7 #> 14   94.8      7 1749 1749-07-02 12:00:00   bone    7 #> 15   66.3      8 1749 1749-08-01 22:00:00  blood    8 #> 16   66.3      8 1749 1749-08-01 22:00:00   bone    8 #> 17   75.9      9 1749 1749-09-01 08:00:01  blood    9 #> 18   75.9      9 1749 1749-09-01 08:00:01   bone    9 #> 19   75.5     10 1749 1749-10-01 18:00:00  blood   10 #> 20   75.5     10 1749 1749-10-01 18:00:00   bone   10 #> 21  158.6     11 1749 1749-11-01 04:00:00  blood   11 #> 22  158.6     11 1749 1749-11-01 04:00:00   bone   11 #> 23   85.2     12 1749 1749-12-01 14:00:01  blood   12 #> 24   85.2     12 1749 1749-12-01 14:00:01   bone   12 #> 25   73.3      1 1750 1750-01-01 00:00:00  blood   13 #> 26   73.3      1 1750 1750-01-01 00:00:00   bone   13 #> 27   75.9      2 1750 1750-01-31 10:00:00  blood   14 #> 28   75.9      2 1750 1750-01-31 10:00:00   bone   14 #> 29   89.2      3 1750 1750-03-02 20:00:01  blood   15 #> 30   89.2      3 1750 1750-03-02 20:00:01   bone   15 #> 31   88.3      4 1750 1750-04-02 06:00:00  blood   16 #> 32   88.3      4 1750 1750-04-02 06:00:00   bone   16 #> 33   90.0      5 1750 1750-05-02 16:00:00  blood   17 #> 34   90.0      5 1750 1750-05-02 16:00:00   bone   17 #> 35  100.0      6 1750 1750-06-02 02:00:01  blood   18 #> 36  100.0      6 1750 1750-06-02 02:00:01   bone   18 #> 37   85.4      7 1750 1750-07-02 12:00:00  blood   19 #> 38   85.4      7 1750 1750-07-02 12:00:00   bone   19 #> 39  103.0      8 1750 1750-08-01 22:00:00  blood   20 #> 40  103.0      8 1750 1750-08-01 22:00:00   bone   20 #> 41   91.2      9 1750 1750-09-01 08:00:01  blood   21 #> 42   91.2      9 1750 1750-09-01 08:00:01   bone   21 #> 43   65.7     10 1750 1750-10-01 18:00:00  blood   22 #> 44   65.7     10 1750 1750-10-01 18:00:00   bone   22 #> 45   63.3     11 1750 1750-11-01 04:00:00  blood   23 #> 46   63.3     11 1750 1750-11-01 04:00:00   bone   23 #> 47   75.4     12 1750 1750-12-01 14:00:01  blood   24 #> 48   75.4     12 1750 1750-12-01 14:00:01   bone   24 #> 49   70.0      1 1751 1751-01-01 00:00:00  blood   25 #> 50   70.0      1 1751 1751-01-01 00:00:00   bone   25 #> 51   43.5      2 1751 1751-01-31 10:00:00  blood   26 #> 52   43.5      2 1751 1751-01-31 10:00:00   bone   26 #> 53   45.3      3 1751 1751-03-02 20:00:01  blood   27 #> 54   45.3      3 1751 1751-03-02 20:00:01   bone   27 #> 55   56.4      4 1751 1751-04-02 06:00:00  blood   28 #> 56   56.4      4 1751 1751-04-02 06:00:00   bone   28 #> 57   60.7      5 1751 1751-05-02 16:00:00  blood   29 #> 58   60.7      5 1751 1751-05-02 16:00:00   bone   29 #> 59   50.7      6 1751 1751-06-02 02:00:01  blood   30 #> 60   50.7      6 1751 1751-06-02 02:00:01   bone   30 #> 61   66.3      7 1751 1751-07-02 12:00:00  blood   31 #> 62   66.3      7 1751 1751-07-02 12:00:00   bone   31 #> 63   59.8      8 1751 1751-08-01 22:00:00  blood   32 #> 64   59.8      8 1751 1751-08-01 22:00:00   bone   32 #> 65   23.5      9 1751 1751-09-01 08:00:01  blood   33 #> 66   23.5      9 1751 1751-09-01 08:00:01   bone   33 #> 67   23.2     10 1751 1751-10-01 18:00:00  blood   34 #> 68   23.2     10 1751 1751-10-01 18:00:00   bone   34 #> 69   28.5     11 1751 1751-11-01 04:00:00  blood   35 #> 70   28.5     11 1751 1751-11-01 04:00:00   bone   35 #> 71   44.0     12 1751 1751-12-01 14:00:01  blood   36 #> 72   44.0     12 1751 1751-12-01 14:00:01   bone   36 #> 73   35.0      1 1752 1752-01-01 00:00:00  blood   37 #> 74   35.0      1 1752 1752-01-01 00:00:00   bone   37 #> 75   50.0      2 1752 1752-01-31 12:00:00  blood   38 #> 76   50.0      2 1752 1752-01-31 12:00:00   bone   38 #> 77   71.0      3 1752 1752-03-02 00:00:01  blood   39 #> 78   71.0      3 1752 1752-03-02 00:00:01   bone   39 #> 79   59.3      4 1752 1752-04-01 12:00:00  blood   40 #> 80   59.3      4 1752 1752-04-01 12:00:00   bone   40 #> 81   59.7      5 1752 1752-05-02 00:00:00  blood   41 #> 82   59.7      5 1752 1752-05-02 00:00:00   bone   41 #> 83   39.6      6 1752 1752-06-01 12:00:01  blood   42 #> 84   39.6      6 1752 1752-06-01 12:00:01   bone   42 #> 85   78.4      7 1752 1752-07-02 00:00:00  blood   43 #> 86   78.4      7 1752 1752-07-02 00:00:00   bone   43 #> 87   29.3      8 1752 1752-08-01 12:00:00  blood   44 #> 88   29.3      8 1752 1752-08-01 12:00:00   bone   44 #> 89   27.1      9 1752 1752-09-01 00:00:01  blood   45 #> 90   27.1      9 1752 1752-09-01 00:00:01   bone   45 #> 91   46.6     10 1752 1752-10-01 12:00:00  blood   46 #> 92   46.6     10 1752 1752-10-01 12:00:00   bone   46 #> 93   37.6     11 1752 1752-11-01 00:00:00  blood   47 #> 94   37.6     11 1752 1752-11-01 00:00:00   bone   47 #> 95   40.0     12 1752 1752-12-01 12:00:01  blood   48 #> 96   40.0     12 1752 1752-12-01 12:00:01   bone   48 #> 97   44.0      1 1753 1753-01-01 00:00:00  blood   49 #> 98   44.0      1 1753 1753-01-01 00:00:00   bone   49 #> 99   32.0      2 1753 1753-01-31 10:00:00  blood   50 #> 100  32.0      2 1753 1753-01-31 10:00:00   bone   50 #> 101  45.7      3 1753 1753-03-02 20:00:01  blood   51 #> 102  45.7      3 1753 1753-03-02 20:00:01   bone   51 #> 103  38.0      4 1753 1753-04-02 06:00:00  blood   52 #> 104  38.0      4 1753 1753-04-02 06:00:00   bone   52 #> 105  36.0      5 1753 1753-05-02 16:00:00  blood   53 #> 106  36.0      5 1753 1753-05-02 16:00:00   bone   53 #> 107  31.7      6 1753 1753-06-02 02:00:01  blood   54 #> 108  31.7      6 1753 1753-06-02 02:00:01   bone   54 #> 109  22.2      7 1753 1753-07-02 12:00:00  blood   55 #> 110  22.2      7 1753 1753-07-02 12:00:00   bone   55 #> 111  39.0      8 1753 1753-08-01 22:00:00  blood   56 #> 112  39.0      8 1753 1753-08-01 22:00:00   bone   56 #> 113  28.0      9 1753 1753-09-01 08:00:01  blood   57 #> 114  28.0      9 1753 1753-09-01 08:00:01   bone   57 #> 115  25.0     10 1753 1753-10-01 18:00:00  blood   58 #> 116  25.0     10 1753 1753-10-01 18:00:00   bone   58 #> 117  20.0     11 1753 1753-11-01 04:00:00  blood   59 #> 118  20.0     11 1753 1753-11-01 04:00:00   bone   59 #> 119   6.7     12 1753 1753-12-01 14:00:01  blood   60 #> 120   6.7     12 1753 1753-12-01 14:00:01   bone   60 #> 121   0.0      1 1754 1754-01-01 00:00:00  blood   61 #> 122   0.0      1 1754 1754-01-01 00:00:00   bone   61 #> 123   3.0      2 1754 1754-01-31 10:00:00  blood   62 #> 124   3.0      2 1754 1754-01-31 10:00:00   bone   62 #> 125   1.7      3 1754 1754-03-02 20:00:01  blood   63 #> 126   1.7      3 1754 1754-03-02 20:00:01   bone   63 #> 127  13.7      4 1754 1754-04-02 06:00:00  blood   64 #> 128  13.7      4 1754 1754-04-02 06:00:00   bone   64 #> 129  20.7      5 1754 1754-05-02 16:00:00  blood   65 #> 130  20.7      5 1754 1754-05-02 16:00:00   bone   65 #> 131  26.7      6 1754 1754-06-02 02:00:01  blood   66 #> 132  26.7      6 1754 1754-06-02 02:00:01   bone   66 #> 133  18.8      7 1754 1754-07-02 12:00:00  blood   67 #> 134  18.8      7 1754 1754-07-02 12:00:00   bone   67 #> 135  12.3      8 1754 1754-08-01 22:00:00  blood   68 #> 136  12.3      8 1754 1754-08-01 22:00:00   bone   68 #> 137   8.2      9 1754 1754-09-01 08:00:01  blood   69 #> 138   8.2      9 1754 1754-09-01 08:00:01   bone   69 #> 139  24.1     10 1754 1754-10-01 18:00:00  blood   70 #> 140  24.1     10 1754 1754-10-01 18:00:00   bone   70 #> 141  13.2     11 1754 1754-11-01 04:00:00  blood   71 #> 142  13.2     11 1754 1754-11-01 04:00:00   bone   71 #> 143   4.2     12 1754 1754-12-01 14:00:01  blood   72 #> 144   4.2     12 1754 1754-12-01 14:00:01   bone   72 #> 145  10.2      1 1755 1755-01-01 00:00:00  blood   73 #> 146  10.2      1 1755 1755-01-01 00:00:00   bone   73 #> 147  11.2      2 1755 1755-01-31 10:00:00  blood   74 #> 148  11.2      2 1755 1755-01-31 10:00:00   bone   74 #> 149   6.8      3 1755 1755-03-02 20:00:01  blood   75 #> 150   6.8      3 1755 1755-03-02 20:00:01   bone   75 #> 151   6.5      4 1755 1755-04-02 06:00:00  blood   76 #> 152   6.5      4 1755 1755-04-02 06:00:00   bone   76 #> 153   0.0      5 1755 1755-05-02 16:00:00  blood   77 #> 154   0.0      5 1755 1755-05-02 16:00:00   bone   77 #> 155   0.0      6 1755 1755-06-02 02:00:01  blood   78 #> 156   0.0      6 1755 1755-06-02 02:00:01   bone   78 #> 157   8.6      7 1755 1755-07-02 12:00:00  blood   79 #> 158   8.6      7 1755 1755-07-02 12:00:00   bone   79 #> 159   3.2      8 1755 1755-08-01 22:00:00  blood   80 #> 160   3.2      8 1755 1755-08-01 22:00:00   bone   80 #> 161  17.8      9 1755 1755-09-01 08:00:01  blood   81 #> 162  17.8      9 1755 1755-09-01 08:00:01   bone   81 #> 163  23.7     10 1755 1755-10-01 18:00:00  blood   82 #> 164  23.7     10 1755 1755-10-01 18:00:00   bone   82 #> 165   6.8     11 1755 1755-11-01 04:00:00  blood   83 #> 166   6.8     11 1755 1755-11-01 04:00:00   bone   83 #>  [ reached 'max' / getOption(\"max.print\") -- omitted 4628 rows ] #>  #> $data_test #>         y season year                date series time #> 1   136.3     10 1948 1948-10-01 12:00:00  blood 2398 #> 2   136.3     10 1948 1948-10-01 12:00:00   bone 2398 #> 3    95.8     11 1948 1948-11-01 00:00:01  blood 2399 #> 4    95.8     11 1948 1948-11-01 00:00:01   bone 2399 #> 5   138.0     12 1948 1948-12-01 12:00:01  blood 2400 #> 6   138.0     12 1948 1948-12-01 12:00:01   bone 2400 #> 7   119.1      1 1949 1949-01-01 00:00:00  blood 2401 #> 8   119.1      1 1949 1949-01-01 00:00:00   bone 2401 #> 9   182.3      2 1949 1949-01-31 10:00:01  blood 2402 #> 10  182.3      2 1949 1949-01-31 10:00:01   bone 2402 #> 11  157.5      3 1949 1949-03-02 20:00:01  blood 2403 #> 12  157.5      3 1949 1949-03-02 20:00:01   bone 2403 #> 13  147.0      4 1949 1949-04-02 06:00:00  blood 2404 #> 14  147.0      4 1949 1949-04-02 06:00:00   bone 2404 #> 15  106.2      5 1949 1949-05-02 16:00:01  blood 2405 #> 16  106.2      5 1949 1949-05-02 16:00:01   bone 2405 #> 17  121.7      6 1949 1949-06-02 02:00:01  blood 2406 #> 18  121.7      6 1949 1949-06-02 02:00:01   bone 2406 #> 19  125.8      7 1949 1949-07-02 12:00:00  blood 2407 #> 20  125.8      7 1949 1949-07-02 12:00:00   bone 2407 #> 21  123.8      8 1949 1949-08-01 22:00:01  blood 2408 #> 22  123.8      8 1949 1949-08-01 22:00:01   bone 2408 #> 23  145.3      9 1949 1949-09-01 08:00:01  blood 2409 #> 24  145.3      9 1949 1949-09-01 08:00:01   bone 2409 #> 25  131.6     10 1949 1949-10-01 18:00:00  blood 2410 #> 26  131.6     10 1949 1949-10-01 18:00:00   bone 2410 #> 27  143.5     11 1949 1949-11-01 04:00:01  blood 2411 #> 28  143.5     11 1949 1949-11-01 04:00:01   bone 2411 #> 29  117.6     12 1949 1949-12-01 14:00:01  blood 2412 #> 30  117.6     12 1949 1949-12-01 14:00:01   bone 2412 #> 31  101.6      1 1950 1950-01-01 00:00:00  blood 2413 #> 32  101.6      1 1950 1950-01-01 00:00:00   bone 2413 #> 33   94.8      2 1950 1950-01-31 10:00:01  blood 2414 #> 34   94.8      2 1950 1950-01-31 10:00:01   bone 2414 #> 35  109.7      3 1950 1950-03-02 20:00:01  blood 2415 #> 36  109.7      3 1950 1950-03-02 20:00:01   bone 2415 #> 37  113.4      4 1950 1950-04-02 06:00:00  blood 2416 #> 38  113.4      4 1950 1950-04-02 06:00:00   bone 2416 #> 39  106.2      5 1950 1950-05-02 16:00:01  blood 2417 #> 40  106.2      5 1950 1950-05-02 16:00:01   bone 2417 #> 41   83.6      6 1950 1950-06-02 02:00:01  blood 2418 #> 42   83.6      6 1950 1950-06-02 02:00:01   bone 2418 #> 43   91.0      7 1950 1950-07-02 12:00:00  blood 2419 #> 44   91.0      7 1950 1950-07-02 12:00:00   bone 2419 #> 45   85.2      8 1950 1950-08-01 22:00:01  blood 2420 #> 46   85.2      8 1950 1950-08-01 22:00:01   bone 2420 #> 47   51.3      9 1950 1950-09-01 08:00:01  blood 2421 #> 48   51.3      9 1950 1950-09-01 08:00:01   bone 2421 #> 49   61.4     10 1950 1950-10-01 18:00:00  blood 2422 #> 50   61.4     10 1950 1950-10-01 18:00:00   bone 2422 #> 51   54.8     11 1950 1950-11-01 04:00:01  blood 2423 #> 52   54.8     11 1950 1950-11-01 04:00:01   bone 2423 #> 53   54.1     12 1950 1950-12-01 14:00:01  blood 2424 #> 54   54.1     12 1950 1950-12-01 14:00:01   bone 2424 #> 55   59.9      1 1951 1951-01-01 00:00:00  blood 2425 #> 56   59.9      1 1951 1951-01-01 00:00:00   bone 2425 #> 57   59.9      2 1951 1951-01-31 10:00:01  blood 2426 #> 58   59.9      2 1951 1951-01-31 10:00:01   bone 2426 #> 59   59.9      3 1951 1951-03-02 20:00:01  blood 2427 #> 60   59.9      3 1951 1951-03-02 20:00:01   bone 2427 #> 61   92.9      4 1951 1951-04-02 06:00:00  blood 2428 #> 62   92.9      4 1951 1951-04-02 06:00:00   bone 2428 #> 63  108.5      5 1951 1951-05-02 16:00:01  blood 2429 #> 64  108.5      5 1951 1951-05-02 16:00:01   bone 2429 #> 65  100.6      6 1951 1951-06-02 02:00:01  blood 2430 #> 66  100.6      6 1951 1951-06-02 02:00:01   bone 2430 #> 67   61.5      7 1951 1951-07-02 12:00:00  blood 2431 #> 68   61.5      7 1951 1951-07-02 12:00:00   bone 2431 #> 69   61.0      8 1951 1951-08-01 22:00:01  blood 2432 #> 70   61.0      8 1951 1951-08-01 22:00:01   bone 2432 #> 71   83.1      9 1951 1951-09-01 08:00:01  blood 2433 #> 72   83.1      9 1951 1951-09-01 08:00:01   bone 2433 #> 73   51.6     10 1951 1951-10-01 18:00:00  blood 2434 #> 74   51.6     10 1951 1951-10-01 18:00:00   bone 2434 #> 75   52.4     11 1951 1951-11-01 04:00:01  blood 2435 #> 76   52.4     11 1951 1951-11-01 04:00:01   bone 2435 #> 77   45.8     12 1951 1951-12-01 14:00:01  blood 2436 #> 78   45.8     12 1951 1951-12-01 14:00:01   bone 2436 #> 79   40.7      1 1952 1952-01-01 00:00:00  blood 2437 #> 80   40.7      1 1952 1952-01-01 00:00:00   bone 2437 #> 81   22.7      2 1952 1952-01-31 12:00:01  blood 2438 #> 82   22.7      2 1952 1952-01-31 12:00:01   bone 2438 #> 83   22.0      3 1952 1952-03-02 00:00:01  blood 2439 #> 84   22.0      3 1952 1952-03-02 00:00:01   bone 2439 #> 85   29.1      4 1952 1952-04-01 12:00:00  blood 2440 #> 86   29.1      4 1952 1952-04-01 12:00:00   bone 2440 #> 87   23.4      5 1952 1952-05-02 00:00:01  blood 2441 #> 88   23.4      5 1952 1952-05-02 00:00:01   bone 2441 #> 89   36.4      6 1952 1952-06-01 12:00:01  blood 2442 #> 90   36.4      6 1952 1952-06-01 12:00:01   bone 2442 #> 91   39.3      7 1952 1952-07-02 00:00:00  blood 2443 #> 92   39.3      7 1952 1952-07-02 00:00:00   bone 2443 #> 93   54.9      8 1952 1952-08-01 12:00:01  blood 2444 #> 94   54.9      8 1952 1952-08-01 12:00:01   bone 2444 #> 95   28.2      9 1952 1952-09-01 00:00:01  blood 2445 #> 96   28.2      9 1952 1952-09-01 00:00:01   bone 2445 #> 97   23.8     10 1952 1952-10-01 12:00:00  blood 2446 #> 98   23.8     10 1952 1952-10-01 12:00:00   bone 2446 #> 99   22.1     11 1952 1952-11-01 00:00:01  blood 2447 #> 100  22.1     11 1952 1952-11-01 00:00:01   bone 2447 #> 101  34.3     12 1952 1952-12-01 12:00:01  blood 2448 #> 102  34.3     12 1952 1952-12-01 12:00:01   bone 2448 #> 103  26.5      1 1953 1953-01-01 00:00:00  blood 2449 #> 104  26.5      1 1953 1953-01-01 00:00:00   bone 2449 #> 105   3.9      2 1953 1953-01-31 10:00:01  blood 2450 #> 106   3.9      2 1953 1953-01-31 10:00:01   bone 2450 #> 107  10.0      3 1953 1953-03-02 20:00:01  blood 2451 #> 108  10.0      3 1953 1953-03-02 20:00:01   bone 2451 #> 109  27.8      4 1953 1953-04-02 06:00:00  blood 2452 #> 110  27.8      4 1953 1953-04-02 06:00:00   bone 2452 #> 111  12.5      5 1953 1953-05-02 16:00:01  blood 2453 #> 112  12.5      5 1953 1953-05-02 16:00:01   bone 2453 #> 113  21.8      6 1953 1953-06-02 02:00:01  blood 2454 #> 114  21.8      6 1953 1953-06-02 02:00:01   bone 2454 #> 115   8.6      7 1953 1953-07-02 12:00:00  blood 2455 #> 116   8.6      7 1953 1953-07-02 12:00:00   bone 2455 #> 117  23.5      8 1953 1953-08-01 22:00:01  blood 2456 #> 118  23.5      8 1953 1953-08-01 22:00:01   bone 2456 #> 119  19.3      9 1953 1953-09-01 08:00:01  blood 2457 #> 120  19.3      9 1953 1953-09-01 08:00:01   bone 2457 #> 121   8.2     10 1953 1953-10-01 18:00:00  blood 2458 #> 122   8.2     10 1953 1953-10-01 18:00:00   bone 2458 #> 123   1.6     11 1953 1953-11-01 04:00:01  blood 2459 #> 124   1.6     11 1953 1953-11-01 04:00:01   bone 2459 #> 125   2.5     12 1953 1953-12-01 14:00:01  blood 2460 #> 126   2.5     12 1953 1953-12-01 14:00:01   bone 2460 #> 127   0.2      1 1954 1954-01-01 00:00:00  blood 2461 #> 128   0.2      1 1954 1954-01-01 00:00:00   bone 2461 #> 129   0.5      2 1954 1954-01-31 10:00:01  blood 2462 #> 130   0.5      2 1954 1954-01-31 10:00:01   bone 2462 #> 131  10.9      3 1954 1954-03-02 20:00:01  blood 2463 #> 132  10.9      3 1954 1954-03-02 20:00:01   bone 2463 #> 133   1.8      4 1954 1954-04-02 06:00:00  blood 2464 #> 134   1.8      4 1954 1954-04-02 06:00:00   bone 2464 #> 135   0.8      5 1954 1954-05-02 16:00:01  blood 2465 #> 136   0.8      5 1954 1954-05-02 16:00:01   bone 2465 #> 137   0.2      6 1954 1954-06-02 02:00:01  blood 2466 #> 138   0.2      6 1954 1954-06-02 02:00:01   bone 2466 #> 139   4.8      7 1954 1954-07-02 12:00:00  blood 2467 #> 140   4.8      7 1954 1954-07-02 12:00:00   bone 2467 #> 141   8.4      8 1954 1954-08-01 22:00:01  blood 2468 #> 142   8.4      8 1954 1954-08-01 22:00:01   bone 2468 #> 143   1.5      9 1954 1954-09-01 08:00:01  blood 2469 #> 144   1.5      9 1954 1954-09-01 08:00:01   bone 2469 #> 145   7.0     10 1954 1954-10-01 18:00:00  blood 2470 #> 146   7.0     10 1954 1954-10-01 18:00:00   bone 2470 #> 147   9.2     11 1954 1954-11-01 04:00:01  blood 2471 #> 148   9.2     11 1954 1954-11-01 04:00:01   bone 2471 #> 149   7.6     12 1954 1954-12-01 14:00:01  blood 2472 #> 150   7.6     12 1954 1954-12-01 14:00:01   bone 2472 #> 151  23.1      1 1955 1955-01-01 00:00:00  blood 2473 #> 152  23.1      1 1955 1955-01-01 00:00:00   bone 2473 #> 153  20.8      2 1955 1955-01-31 10:00:01  blood 2474 #> 154  20.8      2 1955 1955-01-31 10:00:01   bone 2474 #> 155   4.9      3 1955 1955-03-02 20:00:01  blood 2475 #> 156   4.9      3 1955 1955-03-02 20:00:01   bone 2475 #> 157  11.3      4 1955 1955-04-02 06:00:00  blood 2476 #> 158  11.3      4 1955 1955-04-02 06:00:00   bone 2476 #> 159  28.9      5 1955 1955-05-02 16:00:01  blood 2477 #> 160  28.9      5 1955 1955-05-02 16:00:01   bone 2477 #> 161  31.7      6 1955 1955-06-02 02:00:01  blood 2478 #> 162  31.7      6 1955 1955-06-02 02:00:01   bone 2478 #> 163  26.7      7 1955 1955-07-02 12:00:00  blood 2479 #> 164  26.7      7 1955 1955-07-02 12:00:00   bone 2479 #> 165  40.7      8 1955 1955-08-01 22:00:01  blood 2480 #> 166  40.7      8 1955 1955-08-01 22:00:01   bone 2480 #>  [ reached 'max' / getOption(\"max.print\") -- omitted 680 rows ] #>   # An xts object example library(xts) #> Warning: package ‘xts’ was built under R version 4.3.2 #> Loading required package: zoo #> Warning: package ‘zoo’ was built under R version 4.3.2 #>  #> Attaching package: ‘zoo’ #> The following objects are masked from ‘package:base’: #>  #>     as.Date, as.Date.numeric dates <- seq(as.Date(\"2001-05-01\"), length=30, by=\"quarter\") data  <- cbind(c(gas = rpois(30, cumprod(1+rnorm(30, mean = 0.01, sd = 0.001)))), c(oil = rpois(30, cumprod(1+rnorm(30, mean = 0.01, sd = 0.001))))) series <- xts(x = data, order.by = dates) colnames(series) <- c('gas', 'oil') head(series) #>            gas oil #> 2001-05-01   1   0 #> 2001-08-01   1   5 #> 2001-11-01   0   0 #> 2002-02-01   0   1 #> 2002-05-01   2   1 #> 2002-08-01   0   1 series_to_mvgam(series, freq = 4, train_prop = 0.85) #> $data_train #>    y season year       date series time #> 1  1      2 2001 2001-05-01    gas    1 #> 2  0      2 2001 2001-05-01    oil    1 #> 3  1      3 2001 2001-08-01    gas    2 #> 4  5      3 2001 2001-08-01    oil    2 #> 5  0      4 2001 2001-11-01    gas    3 #> 6  0      4 2001 2001-11-01    oil    3 #> 7  0      1 2002 2002-02-01    gas    4 #> 8  1      1 2002 2002-02-01    oil    4 #> 9  2      2 2002 2002-05-01    gas    5 #> 10 1      2 2002 2002-05-01    oil    5 #> 11 0      3 2002 2002-08-01    gas    6 #> 12 1      3 2002 2002-08-01    oil    6 #> 13 2      4 2002 2002-11-01    gas    7 #> 14 3      4 2002 2002-11-01    oil    7 #> 15 2      1 2003 2003-02-01    gas    8 #> 16 0      1 2003 2003-02-01    oil    8 #> 17 1      2 2003 2003-05-01    gas    9 #> 18 1      2 2003 2003-05-01    oil    9 #> 19 3      3 2003 2003-08-01    gas   10 #> 20 0      3 2003 2003-08-01    oil   10 #> 21 0      4 2003 2003-11-01    gas   11 #> 22 1      4 2003 2003-11-01    oil   11 #> 23 2      1 2004 2004-02-01    gas   12 #> 24 1      1 2004 2004-02-01    oil   12 #> 25 0      2 2004 2004-05-01    gas   13 #> 26 1      2 2004 2004-05-01    oil   13 #> 27 3      3 2004 2004-08-01    gas   14 #> 28 0      3 2004 2004-08-01    oil   14 #> 29 2      4 2004 2004-11-01    gas   15 #> 30 2      4 2004 2004-11-01    oil   15 #> 31 1      1 2005 2005-02-01    gas   16 #> 32 5      1 2005 2005-02-01    oil   16 #> 33 1      2 2005 2005-05-01    gas   17 #> 34 3      2 2005 2005-05-01    oil   17 #> 35 0      3 2005 2005-08-01    gas   18 #> 36 1      3 2005 2005-08-01    oil   18 #> 37 2      4 2005 2005-11-01    gas   19 #> 38 2      4 2005 2005-11-01    oil   19 #> 39 1      1 2006 2006-02-01    gas   20 #> 40 1      1 2006 2006-02-01    oil   20 #> 41 1      2 2006 2006-05-01    gas   21 #> 42 0      2 2006 2006-05-01    oil   21 #> 43 2      3 2006 2006-08-01    gas   22 #> 44 1      3 2006 2006-08-01    oil   22 #> 45 0      4 2006 2006-11-01    gas   23 #> 46 0      4 2006 2006-11-01    oil   23 #> 47 0      1 2007 2007-02-01    gas   24 #> 48 0      1 2007 2007-02-01    oil   24 #> 49 2      2 2007 2007-05-01    gas   25 #> 50 1      2 2007 2007-05-01    oil   25 #>  #> $data_test #>    y season year       date series time #> 1  1      3 2007 2007-08-01    gas   26 #> 2  3      3 2007 2007-08-01    oil   26 #> 3  0      4 2007 2007-11-01    gas   27 #> 4  2      4 2007 2007-11-01    oil   27 #> 5  0      1 2008 2008-02-01    gas   28 #> 6  0      1 2008 2008-02-01    oil   28 #> 7  3      2 2008 2008-05-01    gas   29 #> 8  2      2 2008 2008-05-01    oil   29 #> 9  2      3 2008 2008-08-01    gas   30 #> 10 2      3 2008 2008-08-01    oil   30 #>"},{"path":"https://nicholasjclark.github.io/mvgam/reference/sim_mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a set of discrete time series for mvgam modelling — sim_mvgam","title":"Simulate a set of discrete time series for mvgam modelling — sim_mvgam","text":"function simulates discrete time series data fitting multivariate GAM includes shared seasonality dependence state-space latent dynamic factors. Random dependencies among series, .e. correlations long-term trends, included form correlated loadings latent dynamic factors","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/sim_mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a set of discrete time series for mvgam modelling — sim_mvgam","text":"","code":"sim_mvgam(   T = 100,   n_series = 3,   seasonality = \"shared\",   use_lv = FALSE,   n_lv = 1,   trend_model = \"RW\",   drift = FALSE,   prop_trend = 0.2,   trend_rel,   freq = 12,   family = poisson(),   phi,   shape,   sigma,   nu,   mu,   prop_missing = 0,   prop_train = 0.85 )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/sim_mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a set of discrete time series for mvgam modelling — sim_mvgam","text":"T integer. Number observations (timepoints) n_series integer. Number discrete time series seasonality character. Either shared, meaning series share exact seasonal pattern, hierarchical, meaning global seasonality series' pattern can deviate slightly use_lv logical. TRUE, use dynamic factors estimate series' latent trends reduced dimension format. FALSE, estimate independent latent trends series n_lv integer. Number latent dynamic factors generating series' trends trend_model character specifying time series dynamics latent trend. Options : None (latent trend component; .e. GAM component contributes linear predictor, observation process source error; similarly estimated gam) RW (random walk possible drift) AR1 (possible drift) AR2 (possible drift) AR3 (possible drift) VAR1 (contemporaneously uncorrelated VAR1) VAR1cor (contemporaneously correlated VAR1) GP (Gaussian Process squared exponential kernel) See mvgam_trends details drift logical, simulate drift term trend prop_trend numeric. Relative importance trend series. 0 1 trend_rel Depracated. Use prop_trend instead freq integer. seasonal frequency series family family specifying exponential observation family series. Currently supported families : nb(), poisson(), tweedie(), gaussian(), betar(), lognormal(), student() Gamma() phi vector dispersion parameters series (.e. size Negative Binomial phi Tweedie Beta). length(phi) < n_series, first element phi replicated n_series times. Defaults 5 Negative Binomial Tweedie; 10 Beta shape vector shape parameters series (.e. shape Gamma) length(shape) < n_series, first element shape replicated n_series times. Defaults 10 sigma vector scale parameters series (.e. sd Normal Student-T, log(sd) LogNormal). length(sigma) < n_series, first element sigma replicated n_series times. Defaults 0.5 Normal Student-T; 0.2 Lognormal nu vector degrees freedom parameters series (.e. nu Student-T) length(nu) < n_series, first element nu replicated n_series times. Defaults 3 mu vector location parameters series. length(mu) < n_series, first element mu replicated n_series times. Defaults small random values -0.5 0.5 link scale prop_missing numeric stating proportion observations missing. 0 0.8, inclusive prop_train numeric stating proportion data use training. 0.2 1","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/sim_mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a set of discrete time series for mvgam modelling — sim_mvgam","text":"list object containing outputs needed mvgam, including 'data_train' 'data_test', well additional information simulated seasonality trend dependencies","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/sim_mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a set of discrete time series for mvgam modelling — sim_mvgam","text":"","code":"#Simulate series with observations bounded at 0 and 1 (Beta responses) sim_data <- sim_mvgam(family = betar(), trend_model = 'GP', prop_trend = 0.6) plot_mvgam_series(data = sim_data$data_train, series = 'all')   #Now simulate series with overdispersed discrete observations sim_data <- sim_mvgam(family = nb(), trend_model = 'GP', prop_trend = 0.6, phi = 10) plot_mvgam_series(data = sim_data$data_train, series = 'all')"},{"path":"https://nicholasjclark.github.io/mvgam/reference/summary.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for a fitted mvgam object — summary.mvgam","title":"Summary for a fitted mvgam object — summary.mvgam","text":"functions take fitted mvgam object return various useful summaries","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/summary.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for a fitted mvgam object — summary.mvgam","text":"","code":"# S3 method for mvgam summary(object, include_betas = TRUE, digits = 2, ...)  # S3 method for mvgam_prefit summary(object, ...)  # S3 method for mvgam coef(object, summarise = TRUE, ...)"},{"path":"https://nicholasjclark.github.io/mvgam/reference/summary.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for a fitted mvgam object — summary.mvgam","text":"object list object returned mvgam include_betas Logical. Print summary includes posterior summaries linear predictor beta coefficients (including spline coefficients)? Defaults TRUE use FALSE concise summary digits number significant digits printing summary; defaults 2. ... Ignored summarise logical. Summaries coefficients returned TRUE. Otherwise full posterior distribution returned","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/summary.mvgam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary for a fitted mvgam object — summary.mvgam","text":"summary.mvgam summary.mvgam_prefit, list printed -screen showing summaries model coef.mvgam, either matrix posterior coefficient distributions (summarise == FALSE data.frame coefficient summaries)","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/summary.mvgam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary for a fitted mvgam object — summary.mvgam","text":"summary.mvgam summary.mvgam_prefit return brief summaries model's call, along posterior intervals key parameters model. Note smooths extra penalties null space, summaries rho parameters may include penalty terms number smooths original model formula. Approximate p-values smooth terms also returned, methods used calculation following used mgcv equivalents (see summary.gam details). Estimated Degrees Freedom (edf) smooth terms computed using edf.type = 1 described documentation jagam. Experiments suggest p-values tend conservative might returned equivalent model fit summary.gam using method = 'REML' coef.mvgam returns either summaries full posterior estimates GAM component coefficients","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/summary.mvgam.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary for a fitted mvgam object — summary.mvgam","text":"Nicholas J Clark","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/update.mvgam.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an existing mvgam object — update.mvgam","title":"Update an existing mvgam object — update.mvgam","text":"function allows previously fitted mvgam model updated","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/update.mvgam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an existing mvgam object — update.mvgam","text":"","code":"# S3 method for mvgam update(   object,   formula,   trend_formula,   data,   newdata,   trend_model,   trend_map,   use_lv,   n_lv,   family,   priors,   lfo = FALSE,   ... )"},{"path":"https://nicholasjclark.github.io/mvgam/reference/update.mvgam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an existing mvgam object — update.mvgam","text":"object list object returned mvgam. See mvgam() formula Optional new formula object. Note, mvgam currently support dynamic formula updates removal specific terms - term. updating, entire formula needs supplied trend_formula optional character string specifying GAM process model formula. supplied, linear predictor modelled latent trends capture process model evolution separately observation model. response variable specified left-hand side formula (.e. valid option ~ season + s(year)). Also note use identifier series formula specify effects vary across time series. Instead use trend. ensure models trend_map supplied still work consistently (.e. allowing effects vary across process models, even time series share underlying process model). feature currently available RW(), AR() VAR() trend models. nmix() family models, trend_formula used set linear predictor underlying latent abundance data dataframe list containing model response variable covariates required GAM formula optional trend_formula. include columns: series (factor index series IDs;number levels identical number unique series labels (.e. n_series = length(levels(data$series)))) time (numeric integer index time point observation). variables included linear predictor formula must also present newdata Optional dataframe list test data containing least series time addition variables included linear predictor formula. included, observations variable y set NA fitting model posterior simulations can obtained trend_model character  function specifying time series dynamics latent trend. Options : None (latent trend component; .e. GAM component contributes linear predictor, observation process source error; similarly estimated gam) 'RW' RW() 'AR1' AR(p = 1) 'AR2' AR(p = 2) 'AR3' AR(p = 3) 'VAR1'  VAR()(available Stan) 'PWlogistic, 'PWlinear' PW() (available Stan) 'GP' GP() (Gaussian Process squared exponential kernel; available Stan) trend types apart GP() PW(), moving average /correlated process error terms can also estimated (example, RW(cor = TRUE) set multivariate Random Walk n_series > 1). See mvgam_trends details trend_map Optional data.frame specifying series depend latent trends. Useful allowing multiple series depend latent trend process, different observation processes. supplied, latent factor model set setting use_lv = TRUE using mapping set shared trends. Needs column names series trend, integer values trend column state trend series depend . series column single unique entry series data (names perfectly match factor levels series variable data). See examples details use_lv logical. TRUE, use dynamic factors estimate series' latent trends reduced dimension format. available RW(), AR() GP() trend models. Defaults FALSE n_lv integer number latent dynamic factors use use_lv == TRUE. > n_series. Defaults arbitrarily min(2, floor(n_series / 2)) family family specifying exponential observation family series. Currently supported families : nb() count data poisson() count data gaussian() real-valued data betar() proportional data (0,1) lognormal() non-negative real-valued data student_t() real-valued data Gamma() non-negative real-valued data nmix() count data imperfect detection modeled via State-Space N-Mixture model. latent states Poisson, capturing 'true' latent abundance, observation process Binomial account imperfect detection. See mvgam_families example use family Note nb() poisson() available using JAGS backend. Default poisson(). See mvgam_families details priors optional data.frame prior definitions (JAGS Stan syntax). using Stan, can also object class brmsprior (see. prior details). See get_mvgam_priors 'Details' information changing default prior distributions lfo Logical indicating whether part call lfo_cv.mvgam. Returns lighter version model residuals fewer monitored parameters speed post-processing. downstream functions work properly, users always leave set FALSE ... arguments passed mvgam","code":""},{"path":"https://nicholasjclark.github.io/mvgam/reference/update.mvgam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update an existing mvgam object — update.mvgam","text":"","code":"if (FALSE) { # Simulate some data and fit a Poisson AR1 model simdat <- sim_mvgam(n_series = 1, trend_model = 'AR1') mod <- mvgam(y ~ s(season, bs = 'cc'),             trend_model = 'AR1',             data = simdat$data_train) summary(mod)  # Update to an AR2 model updated_mod <- update(mod, trend_model = 'AR2') summary(updated_mod)  # Now update to a Negative Binomial AR1 updated_mod <- update(mod, family = nb()) summary(updated_mod) }"}]
