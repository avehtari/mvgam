% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lfo_cv.mvgam.R
\name{lfo_cv.mvgam}
\alias{lfo_cv.mvgam}
\alias{lfo_cv}
\title{Approximate leave-future-out cross-validation of fitted \code{mvgam} objects}
\usage{
lfo_cv(object, ...)

\method{lfo_cv}{mvgam}(
  object,
  data,
  min_t,
  fc_horizon = 1,
  pareto_k_threshold = 0.7,
  n_cores = 1,
  ...
)
}
\arguments{
\item{object}{\code{list} object returned from \code{mvgam}. See \code{\link[=mvgam]{mvgam()}}}

\item{...}{Ignored}

\item{data}{A \code{dataframe} or \code{list} containing the model response variable and covariates
required by the GAM \code{formula}. Should include columns:
'series' (character or factor index of the series IDs)
'time' (numeric index of the time point for each observation).
Any other variables to be included in the linear predictor of \code{formula} must also be present}

\item{min_t}{Integer specifying the minimum training time required before making predictions
from the data. Default is either \code{30}, or whatever training time allows for at least
\code{10} lfo-cv calculations (i.e. \code{pmin(max(data$time) - 10, 30)})}

\item{fc_horizon}{Integer specifying the number of time steps ahead for evaluating forecasts}

\item{pareto_k_threshold}{Proportion specifying the threshold over which the Pareto shape parameter
is considered unstable, triggering a model refit. Default is \code{0.7}}

\item{n_cores}{\code{integer} specifying number of cores for calculating likelihoods in parallel}
}
\value{
A \code{list} of class \code{mvgam_lfo} containing the approximate ELPD scores,
the Pareto-k shape values and 'the specified \code{pareto_k_threshold}
}
\description{
Approximate leave-future-out cross-validation of fitted \code{mvgam} objects
}
\details{
Approximate leave-future-out cross-validation uses an expanding training window scheme
to evaluate a model on its forecasting ability. The steps used in this function mirror those laid out
in the \href{https://mc-stan.org/loo/articles/loo2-lfo.html}{lfo vignette from the \code{loo} package},
written by Paul Bürkner, Jonah Gabry, Aki Vehtari. First, we refit the model using the first \code{min_t}
observations to perform a single exact \code{fc_horizon}-ahead forecast step. This forecast is evaluated against
the \code{min_t + fc_horizon} out of sample observations using the Expected Log Predictive Density (ELPD).
Next, we approximate each successive round of
expanding window forecasts by moving forward one step at a time \verb{for i in 1:N_evaluations} and re-weighting
draws from the model's posterior predictive distribution using Pareto Smoothed
Importance Sampling (PSIS). In each iteration \code{i}, PSIS weights are obtained for the next observation
that would have been included in the model if we had re-fit (i.e. the last observation that would have
been in the training data, or \code{min_t + i}). If these importance ratios are stable, we consider the
approximation adequate and use the re-weighted posterior's forecast for evaluating the next holdout
set of testing observations (\code{(min_t + i + 1):(min_t + i + fc_horizon)}). At some point the
importance ratio variability will become too large and importance sampling will fail. This is
indicated by the estimated shape parameter \code{k} of the generalized Pareto distribution
crossing a certain threshold \code{pareto_k_threshold}. Only then do we refit the model using
all of the observations up to the time of the failure. We then restart the process and iterate forward
until the next refit is triggered (Bürkner et al. 2020).
}
\references{
Paul-Christian Bürkner, Jonah Gabry & Aki Vehtari (2020). Approximate leave-future-out cross-validation for Bayesian time series models
Journal of Statistical Computation and Simulation. 90:14, 2499-2523.
}
\author{
Nicholas J Clark
}
