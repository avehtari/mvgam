% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mvgam.R
\name{mvgam}
\alias{mvgam}
\title{Fit a Bayesian dynamic GAM to a univariate or multivariate set of discrete time series}
\usage{
mvgam(
  formula,
  trend_formula,
  knots,
  data,
  data_train,
  newdata,
  data_test,
  run_model = TRUE,
  prior_simulation = FALSE,
  return_model_data = FALSE,
  family = "poisson",
  use_lv = FALSE,
  n_lv,
  trend_map,
  trend_model = "None",
  drift = FALSE,
  chains = 4,
  burnin = 500,
  samples = 500,
  thin = 1,
  parallel = TRUE,
  threads = 1,
  priors,
  upper_bounds,
  refit = FALSE,
  use_stan = TRUE,
  max_treedepth,
  adapt_delta,
  jags_path
)
}
\arguments{
\item{formula}{A \code{character} string specifying the GAM observation model formula. These are exactly like the formula
for a GLM except that smooth terms, s, te, ti and t2, can be added to the right hand side
to specify that the linear predictor depends on smooth functions of predictors (or linear functionals of these).}

\item{trend_formula}{An optional \code{character} string specifying the GAM process model formula. If
supplied, a linear predictor will be modelled for the latent trends to capture process model evolution
separately from the observation model. Should not have a response variable specified on the left-hand side
of the formula (i.e. a valid option would be \code{~ season + s(year)}). This feature is experimental, and is only
currently available for Random Walk trend models.}

\item{knots}{An optional \code{list} containing user specified knot values to be used for basis construction.
For most bases the user simply supplies the knots to be used, which must match up with the k value supplied
(note that the number of knots is not always just k). Different terms can use different numbers of knots,
unless they share a covariate.}

\item{data}{A \code{dataframe} or \code{list} containing the model response variable and covariates
required by the GAM \code{formula}. Should include columns:
\code{series} (character or factor index of the series IDs)
\code{time} (numeric index of the time point for each observation).
Any other variables to be included in the linear predictor of \code{formula} must also be present}

\item{data_train}{Deprecated. Still works in place of \code{data} but users are recommended to use
\code{data} instead for more seamless integration into \code{R} workflows}

\item{newdata}{Optional \code{dataframe} or \code{list} of test data containing at least 'series' and 'time'
in addition to any other variables included in the linear predictor of \code{formula}. If included, the
observations in variable \code{y} will be set to \code{NA} when fitting the model so that posterior
simulations can be obtained}

\item{data_test}{Deprecated. Still works in place of \code{newdata} but users are recommended to use
\code{newdata} instead for more seamless integration into \code{R} workflows}

\item{run_model}{\code{logical}. If \code{FALSE}, the model is not fitted but instead the function will
return the model file and the data / initial values that are needed to fit the model outside of \code{mvgam}}

\item{prior_simulation}{\code{logical}. If \code{TRUE}, no observations are fed to the model, and instead
simulations from prior distributions are returned}

\item{return_model_data}{\code{logical}. If \code{TRUE}, the list of data that is needed to fit the
model is returned, along with the initial values for smooth and AR parameters, once the model is fitted.
This will be helpful if users wish to modify the model file to add
other stochastic elements that are not currently avaiable in \code{mvgam}. Default is \code{FALSE} to reduce
the size of the returned object, unless \code{run_model == FALSE}}

\item{family}{\code{family} specifying the exponential observation family for the series. Currently supported
families are:
\itemize{
\item\code{nb()} for count data
\item\code{poisson()} for count data
\item\code{tweedie()} for count data (power parameter \code{p} fixed at \code{1.5})
\item\code{gaussian()} for real-valued data
\item\code{betar()} for proportional data on \verb{(0,1)}
\item\code{lognormal()} for non-negative real-valued data
\item\code{student_t()} for real-valued data
\item\code{Gamma()} for non-negative real-valued data}
See \code{\link{mvgam_families}} for more details}

\item{use_lv}{\code{logical}. If \code{TRUE}, use dynamic factors to estimate series'
latent trends in a reduced dimension format. If \code{FALSE}, estimate independent latent trends for each series}

\item{n_lv}{\code{integer} the number of latent dynamic factors to use if \code{use_lv == TRUE}.
Cannot be \code{>n_series}. Defaults arbitrarily to \code{min(2, floor(n_series / 2))}}

\item{trend_map}{Optional \code{data.frame} specifying which series should depend on which latent
trends. Useful for allowing multiple series to depend on the same latent trend process, but with
different observation processes. If supplied, a latent factor model is set up by setting
\code{use_lv = TRUE} and using the mapping to set up the shared trends. Needs to have column names
\code{series} and \code{trend}, with integer values in the \code{trend} column to state which trend each series
should depend on. The \code{series} column should have a single unique entry for each series in the
data (names should perfectly match factor levels of the \code{series} variable in \code{data}). See examples
for details}

\item{trend_model}{\code{character} specifying the time series dynamics for the latent trend. Options are:
\itemize{
\item \code{None} (no latent trend component; i.e. the GAM component is all that contributes to the linear predictor,
and the observation process is the only source of error; similarly to what is estimated by \code{\link[mgcv]{gam}})
\item \code{RW} (random walk with possible drift)
\item \code{AR1} (with possible drift)
\item \code{AR2} (with possible drift)
\item \code{AR3} (with possible drift)
\item \code{VAR1} (with possible drift; only available in \code{Stan})
\item \code{GP} (Gaussian Process with squared exponential kernel;
only available in \code{Stan})}}

\item{drift}{\code{logical} estimate a drift parameter in the latent trend components. Useful if the latent
trend is expected to broadly follow a non-zero slope. Note that if the latent trend is more or less stationary,
the drift parameter can become unidentifiable, especially if an intercept term is included in the GAM linear
predictor (which it is by default when calling \code{\link[mgcv]{jagam}}). Drift parameters will also likely
be unidentifiable if using dynamic factor models. Therefore this defaults to \code{FALSE}}

\item{chains}{\code{integer} specifying the number of parallel chains for the model}

\item{burnin}{\code{integer} specifying the number of warmup iterations of the Markov chain to run
to tune sampling algorithms}

\item{samples}{\code{integer} specifying the number of post-warmup iterations of the Markov chain to run for
sampling the posterior distribution}

\item{thin}{Thinning interval for monitors}

\item{parallel}{\code{logical} specifying whether multiple cores should be used for
generating MCMC simulations in parallel. If \code{TRUE}, the number of cores to use will be
\code{min(c(chains, parallel::detectCores() - 1))}}

\item{threads}{\code{integer} Experimental option to use multithreading for within-chain
parallelisation in \code{Stan}. We recommend its use only if you are experienced with
\code{Stan}'s \code{reduce_sum} function and have a slow running model that cannot be sped
up by any other means. Only available when using \code{Cmdstan} as the backend}

\item{priors}{An optional \code{data.frame} with prior
definitions (in JAGS or Stan syntax). See \code{\link{get_mvgam_priors}} and
'Details' for more information on changing default prior distributions}

\item{upper_bounds}{Optional \code{vector} of \code{integer} values specifying upper limits for each series. If supplied,
this generates a modified likelihood where values above the bound are given a likelihood of zero. Note this modification
is computationally expensive in \code{JAGS} but can lead to better estimates when true bounds exist. Default is to remove
truncation entirely (i.e. there is no upper bound for each series). Currently not implemented
in \code{Stan}}

\item{refit}{Logical indicating whether this is a refit, called using \code{\link{update.mvgam}}. Users should leave
as \code{FALSE}}

\item{use_stan}{Logical. If \code{TRUE} and if \code{rstan} is installed, the model will be compiled and sampled using
the Hamiltonian Monte Carlo with a call to \code{\link[cmdstanr]{cmdstan_model}} or, if \code{cmdstanr} is not available,
a call to \code{\link[rstan]{stan}}. Note that
there are many more options when using \code{Stan} vs \code{JAGS} (the only "advantage" of \code{JAGS} is the ability
to use a Tweedie family).}

\item{max_treedepth}{positive integer placing a cap on the number of simulation steps evaluated during each iteration when
\code{use_stan == TRUE}. Default is \code{12}. Increasing this value can sometimes help with exploration of complex
posterior geometries, but it is rarely fruitful to go above a \code{max_treedepth} of \code{14}}

\item{adapt_delta}{positive numeric between \code{0} and \code{1} defining the target average proposal acceptance probability
during Stan's adaptation period, if \code{use_stan == TRUE}. Default is \code{0.8}. In general you should not need to change adapt_delta
unless you see a warning message about divergent transitions, in which case you can increase adapt_delta from the default
to a value closer to \code{1} (e.g. from \code{0.95} to \code{0.99}, or from \code{0.99} to \code{0.999}, etc).
The step size used by the numerical integrator is a function of \code{adapt_delta} in that increasing
\code{adapt_delta} will result in a smaller step size and fewer divergences. Increasing \code{adapt_delta} will
typically result in a slower sampler, but it will always lead to a more robust sampler.}

\item{jags_path}{Optional character vector specifying the path to the location of the \code{JAGS} executable (.exe) to use
for modelling if \code{use_stan == FALSE}. If missing, the path will be recovered from a call to \code{\link[runjags]{findjags}}}
}
\value{
A \code{list} object of class \code{mvgam} containing model output, the text representation of the model file,
the mgcv model output (for easily generating simulations at
unsampled covariate values), Dunn-Smyth residuals for each series and key information needed
for other functions in the package. See \code{\link{mvgam-class}} for details.
}
\description{
This function estimates the posterior distribution for Generalised Additive Models (GAMs) that can include
smooth spline functions, specified in the GAM formula, as well as latent temporal processes, specified by trend_model.
There are currently two options for specifying the structures of the trends (either as latent
dynamic factors to capture trend dependencies among series in a reduced dimension format, or as independent trends)
}
\details{
Dynamic GAMs are useful when we wish to predict future values from time series that show temporal dependence
but we do not want to rely on extrapolating from a smooth term (which can sometimes lead to unpredictable and unrealistic behaviours).
In addition, smooths can often try to wiggle excessively to capture any autocorrelation that is present in a time series,
which exacerbates the problem of forecasting ahead. As GAMs are very naturally viewed through a Bayesian lens, and we often
must model time series that show complex distributional features and missing data, parameters for \code{mvgam} models are estimated
in a Bayesian framework using Markov Chain Monte Carlo.
\cr
\cr
\emph{Priors}: A \code{\link[mgcv]{jagam}} model file is generated from \code{formula} and modified to include any latent
temporal processes. Prior distributions for most important model parameters can be altered by the user to inspect model
sensitivities to given priors (see \code{\link{get_mvgam_priors}} for details). Note that latent trends are estimated on the log scale so choose tau, AR and phi priors
accordingly. However more control over the model specification can be accomplished by first using \code{mvgam} as a
baseline, then editing the returned model accordingly. The model file can be edited and run outside
of \code{mvgam} by setting \code{run_model = FALSE} and this is encouraged for complex modelling tasks. Note, no priors are
formally checked to ensure they are in the right syntax for the respective probabilistic modelling framework, so it is
up to the user to ensure these are correct (i.e. use \code{dnorm} for normal densities in \code{JAGS}, with the mean and precision
parameterisation; but use \code{normal} for normal densities in \code{Stan}, with the mean and standard deviation parameterisation)
\cr
\cr
\emph{Random effects}: For any smooth terms using the random effect basis (\code{\link[mgcv]{smooth.construct.re.smooth.spec}}),
a non-centred parameterisation is automatically employed to avoid degeneracies that are common in hierarchical models.
Note however that centred versions may perform better for series that are particularly informative, so as with any
foray into Bayesian modelling, it is worth building an understanding of the model's assumptions and limitations by following a
principled workflow. Also note that models are parameterised using \code{drop.unused.levels = FALSE} in \code{\link[mgcv]{jagam}}
to ensure predictions can be made for all levels of the supplied factor variable
\cr
\cr
\emph{Overdispersion parameters}: When more than one series is included in \code{data_train} and an overdispersed
exponential family is used, additional observation family parameters
(i.e. \code{phi} for \code{nb()} or \code{sigma} for \code{gaussian()}) are
estimated independently for each series.
\cr
\cr
\emph{Factor regularisation}: When using a dynamic factor model for the trends with \code{JAGS} factor precisions are given
regularized penalty priors to theoretically allow some factors to be dropped from the model by squeezing increasing
factors' variances to zero. This is done to help protect against selecting too many latent factors than are needed to
capture dependencies in the data, so it can often be advantageous to set \code{n_lv} to a slightly larger number. However
larger numbers of factors do come with additional computational costs so these should be balanced as well. When using
\code{Stan}, all factors are parameterised with \code{sd = 0.1}
\cr
\cr
\emph{Residuals}: For each series, randomized quantile (i.e. Dunn-Smyth) residuals are calculated for inspecting model diagnostics
If the fitted model is appropriate then Dunn-Smyth residuals will be standard normal in distribution and no
autocorrelation will be evident. When a particular observation is missing, the residual is calculated by comparing independent
draws from the model's posterior distribution
\cr
\cr
\emph{Using Stan}: \code{mvgam} is primarily designed to use Hamiltonian Monte Carlo for parameter estimation
via the software \code{Stan} (using either the \code{cmdstanr} or \code{rstan} interface).
There are great advantages when using \code{Stan} over Gibbs / Metropolis Hastings samplers, which includes the option
to estimate smooth latent trends via \href{https://arxiv.org/abs/2004.11408}{Hilbert space approximate Gaussian Processes}.
This often makes sense for ecological series, which we expect to change smoothly. In \code{mvgam}, latent squared
exponential GP trends are approximated using by default \code{40} basis functions, which saves computational
costs compared to fitting full GPs while adequately estimating
GP \code{alpha} and \code{rho} parameters. Because of the many advantages of \code{Stan} over \code{JAGS},
\emph{further development of the package will only be applied to \code{Stan}}. This includes the planned addition
of more response distributions, plans to handle zero-inflation, and plans to incorporate a greater
variety of trend models. Users are strongly encouraged to opt for \code{Stan} over \code{JAGS} in any proceeding workflows
}
\examples{
\dontrun{
# Simulate a collection of three time series that have shared seasonal dynamics
dat <- sim_mvgam(T = 80, n_series = 3, prop_missing = 0.1,
                trend_rel = 0.6)

# Plot key summary statistics for a single series
plot_mvgam_series(data = dat$data_train, series = 1)

# Plot all series together
plot_mvgam_series(data = dat$data_train, series = 'all')

# Formulate a model using Stan where series share a cyclic smooth for
# seasonality and each series has an independent random walk temporal process;
# Set run_model = FALSE to inspect the returned objects
mod1 <- mvgam(formula = y ~ s(season, bs = 'cc'),
             data = dat$data_train,
             trend_model = 'RW',
             family = 'poisson',
             use_stan = TRUE,
             run_model = FALSE)

# View the model code in Stan language
code(mod1)


# Inspect the data objects needed to condition the model
str(mod1$model_data)

# Inspect the initial value function used to initialise the MCMC chains
mod1$inits

# The following code can be used to run the model outside of mvgam; first using rstan
model_data <- mod1$model_data
library(rstan)
fit <- stan(model_code = mod1$model_file,
           data = model_data,
           init = mod1$inits)

# Now using cmdstanr
library(cmdstanr)
model_data <- mod1$model_data
cmd_mod <- cmdstan_model(write_stan_file(mod1$model_file),
                        stanc_options = list('canonicalize=deprecations,braces,parentheses'))
cmd_mod$print()
fit <- cmd_mod$sample(data = model_data,
                     chains = 4,
                     parallel_chains = 4,
                     refresh = 100,
                     init = mod1$inits)

# Now fit the model using mvgam with the Stan backend
mod1 <- mvgam(formula = y ~ s(season, bs = 'cc'),
              data = dat$data_train,
              trend_model = 'RW',
              family = poisson(),
              use_stan = TRUE)

# Extract the model summary
summary(mod1)

# Plot the estimated historical trend and forecast for one series
plot(mod1, type = 'trend', series = 1)
plot(mod1, type = 'forecast', series = 1)

# Compute the forecast using covariate information in data_test
plot(object = mod1, type = 'trend', newdata = dat$data_test,
     series = 1)
plot(object = mod1, type = 'forecast', newdata = dat$data_test,
     series = 1)

# Plot the estimated seasonal smooth function
plot(mod1, type = 'smooths')

# Plot estimated first derivatives of the smooth
plot(mod1, type = 'smooths', derivatives = TRUE)

# Plot partial residuals of the smooth
plot(mod1, type = 'smooths', residuals = TRUE)

# Plot posterior realisations for the smooth
plot(mod1, type = 'smooths', realisations = TRUE)

# Extract observation model beta coefficient draws as a data.frame
beta_draws_df <- as.data.frame(mod1, variable = 'betas')
head(beta_draws_df)
str(beta_draws_df)

# Example of supplying a trend_map so that some series can share
# latent trend processes
sim <- sim_mvgam(n_series = 3)
mod_data <- sim$data_train

# Here, we specify only two latent trends; series 1 and 2 share a trend,
# while series 3 has it's own unique latent trend
trend_map <- data.frame(series = unique(mod_data$series),
                       trend = c(1,1,2))

# Fit the model using AR1 trends
mod1 <- mvgam(y ~ s(season, bs = 'cc'),
              trend_map = trend_map,
              trend_model = 'AR1',
              data = mod_data,
              return_model_data = TRUE)

# The mapping matrix is now supplied as data to the model in the 'Z' element
mod1$model_data$Z
code(mod1)

# The first two series share an identical latent trend; the third is different
plot(mod1, type = 'trend', series = 1)
plot(mod1, type = 'trend', series = 2)
plot(mod1, type = 'trend', series = 3)

# Example of how to use dynamic coefficients
# Simulate a time-varying coefficient for the effect of temperature
set.seed(3)
N = 200
beta_temp <- vector(length = N)
beta_temp[1] <- 0.4
for(i in 2:N){
  beta_temp[i] <- rnorm(1, mean = beta_temp[i - 1], sd = 0.025)
}

# Simulate the temperature covariate
temp <- rnorm(N, sd = 1)
# Simulate the Gaussian observation process
out <- rnorm(N, mean = 4 + beta_temp * temp,
             sd = 0.5)

# Gather necessary data into a data.frame; split into training / testing
data = data.frame(out, temp, time = seq_along(temp))
data_train <- data[1:180,]
data_test <- data[181:200,]

# Fit the model using the dynamic() formula helper
mod <- mvgam(formula = out ~ dynamic(temp, rho = 8),
             family = gaussian(),
            data = data_train,
            newdata = data_test)

# Inspect the model summary, forecast and time-varying coefficient distribution
summary(mod)
plot(mod, type = 'smooths')
plot(mod, type = 'forecast', newdata = data_test)

# Propagating the smooth term shows how the coefficient is expected to evolve
plot_mvgam_smooth(mod, smooth = 1, newdata = data)
abline(v = 180, lty = 'dashed', lwd = 2)

# Example showing how to incorporate an offset; simulate some count data
# with different means per series
set.seed(100)
dat <- sim_mvgam(trend_rel = 0, mu = c(0, 2, 2), seasonality = 'hierarchical')

# Add offset terms to the training and testing data
dat$data_train$offset <- 0.5 * as.numeric(dat$data_train$series)
dat$data_test$offset <- 0.5 * as.numeric(dat$data_test$series)

# Fit a model that includes the offset in the linear predictor as well as
# hierarchical seasonal smooths
mod1 <- mvgam(formula = y ~ offset(offset) +
         s(series, bs = 're') +
         s(season, bs = 'cc') +
         s(season, by = series, m = 1, k = 5),
         data = dat$data_train,
         trend_model = 'None',
         use_stan = TRUE)

# Inspect the model file to see the modification to the linear predictor
# (eta)
mod1$model_file

# Forecasts for the first two series will differ in magnitude
layout(matrix(1:2, ncol = 2))
plot(mod1, type = 'forecast', series = 1, newdata = dat$data_test,
     ylim = c(0, 75))
plot(mod1, type = 'forecast', series = 2, newdata = dat$data_test,
     ylim = c(0, 75))
layout(1)

# Changing the offset for the testing data should lead to changes in
# the forecast
dat$data_test$offset <- dat$data_test$offset - 2
plot(mod1, 'forecast', newdata = dat$data_test)

# Relative Risks can be computed by fixing the offset to the same value
# for each series
dat$data_test$offset <- rep(1, NROW(dat$data_test))
preds_rr <- predict(mod1, type = 'link', newdata = dat$data_test)
series1_inds <- which(dat$data_test$series == 'series_1')
series2_inds <- which(dat$data_test$series == 'series_2')

# Relative Risks are now more comparable among series
layout(matrix(1:2, ncol = 2))
plot(preds_rr[1, series1_inds], type = 'l', col = 'grey75',
     ylim = range(preds_rr),
     ylab = 'Series1 Relative Risk', xlab = 'Time')
for(i in 2:50){
 lines(preds_rr[i, series1_inds], col = 'grey75')
}

plot(preds_rr[1, series2_inds], type = 'l', col = 'darkred',
     ylim = range(preds_rr),
     ylab = 'Series2 Relative Risk', xlab = 'Time')
for(i in 2:50){
 lines(preds_rr[i, series2_inds], col = 'darkred')
 }
layout(1)
}
}
\references{
Nicholas J Clark & Konstans Wells (2020). Dynamic generalised additive models (DGAMs) for forecasting discrete ecological time series
Methods in Ecology and Evolution. 14:3, 771-784.
}
\seealso{
\code{\link[mgcv]{jagam}}, \code{\link[mgcv]{gam}}
}
\author{
Nicholas J Clark
}
